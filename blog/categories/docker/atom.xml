<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: docker | @znz blog]]></title>
  <link href="http://blog.n-z.jp/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://blog.n-z.jp/"/>
  <updated>2014-08-13T01:33:19+09:00</updated>
  <id>http://blog.n-z.jp/</id>
  <author>
    <name><![CDATA[Kazuhiro NISHIYAMA]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[boot2docker で VM のファイルをコンテナやホストと共有する]]></title>
    <link href="http://blog.n-z.jp/blog/2014-08-06-docker-volume.html"/>
    <updated>2014-08-06T23:17:27+09:00</updated>
    <id>http://blog.n-z.jp/blog/docker-volume</id>
    <content type="html"><![CDATA[<p>Mac OS X 上の <code>boot2docker</code> でホストとコンテナでファイルを共有する方法を試してみました。
さらに <code>boot2docker ssh</code> で入ったときにも見えるような設定でも試してみました。</p>

<!--more-->


<h2>参考</h2>

<ul>
<li><a href="http://qiita.com/numa08/items/e52bd18611ac159af1ac" title="boot2dockerでコンテナからホストのファイルを参照する - Qiita">boot2dockerでコンテナからホストのファイルを参照する - Qiita</a></li>
<li><a href="https://github.com/boot2docker/boot2docker#folder-sharing" title="Folder sharing">Folder sharing</a></li>
<li><a href="https://docs.docker.com/userguide/dockervolumes/" title="Managing data in containers - Docker Documentation">Managing data in containers - Docker Documentation</a></li>
</ul>


<h2>対象バージョン</h2>

<ul>
<li>Mac OS X 10.9.4</li>
<li>VirtualBox 4.3.14</li>
<li>docker 1.1.2</li>
<li>boot2docker 1.1.2</li>
</ul>


<h2>実行コマンド</h2>

<ul>
<li><code>docker run -v /mnt/sda1/data:/data --name my-data busybox true</code> で共有ボリューム用コンテナ作成</li>
<li><code>docker run --rm -v /usr/local/bin/docker:/docker -v /var/run/docker.sock:/docker.sock svendowideit/samba my-data</code> で samba 起動</li>
<li><code>docker run -it --rm --volumes-from my-data ubuntu /bin/bash</code> で確認</li>
</ul>


<h3>共有ボリューム用コンテナ作成</h3>

<p><a href="http://blog.n-z.jp/blog/2013-12-24-docker-rm.html" title="Dockerで不要になったコンテナやイメージを削除する">Dockerで不要になったコンテナやイメージを削除する</a>
のように <code>docker ps -a -q | xargs docker rm</code> などで停止しているコンテナを削除してしまうと
<code>my-data</code> という名前を付けたデータ保存用のコンテナも消えてしまうので、
<code>boot2docker</code> では永続化されているパーティションの <code>/mnt/sda1</code> に <code>data</code> をおくことにしました。</p>

<p>run の時点で <code>/mnt/sda1/data</code> は自動作成されるので、
あらかじめ作っておく必要はありません。</p>

<p>間違えてコンテナを削除してしまった場合は
<code>docker run -v /mnt/sda1/data:/data --name my-data busybox true</code>
で作成し直せばデータは残ったまま <code>my-data</code> コンテナを再作成できます。</p>

<p>このやり方は docker を動かすホストに依存してしまうので、
一般には標準のボリュームコンテナを作成する方法の方がおすすめのようです。</p>

<h3>共有ボリューム用コンテナ再作成 (標準の方法の場合)</h3>

<p><code>--volumes-from</code> で指定した共有は使っているコンテナがなくなってしまっても内容が残っていますが、
名前で指定して取り出す方法がなくなってしまうように見えます。</p>

<p><code>my-data</code> コンテナを削除してしまった場合、
<code>--volumes-from my-data</code> は使えなくなるので、
<code>docker run --volumes-from samba-server --name my-data busybox true</code>
のように残っているコンテナを <code>--volumes-from</code> で指定して再作成すれば、
また <code>docker run -it --rm --volumes-from my-data ubuntu /bin/bash</code> のように
<code>--volumes-from</code> に <code>my-data</code> を指定できるようになります。</p>

<h3>samba 起動</h3>

<p><code>docker run --rm -v /usr/local/bin/docker:/docker -v /var/run/docker.sock:/docker.sock svendowideit/samba my-data</code>
で samba を起動します。</p>

<p><code>docker.sock</code> も渡しているので、多重起動しないように既存の <code>samba-server</code> は止めてくれるようです。</p>

<p>起動時に以下のようにホスト側からの接続方法の説明が出ます。</p>

<pre><code>% docker run --rm -v /usr/local/bin/docker:/docker -v /var/run/docker.sock:/docker.sock svendowideit/samba my-data
stopping and removing existing server
starting samba server container sharing my-data:/data

# run 'docker logs samba-server' to view the samba logs

================================================

Your data volume (/data) should now be accessible at \\&lt;docker ip&gt;\ as 'guest' user (no password)

For example, on OSX, using a typical boot2docker vm:
    goto Go|Connect to Server in Finder
    enter 'cifs://192.168.59.103
    hit the 'Connect' button
    select the volumes you want to mount
    choose the 'Guest' radiobox and connect

Or on Linux:
    mount -t cifs //192.168.59.103/data /mnt/data -o username=guest

Or on Windows:
    Enter '\\192.168.59.103\data' into Explorer
    Log in as Guest - no password
</code></pre>

<h3>samba に接続</h3>

<p><code>boot2docker ip</code> で IP アドレスを確認して、
<code>192.168.59.103</code> なら、
<code>Finder</code> の <code>サーバへ接続</code> (メニューの <code>移動</code> の <code>サーバーへ接続...</code>) を開いて、
サーバアドレスとして <code>cifs://192.168.59.103/data</code> を入力して <code>接続</code> します。
<code>ユーザの種類</code> は <code>ゲスト</code> を選んで <code>接続</code> します。
すると <code>/Volumes/data</code> で見えるようになります。</p>

<p>Linux なら <code>mount -t cifs //192.168.59.103/data /mnt/data -o username=guest</code> のようにマウントするそうです。</p>

<p>Windows ならエクスプローラーで <code>\\192.168.59.103\data</code> にパスワードなしのゲスト接続すれば見えるそうです。</p>

<h3>別コンテナで確認</h3>

<p><code>docker run -it --rm --volumes-from my-data ubuntu /bin/bash</code> などで別コンテナを起動すると、
<code>/data</code> にマウントされているので、
<code>ls -l /data</code> で中身を確認したり、
<code>/data</code> の中にファイルを作成して他で見えることを確認しました。</p>

<h2>まとめ</h2>

<p><a href="https://github.com/boot2docker/boot2docker#folder-sharing">README に書いてある Folder sharing</a>
だと間違えて消してしまうことがあったので、ちょっと工夫した方法を紹介しました。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[boot2docker のバージョンアップ]]></title>
    <link href="http://blog.n-z.jp/blog/2014-08-06-boot2docker-upgrade.html"/>
    <updated>2014-08-06T23:10:26+09:00</updated>
    <id>http://blog.n-z.jp/blog/boot2docker-upgrade</id>
    <content type="html"><![CDATA[<p>boot2docker の ISO の更新は専用コマンドで簡単にできるとわかったので、
わざと古いバージョンに戻したりして動作確認してみました。</p>

<!--more-->


<h2>対象バージョン</h2>

<ul>
<li>Mac OS X 10.9.4</li>
<li>VirtualBox 4.3.14</li>
<li>docker 1.1.2</li>
<li>boot2docker 1.1.2</li>
</ul>


<h2>更新準備</h2>

<p><code>boot2docker delete</code> して消してから ISO を更新して
<code>boot2docker init</code> で作り直すという説明もありますが、
再起動しても残る部分は ISO とは別の仮想ディスクの <code>/dev/sda1</code> に保存されていて、
そのまま使い回せることがほとんどなので、
作り直さなくても更新できます。</p>

<p>大きくバージョンをあげるとか、クリーンな環境でやり直したいと言うときは消して作り直せば良いと思います。</p>

<p>参考: <a href="http://qiita.com/tukiyo3/items/07f1eb77b5ffd9031e30" title="boot2dockerのデータ永続化まとめ - Qiita">boot2dockerのデータ永続化まとめ - Qiita</a></p>

<h2>更新方法</h2>

<h3>VM を停止して更新</h3>

<p><code>boot2docker upgrade</code> で VM が起動していれば停止して更新して起動し直してくれます。</p>

<h3>ISO だけ更新</h3>

<p><code>boot2docker download</code> で ISO だけ無条件にダウンロードしてくれます。</p>

<h3>boot2docker help</h3>

<p>以上の説明は <code>boot2docker help</code> にちゃんと書いてある通りです。</p>

<pre><code>% boot2docker help
Usage: boot2docker [&lt;options&gt;] &lt;command&gt; [&lt;args&gt;]

boot2docker management utility.

Commands:
    init                    Create a new boot2docker VM.
    up|start|boot           Start VM from any states.
    ssh [ssh-command]       Login to VM via SSH.
    save|suspend            Suspend VM and save state to disk.
    down|stop|halt          Gracefully shutdown the VM.
    restart                 Gracefully reboot the VM.
    poweroff                Forcefully power off the VM (might corrupt disk image).
    reset                   Forcefully power cycle the VM (might corrupt disk image).
    delete|destroy          Delete boot2docker VM and its disk image.
    config|cfg              Show selected profile file settings.
    info                    Display detailed information of VM.
    ip                      Display the IP address of the VM's Host-only network.
    status                  Display current state of VM.
    download                Download boot2docker ISO image.
    upgrade                 Upgrade the boot2docker ISO image (if vm is running it will be stopped and started).
    version                 Display version information.

Options:
      --basevmdk="": Path to VMDK to use as base for persistent partition
      --dhcp=true: enable VirtualBox host-only network DHCP.
      --dhcpip=192.168.59.99: VirtualBox host-only network DHCP server address.
  -s, --disksize=20000: boot2docker disk image size (in MB).
      --dockerport=2375: host Docker port (forward to port 2375 in VM).
      --hostip=192.168.59.3: VirtualBox host-only network IP address.
      --iso="/Users/knishiyama/.boot2docker/boot2docker.iso": path to boot2docker ISO image.
      --lowerip=192.168.59.103: VirtualBox host-only network DHCP lower bound.
  -m, --memory=2048: virtual machine memory size (in MB).
      --netmask=ffffff00: VirtualBox host-only network mask.
      --serial=false: try serial console to get IP address (experimental)
      --serialfile="": path to the serial socket/pipe.
      --ssh="ssh": path to SSH client utility.
      --ssh-keygen="ssh-keygen": path to ssh-keygen utility.
      --sshkey="/Users/knishiyama/.ssh/id_boot2docker": path to SSH key to use.
      --sshport=2022: host SSH port (forward to port 22 in VM).
      --upperip=192.168.59.254: VirtualBox host-only network DHCP upper bound.
      --vbm="VBoxManage": path to VirtualBox management utility.
  -v, --verbose=false: display verbose command invocations.
      --vm="boot2docker-vm": virtual machine name.
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RubyLiveを仮想環境で作成]]></title>
    <link href="http://blog.n-z.jp/blog/2014-07-13-build-rubylive-on-vm.html"/>
    <updated>2014-07-13T09:35:02+09:00</updated>
    <id>http://blog.n-z.jp/blog/build-rubylive-on-vm</id>
    <content type="html"><![CDATA[<p>最近流行りの仮想環境を使ってクリーンな wheezy 環境で RubyLive を作成できるようにしました。</p>

<p>VirtualBox + Vagrant は特殊な制限のない仮想環境なので Live イメージが作成できたのですが、
docker は後述の制限のために作成できませんでした。</p>

<!--more-->


<h2>RubyLive を Vagrant で作成</h2>

<p>Vagrant を使ってクリーンな wheezy 環境で RubyLive の ISO を作成できるようにしました。
こちらは問題なく作成できました。</p>

<h3>動作確認バージョン</h3>

<ul>
<li>VirtualBox 4.3.12</li>
<li>Vagrant 1.6.3</li>
</ul>


<h3>使い方</h3>

<ul>
<li>VirtualBox と Vagrant をインストールしておきます。</li>
<li><code>git clone https://github.com/znz/rubylive-builder</code> で取得します。</li>
<li><code>cd rubylive-builder</code> で中に入ります。</li>
<li><code>VM_MEMORY=512 vagrant up</code> のように適当なメモリ容量を指定して起動します。 (指定なしなら 1024)

<ul>
<li>他の項目も環境変数である程度変更できるようにしています。</li>
<li>初回起動時は box をダウンロードするので非常に時間がかかります。</li>
<li>provision で live-build などの必要なパッケージをインストールしています。</li>
</ul>
</li>
<li><code>vagrant ssh</code> でゲストにログインします。</li>
<li><code>/vagrant/rubylive.sh</code> を実行すると <code>/home/vagrant/rubylive</code> で RubyLive のイメージを作成します。

<ul>
<li>実行するたびにタイムスタンプの入ったファイル名の ISO ファイルが作成されます。</li>
<li>ネットワークの速度やマシンスペックに影響を受けると思いますが、試した環境では約1時間かかりました。</li>
</ul>
</li>
<li>作成できた <code>/home/vagrant/rubylive/*.iso</code> を <code>/vagrant</code> にコピーまたは移動して、ホスト OS 側に取り出します。</li>
<li>取り出した ISO ファイルを使用します。</li>
</ul>


<p>なぜか
    chroot: failed to run command <code>/usr/bin/env': No such file or directory
で失敗することがありましたが、再度</code>/vagrant/rubylive.sh` を実行すれば問題なく作成できました。</p>

<h3>片付け方</h3>

<ul>
<li><code>vagrant destroy</code> で VM を破棄します。</li>
<li><code>git clone</code> した作業ディレクトリを削除します。</li>
<li>wheezy の box が不要なら <code>vagrant box remove opscode_debian-7.4_chef-provisionerless</code> で削除します。</li>
<li>Vagrant や VirtualBox も不要ならアンインストールします。</li>
</ul>


<h2>RubyLive を Docker で作成 (失敗)</h2>

<p>docker 環境の中では <code>chroot /rubylive/chroot mount -t proc proc /proc</code> が <code>EPERM</code> で失敗するため、作成できませんでした。</p>

<h3>動作確認バージョン</h3>

<ul>
<li>docker 1.1.1</li>
</ul>


<h3>試し方</h3>

<ul>
<li>docker をインストールしておきます。</li>
<li><code>git clone https://github.com/znz/rubylive-builder</code> で取得します。</li>
<li><code>docker build rubylive-builder</code> で作成に挑戦します。

<ul>
<li>または <code>cd rubylive-builder</code> で中に入って <code>docker build .</code> です。</li>
</ul>
</li>
<li><code>docker ps -a</code> で最近の CREATED の IMAGE を確認します。

<ul>
<li>もしくは <code>docker images</code> で確認します。</li>
<li>最後の失敗した後の状態は残っていないようでした。</li>
</ul>
</li>
<li><code>docker run -i -t --rm 4b8bc4523794 /bin/bash</code> のように中に入ります。

<ul>
<li>4b8bc4523794 のところは確認した IMAGE の ID にしてください。</li>
</ul>
</li>
<li><code>cd rubylive</code> で rubylive ディレクトリに入って <code>rake</code> で作成に再挑戦します。</li>
<li><code>less /rubylive/chroot/debootstrap/debootstrap.log</code> でログを確認したり、
<code>chroot /rubylive/chroot mount -t proc proc /proc</code> や
<code>mount -t proc proc /rubylive/chroot/proc</code> を直接実行してみたりして
原因を確認します。</li>
</ul>


<h3>失敗部分のメッセージ</h3>

<pre><code>W: Failure trying to run: chroot /rubylive/chroot mount -t proc proc /proc
W: See /rubylive/chroot/debootstrap/debootstrap.log for details
P: Begin unmounting filesystems...
P: Saving caches...
/usr/bin/env: apt-get: No such file or directory
rake aborted!
Command failed with status (1): [sudo lb build...]
</code></pre>

<p><code>/rubylive/chroot/debootstrap/debootstrap.log</code> をみると <code>mount: permission denied</code> と出ていました。</p>

<h3>Dockerfile 直接指定 (失敗)</h3>

<p><code>docker build https://raw.githubusercontent.com/znz/rubylive-builder/master/Dockerfile</code>
のように直接 URL を指定する方法は
<code>sources.list</code> を国内ミラーに差し替える部分が失敗して使えませんでした。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ubuntu 14.04 で dokku を使う]]></title>
    <link href="http://blog.n-z.jp/blog/2014-04-18-ubuntu-1404-dokku.html"/>
    <updated>2014-04-18T23:00:00+09:00</updated>
    <id>http://blog.n-z.jp/blog/ubuntu-1404-dokku</id>
    <content type="html"><![CDATA[<p>Ubuntu 14.04 がリリースされたので、
<a href="https://github.com/progrium/dokku">dokku</a>
を Ubuntu 14.04 で試してみました。</p>

<!--more-->


<h2>dokku の Vagrantfile を確認する</h2>

<p>まず dokku を clone して中の Vagrantfile をみて、
環境変数で設定できる項目があるのを確認しておきます。</p>

<pre><code class="console">% git clone https://github.com/progrium/dokku
% cd dokku
% vi Vagrantfile
</code></pre>

<h2>Vagantfile を変更する</h2>

<p>デフォルトの apt-line のままだとダウンロードが遅いので、
<a href="http://mirrors.ubuntu.com/mirrors.txt">http://mirrors.ubuntu.com/mirrors.txt</a>
からミラーサーバーを選んで (今回は jaist を選択)、
shell provision のところで書き換えておきます。
(関係ないところにマッチして問題が起きる可能性はほぼないので、置換元の URL の <code>.</code> はエスケープしていません。)</p>

<pre><code class="diff">diff --git a/Vagrantfile b/Vagrantfile
index a310f6b..7c1a133 100644
--- a/Vagrantfile
+++ b/Vagrantfile
@@ -29,5 +29,10 @@ Vagrant::configure("2") do |config|
     vb.customize ["modifyvm", :id, "--memory", BOX_MEMORY]
   end

-  config.vm.provision :shell, :inline =&gt; "apt-get -y install git &amp;&amp; cd /root/dokku &amp;&amp; #{make_cmd}"
+  config.vm.provision :shell, :inline =&gt; &lt;&lt;-SHELL
+    sed -i~ -e 's;http://archive.ubuntu.com/ubuntu;http://ftp.jaist.ac.jp/pub/Linux/ubuntu;' /etc/apt/sources.list &amp;&amp;
+    apt-get update &amp;&amp;
+    apt-get -y install git &amp;&amp;
+    cd /root/dokku &amp;&amp; #{make_cmd}
+  SHELL
 end
</code></pre>

<h2>初回起動</h2>

<p><code>BOX_NAME</code>, <code>BOX_URI</code> に trusty を指定して、
<code>BOX_MEMORY</code> も 512 から 2048 に増やした値を指定して起動します。</p>

<p><code>node-js-sample</code> だと 512 メガでも問題ないのですが、
Rails アプリを動かそうとするとメモリ不足で <code>bundle install</code> の途中で失敗して
deploy できなかったので増やしています。</p>

<pre><code class="console">% BOX_NAME=trusty-amd64-20140418 BOX_URI=https://cloud-images.ubuntu.com/vagrant/trusty/20140418/trusty-server-cloudimg-amd64-vagrant-disk1.box BOX_MEMORY=2048 vagrant up
</code></pre>

<p>box のダウンロードとインストール、
VM の作成などには時間がかかるので、
他のことをしながらゆっくり待ちます。</p>

<h2>二度目以降の起動</h2>

<p>VM の作成ができている状態なら、
box の設定は参照されないので省略できます。
<code>vagrant destroy</code> した後に <code>vagrant up</code> し直したときは参照されるので、
毎回設定していてもかまいません。</p>

<p><code>BOX_MEMORY</code> は毎回設定されるので、指定を忘れると 512 に戻ってしまいます。</p>

<pre><code class="console">% BOX_MEMORY=2048 vagrant up
</code></pre>

<h2>dokku の初期設定</h2>

<p>ssh の鍵を追加します。</p>

<pre><code class="console">% vagrant ssh
vagrant@dokku:~$ egrep '^ssh' ~/.ssh/authorized_keys | sudo sshcommand acl-add dokku vagrant
dd:3b:b8:2e:85:04:06:e9:ab:ff:a8:0a:c0:04:6e:d6
vagrant@dokku:~$ cat ~/.ssh/authorized_keys
# CLOUD_IMG: This file was created/modified by the Cloud Image build process
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA6NF8iallvQVp22WDkTkyrtvp9eWW6A8YVr+kz4TjGYe7gHzIw+niNltGEFHzD8+v1I2YJ6oXevct1YeS0o9HZyN1Q9qgCgzUFtdOKLv6IedplqoPkcmF0aYet2PkEDo3MlTBckFXPITAMzF8dJSIFo9D8HfdOV0IAdx4O7PtixWKn5y2hMNG0zQPyUecp4pzC6kivAIhyfHilFR61RGL+GPXQ2MWZWFYbAGjyiYJnAmCP3NOTd0jMZEnDkbUvxhMmBYSdETk1rRgm+R4LOzFUGaHqHDLKLX+FIPKcF96hrucXzcWyLbIbEgE98OHlnVYCzRdK8jlqm8tehUc9c9WhQ== vagrant insecure public key
vagrant@dokku:~$ cat /home/dokku/.ssh/authorized_keys
command="FINGERPRINT=dd:3b:b8:2e:85:04:06:e9:ab:ff:a8:0a:c0:04:6e:d6 NAME=vagrant `cat /home/dokku/.sshcommand` $SSH_ORIGINAL_COMMAND",no-agent-forwarding,no-user-rc,no-X11-forwarding,no-port-forwarding ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA6NF8iallvQVp22WDkTkyrtvp9eWW6A8YVr+kz4TjGYe7gHzIw+niNltGEFHzD8+v1I2YJ6oXevct1YeS0o9HZyN1Q9qgCgzUFtdOKLv6IedplqoPkcmF0aYet2PkEDo3MlTBckFXPITAMzF8dJSIFo9D8HfdOV0IAdx4O7PtixWKn5y2hMNG0zQPyUecp4pzC6kivAIhyfHilFR61RGL+GPXQ2MWZWFYbAGjyiYJnAmCP3NOTd0jMZEnDkbUvxhMmBYSdETk1rRgm+R4LOzFUGaHqHDLKLX+FIPKcF96hrucXzcWyLbIbEgE98OHlnVYCzRdK8jlqm8tehUc9c9WhQ== vagrant insecure public key
</code></pre>

<h2>dokku の鍵追加失敗例</h2>

<p><code>cat ~/.ssh/authorized_keys | sudo sshcommand acl-add dokku vagrant</code>
で追加してしまうと以下のように変になってしまいます。</p>

<pre><code class="text">vagrant@dokku:~$ cat /home/dokku/.ssh/authorized_keys
command="FINGERPRINT=is NAME=vagrant `cat /home/dokku/.sshcommand` $SSH_ORIGINAL_COMMAND",no-agent-forwarding,no-user-rc,no-X11-forwarding,no-port-forwarding # CLOUD_IMG: This file was created/modified by the Cloud Image build process
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA6NF8iallvQVp22WDkTkyrtvp9eWW6A8YVr+kz4TjGYe7gHzIw+niNltGEFHzD8+v1I2YJ6oXevct1YeS0o9HZyN1Q9qgCgzUFtdOKLv6IedplqoPkcmF0aYet2PkEDo3MlTBckFXPITAMzF8dJSIFo9D8HfdOV0IAdx4O7PtixWKn5y2hMNG0zQPyUecp4pzC6kivAIhyfHilFR61RGL+GPXQ2MWZWFYbAGjyiYJnAmCP3NOTd0jMZEnDkbUvxhMmBYSdETk1rRgm+R4LOzFUGaHqHDLKLX+FIPKcF96hrucXzcWyLbIbEgE98OHlnVYCzRdK8jlqm8tehUc9c9WhQ== vagrant insecure public key
</code></pre>

<pre><code class="bash">    KEY=$(cat)
    FINGERPRINT=$(ssh-keygen -lf /dev/stdin &lt;&lt;&lt; $(echo $KEY) | awk '{print $2}')
    KEY_PREFIX="command=\"FINGERPRINT=$FINGERPRINT NAME=$NAME \`cat $USERHOME/.sshcommand\` \$SSH_ORIGINAL_COMMAND\",no-agent-forwarding,no-user-rc,no-X11-forwarding,no-port-forwarding"
    echo "$KEY_PREFIX $KEY" &gt;&gt; "$USERHOME/.ssh/authorized_keys"
    echo $FINGERPRINT
</code></pre>

<p>の部分を以下のように <code>while read</code> ループに変えた方が良いのかもしれません。</p>

<pre><code class="bash">    while read KEY; do
      FINGERPRINT=$(ssh-keygen -lf /dev/stdin &lt;&lt;&lt; $(echo $KEY) | awk '{print $2}')
      KEY_PREFIX="command=\"FINGERPRINT=$FINGERPRINT NAME=$NAME \`cat $USERHOME/.sshcommand\` \$SSH_ORIGINAL_COMMAND\",no-agent-forwarding,no-user-rc,no-X11-forwarding,no-port-forwarding"
      echo "$KEY_PREFIX $KEY" &gt;&gt; "$USERHOME/.ssh/authorized_keys"
      echo $FINGERPRINT
    done
</code></pre>

<h2>node-js-sample の deploy</h2>

<p><code>node-js-sample</code> を <code>deploy</code> して動作確認します。
以下の例では <code>ssh dokku</code> で VM に接続できるように <code>~/.ssh/config</code> に設定済みです。</p>

<pre><code class="console">% git clone https://github.com/heroku/node-js-sample
Cloning into 'node-js-sample'...
remote: Reusing existing pack: 319, done.
remote: Total 319 (delta 0), reused 0 (delta 0)
Receiving objects: 100% (319/319), 201.92 KiB | 210.00 KiB/s, done.
Resolving deltas: 100% (17/17), done.
Checking connectivity... done.
% cd node-js-sample
% git remote add dokku dokku:node-js-app
%  git push --set-upstream dokku master
Counting objects: 319, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (274/274), done.
Writing objects: 100% (319/319), 201.92 KiB | 0 bytes/s, done.
Total 319 (delta 17), reused 319 (delta 17)
-----&gt; Cleaning up ...
remote: Cloning into '/tmp/tmp.ChNvZEb5S9'...
-----&gt; Building node-js-app ...
remote: warning: You appear to have cloned an empty repository.
remote: done.
remote: HEAD is now at 2e52ce7... Update documentation links
       Node.js app detected
-----&gt; Requested node range:  0.10.x
-----&gt; Resolved node version: 0.10.26
-----&gt; Downloading and installing node
(省略)
-----&gt; Discovering process types
       Procfile declares types -&gt; web
-----&gt; Releasing node-js-app ...
-----&gt; Deploying node-js-app ...
=====&gt; Application deployed:
       http://node-js-app.dokku.me

To dokku:node-js-app
 * [new branch]      master -&gt; master
Branch master set up to track remote branch master from dokku.
</code></pre>

<p>Vagrantfile で guest の 80 番ポートを host の 8080 番ポートで見えるように設定されているので
<code>http://node-js-app.dokku.me:8080/</code>
で開くと <code>Hello World!</code> と表示されます。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第3回 コンテナ型仮想化の情報交換会＠大阪 (コンテナ型VMや関連するカーネル等の技術が話題の勉強会)に参加した]]></title>
    <link href="http://blog.n-z.jp/blog/2014-04-12-lxcjp.html"/>
    <updated>2014-04-12T22:23:56+09:00</updated>
    <id>http://blog.n-z.jp/blog/lxcjp</id>
    <content type="html"><![CDATA[<p><a href="http://atnd.org/events/46446">第3回 コンテナ型仮想化の情報交換会＠大阪 (コンテナ型VMや関連するカーネル等の技術が話題の勉強会)</a>
に参加してきました。</p>

<!--more-->


<h2>全体の感想</h2>

<p>全体的には LXC や Docker に限らず、
Hyper-V 上での FreeBSD jail の話や Vagrant や CircleCI (LXC を使っている) などの話もあって、面白かったです。</p>

<h2>会場</h2>

<p>ちょっと早めに出発して、梅田から難波橋を通って堺筋を通って会場まで歩いていきました。
場所もわかりやすくて交差点の名前と目的地のビルの名前をちゃんとチェックしていれば迷わずにたどり着けました。</p>

<p>会場無線 LAN があったのですが、
最初に接続した MacBook Air は問題なく繋がっていたのですが、
後から追加でつなごうとした iPod touch は無線 LAN 自体は繋がっているのに APIPA の IP アドレスになっていて、
DHCP の割り当て IP アドレスが足りなかったのではないかと思いました。</p>

<h2>LXC</h2>

<p>いろいろと知らないことも多くて勉強になったのですが、特に <code>veth</code> と <code>macvlan</code> の違いがよくわかっていなかったので、
<code>veth</code> は作成しただけだと通信に使えなくてペアの片方をネットワークネームスペースに入れないと使えないというコンテナ用の機能で、
<code>macvlan</code> は物理 NIC に別 MAC アドレスを付けて使うもの、
というのがわかって良かったです。</p>

<p>LXC という言葉がさすものが「カーネルのコンテナ機能」のときと「<code>lxc-start</code> などの LXC のユーザーランド」のことがある、というのは気をつける必要があると思いました。
たとえば Docker 0.9 で LXC への依存がなくなったというのは <code>lxc-start</code> などを使わなくなって、システムコールを <code>libcontainer</code> という別ライブラリで直接呼んでカーネルのコンテナ機能を使うようになったなど。</p>

<h2>FreeBSD jail</h2>

<p>jail については存在は知っていたのですが、使ったことはなかったので、そういうものなのかと思ってみていました。</p>

<h2>VagrantユーザのためのDocker入門</h2>

<p>途中の質問にあった container と image の違いで
<a href="http://docs.docker.io/en/latest/terms/image/">http://docs.docker.io/en/latest/terms/image/</a>
に書いてある
<code>In Docker terminology, a read-only Layer is called an image. An image never changes.</code>
が根拠だと思うのですが、
イメージはコンテナに名前をつけてリードオンリーにしたもの、という説明で
今まで曖昧にしていた違いがちゃんとわかったように思いました。</p>

<p>このブログの Docker 関連記事の中で一番人気の
<a href="http://blog.n-z.jp/blog/2013-12-24-docker-rm.html">Dockerで不要になったコンテナやイメージを削除する</a>
で割とコンテナとイメージを曖昧な感じで書いているのは、はっきりとは区別できていなかったからでした。</p>

<p>Vagrant との使い分けも実際に両方使っている人の話だったので、非常に参考になりました。
基本的には Vagrant も Docker も開発環境として使うという話でした。</p>

<h2>Docker運用の観点からみたLXC</h2>

<p>いろいろな話がありました。
基本的には production 環境として使う話でした。</p>

<h2>Docker の layer 数制限の話</h2>

<p>休憩時間に話をしていたのですが layer の制限が 42 から 127 に増えたのは
<a href="https://github.com/dotcloud/docker/pull/2897">Increase max image depth to 127</a>
からで、
理由は aufs の方で <code>CONFIG_AUFS_BRANCH_MAX_127</code> という設定を <code>y</code> にすると
制限が 127 になるから、ということのようでした。</p>

<p>懇親会の時にも話が出たのですが、
<code>RUN</code> ごとにキャッシュがきくので、
基本的には <code>Dockerfile</code> の変更を試している間は <code>RUN</code> ごとに細かくコマンドを並べて試行錯誤して、
出来上がったら <code>&amp;&amp;</code> でつなげて一行の <code>RUN</code> にまとめるのが良さそう、
という話でした。</p>

<p>関連する話としては aufs の layer が重なっているのを git で merge するときのようにまとめたい、
という意見に対して、
<code>Dockerfile</code> をマスター (主) として扱って、
イメージは捨てていつでも作り直せるもの (従) として扱う方が良い、
だから、無理に aufs の差分イメージの中を直接いじってマージしようとせずに
<code>Dockerfile</code> から再生成した方が良い、
という話がありました。</p>

<h2>CircleCI, Cucumber-Chef</h2>

<p><code>CircleCI</code> と <code>ngrok</code> を組み合わせて、
rebuild.fm で話があったブランチごとよりもさらに富豪的に、
コミットごとに時間制限付きのサーバーを動かす話などがありました。</p>

<p><code>CircleCI</code> の1時間という時間制限 (SSH で入れるようにして動かすと30分) と
ローカルサーバーを外に公開できる <code>ngrok</code> というものを組み合わせて
コミットごとに一定時間サーバーを動かしているという話でした。</p>

<h2>終わり</h2>

<p>他の発表の時間に余裕を持たせていて、パネルディスカッションはありませんでした。</p>
]]></content>
  </entry>
  
</feed>
