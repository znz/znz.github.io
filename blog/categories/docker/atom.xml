<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: docker | @znz blog]]></title>
  <link href="http://blog.n-z.jp/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://blog.n-z.jp/"/>
  <updated>2017-09-21T00:21:10+09:00</updated>
  <id>http://blog.n-z.jp/</id>
  <author>
    <name><![CDATA[Kazuhiro NISHIYAMA]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[第11回 コンテナ型仮想化の情報交換会＠大阪に参加した]]></title>
    <link href="http://blog.n-z.jp/blog/2017-06-17-lxcjp.html"/>
    <updated>2017-06-17T13:30:00+09:00</updated>
    <id>http://blog.n-z.jp/blog/lxcjp</id>
    <content type="html"><![CDATA[<p><a href="https://ct-study.connpass.com/event/55305/">第11回 コンテナ型仮想化の情報交換会＠大阪</a>に参加してきました。</p>

<!--more-->


<p>以下、メモです。</p>

<h2>案内など</h2>

<ul>
<li>Wi-Fi はないはずだったが、提供できた</li>
<li>ハッシュタグは <a href="https://twitter.com/search?q=%23lxcjp">#lxcjp</a></li>
<li>(<a href="https://togetter.com/li/1121078">第11回 コンテナ型仮想化の情報交換会＠大阪 #lxcjp - Togetterまとめ</a>にまとめられています。質疑応答はメモ間違いもありそうなので、Togetter の方が正確そうです。)</li>
</ul>


<h2>Linuxコンテナ基礎(仮)</h2>

<ul>
<li>自己紹介</li>
<li><a href="http://gihyo.jp/admin/serial/01/linux_containers">LXCで学ぶコンテナ入門 －軽量仮想化環境を実現する技術</a></li>
<li>基礎知識</li>
<li>単独の機能があるわけではなく、 namespace とか cgroup とかを組みわせて実現されている</li>
<li>chroot とか pivot_root とか</li>
<li>speakerdeck で資料は公開予定</li>
<li>speakerdeck に元になった情報の多い資料も公開されている</li>
<li><a href="https://speakerdeck.com/tenforward/11th-ctstudy">Linux コンテナの基礎 / 11th CTStudy by tenforward</a></li>
</ul>


<h2>Haconiwa</h2>

<ul>
<li>イベントページでは「変拍子パワーポップ系コンテナランタイムHaconiwa - 夏を古くするな！」というタイトルになっていましたが、実際のタイトルは変わっていました。</li>
<li>自己紹介</li>
<li>Haconiwa とは?</li>
<li>mruby</li>
<li>ビュッフェ型コンテナランタイム</li>
<li>ビュッフェ型とは Web フレームワークでいうと Padrino</li>
<li>ruby で色々かける</li>
<li>コンテナの初期化処理とか</li>
<li>シグナルハンドラで CPU 割り当てを増減したりとか</li>
<li>Sqale という PaaS の運用のお手伝いの話</li>
<li>やりたいことが lxc などが古くて実現が難しかった</li>
<li>もしイチからやるなら?</li>
<li>コンテナ勉強会との出会い</li>
<li>RubyKaigi 2016 に応募して選考に通る前に完成</li>
<li>Haconiwa の実装方針</li>
<li>コア部分は Pure Ruby</li>
<li>システムコールは mruby gem でラップ</li>
<li>全てはプロセス</li>
<li>sample/process.rb を改変したものでデモ</li>
<li>関連技術</li>
<li>FastContainer</li>
<li><a href="http://hb.matsumoto-r.jp/entry/2016/11/11/234915">FastContainerアーキテクチャ構想</a></li>
<li>プロセスの3分類: immortal (いわゆるデーモン), short-lived (バッチとか ls とかの単独のコマンド), mortal</li>
<li>2つの中間的なものを定義する</li>
<li>mortal な存在としての FastCGI</li>
<li>inetd, xinetd</li>
<li>immortal なコンテナ: システムコンテナ, アプリケーションコンテナ, VPS として使う場合, Dokku</li>
<li>short-lived なコンテナ: アプリケーションコンテナで単一のジョブ: systemd-nspawn, FaaS</li>
<li>なぜ FastContainer か</li>
<li>負荷が上がった時: スケールアップ, スケールアウト</li>
<li>従来の VM では高速なスケールアップは非常に困難</li>
<li>コンテナでも煩雑さは残る</li>
<li>Haconiwa がスケールアップについての問題を解決</li>
<li>スケールアウトも従来の VM ではインスタンスの複製が難しいなど</li>
<li>コンテナもコストは下がるが自動化には課題がある</li>
<li><a href="http://mikeda.hatenablog.com/entry/2015/02/01/195102">負荷低すぎはもはや障害じゃないのか</a></li>
<li>FastContainer が解決するもの: スケールアウトについて インスタンスの入れ替え、増減が容易になる</li>
<li>+Haconiwa が解決するもの: 起動するコンテナ数をコンテナ自身で動的に操作させることが可能</li>
<li>Container as Code</li>
<li>その他のメリット</li>
<li>セキュリティ的観点: コンテナは、常に入れ替わるので、パッケージのアップグレードや、ミドルウェアの更新が非常になめらかに行える</li>
<li>運用的観点: どのホストであっても同じように動く。ホストをリソースプールとみなして透過的に扱える</li>
<li>FastContainer は実現できるか?</li>
<li>Scheduler: nomad</li>
<li>CoreAPI+CMDB</li>
<li>Web Proxy / Dispatcher : 起動のきっかけにもなるので Dispatcher</li>
<li>どうして Haconiwa を作ったのですか?</li>
<li>alternative rock</li>
<li>Docker はすごいが、それだけでいいのか</li>
<li>オルタナティブな存在が新しい価値観を届けるかもしれないのだ。</li>
<li>質疑応答</li>
<li>Q: どこで負荷を判別するか</li>
<li>A: cgroup の stat をベースに, veth (?) とかの負荷をみて</li>
<li>udzura cgroup で検索</li>
<li><a href="http://udzura.hatenablog.jp/entry/2017/05/02/175445">cgroup経由でシステムの利用状況を知る - CPU編</a> あたりが関連?</li>
<li>Q: mruby?</li>
<li>A: mruby の説明など</li>
<li>システムコール部分も Ruby っぽくやるために mruby という感じ?</li>
<li>Q: Web 以外の技術で FastCGI のような技術を応用することを考えているか?</li>
<li>A: nginx は tcp proxy 機能もあるので sshd とかも試している</li>
<li>Q: 具体的な利用予定は?</li>
<li>A: ロリポップ的に使えてオートスケールできるものができると良いかも?</li>
<li><a href="https://speakerdeck.com/udzura/the-alternative-container">変拍子パワーポップ系コンテナ、Haconiwa /the-alternative-container</a></li>
</ul>


<h2>休憩</h2>

<p>懇親会の追加申し込み受付案内</p>

<h2>chrootとnetwork namespaceでつくる簡易コンテナ</h2>

<ul>
<li>自己紹介</li>
<li>自作コンテナのモチベーション</li>
<li>Linux コンテナの勉強、既存コンテナ技術の再確認、手元でのネットワークテスト環境</li>
<li>chroot × network namespace × UTS namespace</li>
<li>UTS namespace は管理しやすいから</li>
<li>nginx + mackerel-agent + sshd</li>
<li>コマンドで作成</li>
<li>デモ</li>
<li>イメージ作成は docker export とか debootstrap とかが使える</li>
<li>namespace の永続化</li>
<li>/proc/[PID]/ns 配下にある特殊ファイル</li>
<li>bind マウントを使って永続化する</li>
<li>mount &ndash;bind /run/utsns /run/utsns</li>
<li>mount &ndash;make-shared /run/utsns</li>
<li>unshare -u mount &ndash;bind /proc/self/ns/uts /run/utsns/test01</li>
<li>最近の unshare コマンドなら unshare &ndash;uts=/run/utsns/test01</li>
<li>UTS namespace: 主に管理のため</li>
<li>Network の作成</li>
<li>veth 作って bridge に接続</li>
<li>Netowrk はポータビリティに影響が出やすい</li>
<li>一時期 docker が頑張ってた: VXLAN による overlay Network など</li>
<li>改善すべき箇所がたくさんある面白い分野</li>
<li>chroot 環境の作成</li>
<li>コンテナの中でも systemd を動かすと shared マウントだとコンテナの片付けの時に親の方まで一緒にアンマウントされてしまってはまるので、 rslave が必要</li>
<li>コンテナ内でのプロセスの実行: nsenter した上で chroot する</li>
<li>chroot 配下では systemd は動作しないので注意が必要</li>
<li>chroot の代わりに systemd-nspawn を使う</li>
<li>PID namespace</li>
<li>docker 1.13 で run に init オプションがついた</li>
<li>ss はネームスペースを指定できる</li>
<li>いけてない箇所</li>
<li>質疑応答</li>
<li>Q: udzuraさん: VXLAN を検証している?</li>
<li>A: 業務では使っていなくて趣味でやっている。 Open vSwitch で軽く試したことはある。</li>
</ul>


<p>veth のデモは <a href="https://asciinema.org/a/122327">Network Namespace &amp; Veth demo</a> を参照</p>

<h2>LXD 採用から運用までの顛末記</h2>

<ul>
<li>自己紹介</li>
<li>LXD 採用で、XREA、ハイパフォーマンスで安定稼働しております</li>
<li>XERA の歴史</li>
<li>古い物理サーバーから KVM</li>
<li>完全仮想化の利点と問題点</li>
<li>時代はコンテナだということで準仮想化</li>
<li>なぜ LXD か?</li>
<li>Docker: ユーザーの権限独立とネットワーク周りの問題が解決できず</li>
<li>KVM: オーバーヘッドが多くてリソースが無駄</li>
<li>OpenVZ: コンテナより遅かった</li>
<li>VMware: 考えたこともない</li>
<li>LXD: コンテナだし、リソースが有効に使えて、ヒャッハーだ！</li>
<li>LXD 採用からサービス開始まで</li>
<li>マイグレーションに伴う障害はあったが、コンテナが原因の問題はおきなかった</li>
<li>LXD の運用環境</li>
<li>ホスト Ubuntu 16.04 LTS</li>
<li>ゲスト CentOS 7</li>
<li>ZFS + ブロックデバイス</li>
<li>ホストシステム構築時のトラブル</li>
<li>オープンファイル数の上限編</li>
<li>試行錯誤した結果 <code>fs.inotify.max_user_instances</code> だった</li>
<li>その他色々上限解除</li>
<li>LXD 運用編</li>
<li>1: ユーザークォータがきかない→運用でカバー</li>
<li>2: マイグレーション時に Apache のアラートがあがる</li>
<li>原因は Apache RLimitNPROC + Potential DoS attacks</li>
<li>同じユーザーだったのが原因</li>
<li><a href="https://linuxcontainers.org/lxc/security/">https://linuxcontainers.org/lxc/security/</a></li>
<li>3: ホストのロードアベレージが急激に上昇→ZFS がボトルネック、チューニングを実施</li>
<li>4: コンテナ自体のリソース制御</li>
<li>5: (よそ見をしていたら見逃した)</li>
<li>LXD に変えてどうだったか</li>
<li>よかったという話</li>
<li>質疑応答</li>
<li>Q: ホスト間のマイグレーションは使っているか?</li>
<li>A: KVM からのマイグレーションだったので今回は使っていない。次回は使うかもしれない。</li>
<li>Q: ZFS で苦労されたという話だったが、他に選択肢はあったのか?</li>
<li>A: ZFS がデフォルトっぽい感じだったので、選んだ。ブロックデバイスかどうかというのはあったが、ブロックデバイスを選んだ。</li>
<li>Q: Docker のネットワーク周りの問題とは?</li>
<li>担当者 A: ポートとか IP とかの問題</li>
</ul>


<h2>休憩</h2>

<p>懇親会の案内</p>

<h2>Joe&rsquo;s と LXC とその運用実例と</h2>

<ul>
<li>Joe&rsquo;s Cloud Computing</li>
<li>会社紹介</li>
<li>Speaker 紹介</li>
<li>Joe&rsquo;s と LXC</li>
<li>2001年: Scientific Linux 6 with kernel 2.6.42 (後で訂正あり) + patch, zfs on fuse: 当初よりテンプレートを意識した設計</li>
<li>2010年〜: ubuntu に乗り換え, LXD への移行模索中</li>
<li>現在: 共用サーバーの半分が LXC 駆動</li>
<li>LXC と Docker</li>
<li>kvm との比較</li>
<li>LXC 運用のメリット: リソース管理がしやすい</li>
<li>運用例: zabbix 運用, 障害対応, IPブロック, プロセス管理</li>
<li>運用テストで LXC で zabbix を作成</li>
<li>nagios から移行</li>
<li>本番環境に移動</li>
<li>lxc だと rsync でコピーして起動できる</li>
<li>同一ネットワークだと監視の意味が、ということでさくらクラウドに移動</li>
<li>障害対応</li>
<li>ハードウェア障害</li>
<li>起動しなくても HDD から読み出せるならレスキュー環境で起動して吸い出してなんとかできる</li>
<li>IP ブロック</li>
<li>ホスト側の FORWARD チェインでブロック</li>
<li>FORWARD なので失敗しても取り消しやすい</li>
<li>ゲスト側が古くて ipset が使えなくてもホスト側で使えるので便利</li>
<li>プロセス管理: ホスト側から監視できる (htop とか)</li>
<li>これからの LXC ホスティング</li>
<li>デプロイ速度の向上</li>
<li>仮想コンソールの実装</li>
<li>Migration / HA の実装</li>
<li>まだまだこれから楽しめる分野</li>
<li>質疑応答</li>
<li>Q: Zabbix のバックアップ運用は?</li>
<li>A: ローカルは HDD が多いマシンがあるのでそこにとっている。リモートはホスト側で rsync と database のバックアップ</li>
<li>Q: ゲスト数はどのくらい?</li>
<li>A: 4コアで1台ぐらいのイメージ。テストでは40台ぐらいで</li>
<li>ディスクの I/O がボトルネックになる。</li>
<li>Q: 特権コンテナ?</li>
<li>A: マネージドは特権コンテナで問題ない。 VPS は非特権コンテナの予定あり。</li>
<li>Q: LXC のバージョンアップやマイグレーションでの気をつけたポイントは?</li>
<li>A: 古いサーバーのバージョン確認 kernel 2.6.42 ではなかった 2.6.32.41 LXC 0.7.4.1</li>
<li><a href="https://speakerdeck.com/samaiyou/joes-and-working-with-lxc">Joe&rsquo;s and working with LXC by samaiyou</a></li>
</ul>


<h2>Dockerコンテナ監視要素の検討</h2>

<ul>
<li>古い情報で誤解されていることがある</li>
<li><a href="http://docs.docker.jp/">http://docs.docker.jp/</a></li>
<li>動機: どのように監視をしたら良いのか?, runC と containerD, 私は私が欲しい監視システムを作りたい</li>
<li>監視と運用: システム稼働状況の把握と対策, サービスレベル</li>
<li><a href="http://www.brendangregg.com/linuxperf.html">http://www.brendangregg.com/linuxperf.html</a></li>
<li>ストレージドライバーによってパフォーマンスが大きく異なる</li>
<li>dockerd (Docker Engine), containerD</li>
<li>スケジューリング + クラスタ管理 = オーケストレーション</li>
<li>良い感じの自動化ツールはまだなさそう</li>
<li>Prometheus</li>
<li>Docker Engine とデーモンの変遷</li>
<li>v1.11〜 は dockerd - containerd - runC になっている</li>
<li><a href="https://www.opencontainers.org/">https://www.opencontainers.org/</a> - runC</li>
<li><a href="https://www.cncf.io/">https://www.cncf.io/</a> - containerd</li>
<li>2013年→2016年夏現在: dockerd デーモンの解体, 従来のコンテナ監視はメトリクス取得に集中</li>
<li>runC</li>
<li>バイナリ配布はされていないので自分で make する必要あり</li>
<li>runc のデモ</li>
<li>Docker Compose</li>
<li>fig が買収されて docker-compose になった</li>
<li>docker swarm mode, overlay network で Routing mesh, docker service create でサービス作成</li>
<li>サービス名で名前解決できる</li>
<li>監視はどうする?</li>
<li>Docker Swarm という swarm mode とは名前は似ているが別物がまだ残っているがそのうち消えるはず</li>
<li>API と SDK</li>
<li><code>curl --unix-socket /var/run/docker.sock -X GET http://v1.29/containers/json?size=true | jq "." | less</code> とかでも情報がとれる</li>
<li><a href="https://github.com/yadutaf/ctop">https://github.com/yadutaf/ctop</a></li>
<li>systemd-cgtop より便利</li>
<li>Q: containerd と runc を意識する必要はあるか?</li>
<li>A: 普段はあまり意識する必要はない</li>
<li>Q: ホスティングサービスでは docker を選ばなかったが、お客様から見えない部分では使いたい</li>
<li>A: さくらの VPS のコントロールパネルなどで docker を使っている</li>
<li>Q: kubernetes とかは?</li>
<li>A: 用途が違うので使い分ければ良いのでは。使いたいものを使えば良いのでは。</li>
<li>ユーザー目線で使いやすいのは swarm mode とか</li>
<li>リソースを有効活用したいのなら mesos とか</li>
<li>kubernetes はあまり詳しくない</li>
<li>mesos は API があって使いやすいらしい</li>
<li>ctop は同じ名前で別のものがある</li>
</ul>


<h2>感想</h2>

<p>lxc/lxd の話がきけてよかったです。Web 上ではあまり見かけないと思っていましたが、使っているところではちゃんと使っていて、安定して運用できていると聞いて、用途によっては使ってみたいと思いました。</p>

<p>Docker の話も普段 Dokku などで使っていて、なんか色々変わっていっているとは感じていましたが、まとまった話として聞けてよかったです。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ansibleでjsonファイルの設定を更新した]]></title>
    <link href="http://blog.n-z.jp/blog/2017-06-16-ansible-json.html"/>
    <updated>2017-06-16T21:26:00+09:00</updated>
    <id>http://blog.n-z.jp/blog/ansible-json</id>
    <content type="html"><![CDATA[<p>ansible で json ファイル (今回は <code>/etc/docker/daemon.json</code>) を更新したかったのですが、 <code>lineinfile</code> や <code>replace</code> や <code>ini_file</code> のように単独のモジュールで簡単にできるものではなかったので、少し工夫をして実現しました。</p>

<!--more-->


<h2>動作確認バージョン</h2>

<ul>
<li>ansible 2.3.1.0</li>
</ul>


<p>combine フィルター (後述) が New in version 2.0 なので、 1.x では動かないと思います。</p>

<h2>実例</h2>

<p><a href="https://github.com/znz/ansible-role-docker">https://github.com/znz/ansible-role-docker</a> や <a href="https://github.com/znz/ansible-playbook-gitlab-dokku/tree/master/provision/roles/docker-dns">https://github.com/znz/ansible-playbook-gitlab-dokku/tree/master/provision/roles/docker-dns</a> にあります。</p>

<h2>json ファイル読み込み</h2>

<p>まずは <code>command</code> モジュールで読み込んで、 <code>set_fact</code> で変数に設定しておきます。</p>

<pre><code>- name: "Read daemon.json"
  command: cat /etc/docker/daemon.json
  register: result
  changed_when: no
</code></pre>

<p>記事を書いていて気づいたのですが、リモートからファイルを読み込むには <code>slurp</code> モジュールというのがあるようですが、作った時点では知らなかったので、使っていません。</p>

<p>base64 でエンコードされていて b64decode を通す必要があるようなので、何度も参照するなら、次の <code>set_fact</code> を組み合わせた方が良さそうなのは変わらなさそうです。</p>

<h2>json から dict に変換</h2>

<p>json の文字列から <a href="http://docs.ansible.com/ansible/playbooks_filters.html#filters-for-formatting-data"><code>from_json</code>フィルター</a>で変換します。</p>

<p></p>

<pre><code>- set_fact: docker_daemon_json="{{ result.stdout | from_json }}"
</code></pre>

<p></p>

<h2>combine フィルターでマージ</h2>

<p><a href="http://docs.ansible.com/ansible/playbooks_filters.html#combining-hashes-dictionaries"><code>combine</code>フィルター</a>で設定をマージして、 <code>to_json</code> フィルターで json 文字列に変換してファイルに書き出します。</p>

<p>今回の用途では、ネストしたデータは考慮する必要がなく、トップレベルのキーが一致するもので置き換えられればよかったので、 <code>recursive=True</code> は指定していません。</p>

<p><code>when</code> でのチェックもしておかないと、設定内容としては変わっていないのに、 json 文字列になった時にキーの順番が変わっているのか、 changed になってしまうことがあったので、 <code>when</code> で設定内容に変更がある時だけ書き込むようにしています。</p>

<pre><code>- name: "Update daemon.json"
  template:
    src: daemon.json.j2
    dest: /etc/docker/daemon.json
    owner: root
    group: root
    mode: 0400
  when: "docker_daemon_json != docker_daemon_json|combine({'dns':dns})"
  notify:
  - restart docker
</code></pre>

<p>templates/daemon.json.j2:</p>

<p></p>

<pre><code>{{ docker_daemon_json | combine({"dns": dns}) | to_json }}
</code></pre>

<p></p>

<h2>動作確認</h2>

<p>全体ができた後に、</p>

<ul>
<li>ファイルがない時の動作</li>
<li>設定が変わらない時の動作</li>
<li>設定が変わる時の動作</li>
</ul>


<p>も確認しておきます。</p>

<h2>docker のデーモン設定ファイル</h2>

<p>docker の<a href="http://docs.docker.jp/engine/reference/commandline/dockerd.html#daemon-configuration-file">デーモン設定ファイル</a>は <code>insecure-registries</code> (<code>--insecure-registry=[]</code>) や <code>dns</code> や <code>bip</code> など dockerd のオプションで指定できるものはなんでも指定できます。</p>

<p><a href="http://docs.docker.jp/engine/admin/systemd.html#custom-docker-daemon-options">docker デーモンのオプション変更</a>は systemd の docker.service の設定を変更する方法もあるようですが、ローカルの変更をローカルの独立ファイルに隔離できて、バージョンアップの影響も少なそうなので、 daemon.json を使うことにしました。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[dokku 0.4.1 の新規インストールを試してみた]]></title>
    <link href="http://blog.n-z.jp/blog/2015-10-08-dokku-041.html"/>
    <updated>2015-10-08T23:00:00+09:00</updated>
    <id>http://blog.n-z.jp/blog/dokku-041</id>
    <content type="html"><![CDATA[<p>仮想環境で dokku 0.4.1 の新規インストールを試しました。</p>

<!--more-->


<h2>検証環境</h2>

<ul>
<li>Ubuntu 14.04.3 LTS (trusty) amd64</li>
<li><code>docker</code> 1.8.2</li>
<li><code>dokku</code> 0.4.1</li>
<li><a href="https://github.com/Flink/dokku-psql-single-container" title="dokku-psql-single-container">dokku-psql-single-container</a> プラグイン 0.4.0</li>
</ul>


<h2>dokku のインストール</h2>

<p><a href="https://github.com/progrium/dokku#installing" title="Installing">Installing</a> の手順通りにインストールしました。</p>

<pre><code>wget https://raw.githubusercontent.com/progrium/dokku/v0.4.1/bootstrap.sh
sudo DOKKU_TAG=v0.4.1 bash bootstrap.sh
</code></pre>

<p><code>herokuish</code> の <code>postinst</code> で時間がかかります。</p>

<h2>Web UI で初期設定</h2>

<p>debconf での設定は出てこなかったので Web ブラウザで <code>http://localhost</code> を開いて初期設定します。</p>

<p><code>Public Key</code> には <code>~/.ssh/id_rsa.pub</code> の内容をコピペしました。
まだ鍵がなければ <code>ssh-keygen</code> で作成します。</p>

<p><code>Hostname</code> はインターネットに接続しているグローバル IP アドレスが入っていたので、 <code>dokku.me</code> に変更して、 <code>Use virtualhost naming for apps</code> にチェックを入れました。</p>

<p>最後に <code>Finish Setup</code> を押して初期設定完了です。</p>

<p>この設定で <code>http://アプリ名.dokku.me</code> のような URL で各アプリにアクセスできるようになります。(<code>dokku.me</code> は <code>dokku</code> のドキュメントに書いてあるドメインで、すべてのサブドメインでも <code>127.0.0.1</code> を返してくれるドメインのようです。)
(2016-04-20 追記: 現在は 127.0.0.1 ではなく 10.0.0.2 に変わっています。)</p>

<p>初期設定終了後はアプリをデプロイするまで <code>http://localhost</code> には繋がらなくなります。</p>

<h2>node のサンプルアプリのデプロイ</h2>

<p><a href="http://progrium.viewdocs.io/dokku/application-deployment/" title="Deploy an App">Deploy an App</a> に書いてあるように node のサンプルアプリをデプロイしてみます。</p>

<p>ssh server が入っていなければ <code>sudo apt-get install openssh-server</code> でインストールしておきます。</p>

<pre><code>git clone https://github.com/heroku/node-js-sample
cd node-js-sample
git remote add dokku dokku@dokku.me:node-js-app
git push dokku master
</code></pre>

<p>push が成功したら <code>http://node-js-app.dokku.me</code> をブラウザで開きます。
「<code>Hello World!</code>」と表示されれば成功です。</p>

<p><code>dokku</code> の内部の実体としては <code>/home/dokku/node-js-app</code> に入っています。</p>

<p>デプロイ前の状態に戻すには</p>

<pre><code>dokku apps:destroy node-js-app
</code></pre>

<p>で削除します。</p>

<h2>dokku コマンドについて</h2>

<p>実行例はサーバー上でのものを示していますが、 <code>sudo dokku</code> で実行しているもの以外はサーバー上で <code>dokku サブコマンド</code> で実行しても、リモートから <code>ssh dokku@dokku.me サブコマンド</code> で実行しても、基本的には同じ意味になります。</p>

<h2>グローバル設定の変更</h2>

<p>初期設定だと <code>curl</code> のタイムアウトが短すぎて、後の <code>ruby</code> のダウンロードのところでエラーになってしまうため、 <code>dokku config:set --global CURL_TIMEOUT=120</code> でタイムアウト時間を延ばします。</p>

<pre><code>$ dokku config --global
====&gt; --global config vars
CURL_CONNECT_TIMEOUT: 5
CURL_TIMEOUT:         30
$ dokku config:set --global CURL_TIMEOUT=120
-----&gt; Setting config vars
       CURL_TIMEOUT: 120
$ dokku config --global
====&gt; --global config vars
CURL_CONNECT_TIMEOUT: 5
CURL_TIMEOUT:         120
</code></pre>

<h2>dokku-psql-single-container プラグインのインストール</h2>

<pre><code>sudo dokku plugin:install https://github.com/Flink/dokku-psql-single-container
</code></pre>

<p>でプラグインをインストールします。
postgres の docker イメージをダウンロードするため、ある程度時間がかかります。</p>

<p>アンインストールは</p>

<pre><code>sudo dokku plugin:uninstall psql-single-container
</code></pre>

<p>です。(<code>dokku-</code> はつかない。)</p>

<h3>sshcommand の変更</h3>

<p><code>sshcommand create</code> で <code>dokku-psql-single-container</code> プラグインが使っている <code>/home/dokku/.psql-sc/data</code> の <a href="https://github.com/Flink/dokku-psql-single-container/issues/5">owner が変わってしまう問題がある</a>ため、</p>

<pre><code>sudoedit /usr/local/bin/sshcommand
</code></pre>

<p>で</p>

<pre><code>    chown -R $USER $USERHOME
</code></pre>

<p>を</p>

<pre><code>    chown $USER $USERHOME
    chown -R $USER $USERHOME/.ssh*
</code></pre>

<p>に変更しました。</p>

<p><a href="https://github.com/dokku/dokku-postgres">公式の postgres plugin</a> だとこの変更は必要ありません。</p>

<h2>Rails のサンプルアプリのデプロイの準備</h2>

<p>プラグインを使うため、 <code>git push</code> 前に準備しておきます。
(今回試したアプリの場合は <code>git push</code> 後に <code>psql:create</code> しても大丈夫でした。)</p>

<pre><code>dokku apps:create ruby-rails-app
dokku psql:create ruby-rails-app
</code></pre>

<p>まず <code>apps:create</code> で <code>/home/dokku/ruby-rails-app</code> を作成してから、そのアプリと連携するデータベースを <code>psql:create</code> で作成します。</p>

<h2>Rails のサンプルアプリのデプロイ</h2>

<p>Rails のサンプルアプリをデプロイします。</p>

<pre><code>git clone https://github.com/heroku/ruby-rails-sample
cd ruby-rails-sample
git remote add dokku dokku@dokku.me:ruby-rails-app
git push dokku master
dokku run ruby-rails-app rake db:migrate
</code></pre>

<p>push が成功したら <code>http://ruby-rails-app.dokku.me</code> を開きます。
<code>Hello World</code> と現在時刻が表示されていたら成功です。</p>

<p>後から <code>psql:create</code> した場合は 500 エラーになるので、 <code>dokku ps:restart ruby-rails-app</code> で再起動すると環境変数の追加が反映されてなおります。</p>

<h2>デプロイ前に戻す方法</h2>

<p><code>dokku apps:destroy ruby-rails-app</code> で戻せるはずですが、データベースに接続中でデータベースの削除に失敗することがあります。</p>

<p>失敗した場合は <code>dokku psql:admin_console</code> で接続して <code>\l</code> で削除できていないのを確認して、 <code>DROP DATABASE db_ruby_rails_app;</code> で削除できました。</p>

<h2>タイムゾーン変更</h2>

<p>タイムゾーンが UTC になっているので日本時間に変更しました。</p>

<pre><code>dokku config:set ruby-rails-app TZ=Asia/Tokyo
</code></pre>

<h2>初期設定した以外の Virtualhost を使う方法</h2>

<p><code>node-js-sample</code> を再利用して、別ドメインでも見えるようにしてみました。</p>

<pre><code>cd node-js-sample
git remote add xip dokku@dokku.me:node-js-app.127.0.0.1.xip.io
git push xip master
</code></pre>

<p><code>http://node-js-app.127.0.0.1.xip.io</code> でも「<code>Hello World!</code>」が見えれば成功ですが、デフォルトホストとして見えているだけかもしれないので、 <code>index.js</code> の <code>'Hello World!'</code> 部分を変更して区別できるようにすると良いかもしれません。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[dokku 0.3 系から 0.4 系へのアップグレード]]></title>
    <link href="http://blog.n-z.jp/blog/2015-10-08-dokku-03-to-04.html"/>
    <updated>2015-10-08T22:00:00+09:00</updated>
    <id>http://blog.n-z.jp/blog/dokku-03-to-04</id>
    <content type="html"><![CDATA[<p>dokku 0.3.26 から dokku 0.4.1 へのアップグレードをしました。</p>

<!--more-->


<h2>検証環境</h2>

<ul>
<li>Ubuntu 14.04.3 LTS (trusty) amd64</li>
<li><code>docker</code> 1.6.2 から 1.8.2</li>
<li><code>dokku</code> 0.3.26 から 0.4.1</li>
<li><a href="https://github.com/Flink/dokku-psql-single-container" title="dokku-psql-single-container">dokku-psql-single-container</a> プラグイン 0.4.0</li>
</ul>


<h2>docker の apt レポジトリの変更</h2>

<p><a href="https://blog.docker.com/2015/07/new-apt-and-yum-repos/" title="New Apt and Yum Repos">New Apt and Yum Repos</a> に書いてあるように <code>docker</code> 1.8 からは新しいレポジトリにしか存在しなくなったので、 <code>/etc/apt/sources.list.d/docker.list</code> を書き換える必要がありました。</p>

<p>以下の手順で変更しました。</p>

<pre><code>sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D
sudoedit /etc/apt/sources.list.d/docker.list
sudo apt-get update
</code></pre>

<p><code>docker.list</code> は以下の内容に変更しました。</p>

<pre><code>deb https://apt.dockerproject.org/repo ubuntu-trusty main
</code></pre>

<p>パッケージ名も <code>lxc-docker</code> で始まるものから <code>docker-engine</code> に変わっています。</p>

<p><code>dokku</code> 0.3.26 ではプラグインの互換性への配慮から <code>lxc-docker-1.6.2</code> にバージョンが固定されていましたが、制限が解除されています。</p>

<p>具体的には <code>herokuish</code> 0.0.1 が <code>lxc-docker-1.6.2</code> に <code>Pre-Depends</code> していたのが、 <code>herokuish</code> 0.3.3 に上がって <code>docker-engine</code> への <code>Pre-Depends</code> に変わっています。</p>

<h2>アップグレード</h2>

<h3>sshcommand の変更</h3>

<p><code>sshcommand create</code> で <code>dokku-psql-single-container</code> プラグインが使っている <code>/home/dokku/.psql-sc/data</code> の <a href="https://github.com/Flink/dokku-psql-single-container/issues/5">owner が変わってしまう問題がある</a>ため、</p>

<pre><code>sudoedit /usr/local/bin/sshcommand
</code></pre>

<p>で</p>

<pre><code>    chown -R $USER $USERHOME
</code></pre>

<p>を</p>

<pre><code>    chown $USER $USERHOME
    chown -R $USER $USERHOME/.ssh*
</code></pre>

<p>に変更しています。</p>

<p><code>sshcommand</code> パッケージが 0.0.1 から 0.1.0 に上がって変更が戻ってしまうので、 <code>sshcommand</code> だけ先にアップグレードして、再度変更しました。</p>

<h3>パッケージのアップグレード</h3>

<pre><code>sudo apt-get dist-upgrade
</code></pre>

<p>でアップグレードしました。</p>

<p><code>dokku</code> や <code>herokuish</code> のアップグレードの他に、 <code>lxc-docker-1.6.2</code> が削除されて <code>docker-engine</code> と <code>plugn</code> が新しくインストールされます。</p>

<p>初回インストールと同様に <code>herokuish</code> の postinst で時間がかかります。</p>

<h3>不要なパッケージの削除</h3>

<p><code>lxc-docker-1.6.2</code> の完全削除と (<code>plugn</code> パッケージに置き換えられた) <code>pluginhook</code> パッケージの削除をしました。</p>

<pre><code>sudo apt-get purge lxc-docker*
sudo apt-get autoremove
</code></pre>

<h3>プラグインの再インストール</h3>

<p><code>psql-sc</code> は移行措置で <code>/var/lib/dokku/plugins/available/psql-sc</code> に移動されているのですが、有効になっていない (<code>/var/lib/dokku/plugins/enabled</code> からのシンボリックリンクがない) ので、パスが違うこともあり、再度インストールして、古い方は消すことにしました。</p>

<pre><code>sudo dokku plugin:install https://github.com/Flink/dokku-psql-single-container
sudo dokku plugin:uninstall psql-sc
</code></pre>

<p>プラグインのインストールやアンインストールは root 権限が必要なため、サーバー上で <code>sudo dokku</code> で実行する必要がありました。</p>

<p>PostgreSQL のプラグインとしては <a href="https://github.com/dokku/dokku-postgres" title="dokku postgres (beta)">dokku postgres (beta)</a> もありますが、まだ beta なのとデータ移行の問題があるため、当面は同じプラグインを使い続けることにしました。</p>

<h2>再起動して反映</h2>

<pre><code>sudo reboot
</code></pre>

<p>で再起動して、問題なく動くことを確認しました。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[さくらのVPSにdokkuをdebで入れてみた]]></title>
    <link href="http://blog.n-z.jp/blog/2015-04-20-sakura-vps-dokku.html"/>
    <updated>2015-04-20T21:54:51+09:00</updated>
    <id>http://blog.n-z.jp/blog/sakura-vps-dokku</id>
    <content type="html"><![CDATA[<p>さくらの VPS を新しく借りて初期設定をして、
dokku 0.3.17 を Debian パッケージで入れてみたので、そのメモです。</p>

<!--more-->


<h2>Ubuntu 14.04 インストール</h2>

<p><a href="https://help.sakura.ad.jp/app/answers/detail/a_id/2403" title="カスタムOSインストールガイド - Ubuntu 12.04/14.04">カスタムOSインストールガイド - Ubuntu 12.04/14.04</a>
を参考にしてインストールしました。</p>

<h2>etckeeper インストール</h2>

<p>etckeeper だけをインストールすると bzr が一緒に入って使われてしまうので、
git と一緒にインストールすることで bzr が入らないようにします。</p>

<pre><code>sudo aptitude install git etckeeper
</code></pre>

<p>次に etckeeper.conf を編集して <code>VCS="bzr"</code> の代わりに <code>VCS="git"</code> を有効にします。
ついでにコミットするときに差分をみたいので <code>GIT_COMMIT_OPTIONS="-v"</code> を設定しました。</p>

<pre><code>EDITOR=vi sudoedit /etc/etckeeper/etckeeper.conf
</code></pre>

<p>パッケージをインストールしたときに自動で初期コミットされていないので、
手動で初期コミットをしておきます。</p>

<pre><code>sudo etckeeper init
sudo etckeeper commit "Initial commit"
</code></pre>

<p>git なので <code>git gc</code> もしておきます。
<code>etckeeper vcs コマンド</code> で <code>/etc</code> ディレクトリで <code>git コマンド</code> を実行するのと同じ意味になります。</p>

<pre><code>sudo etckeeper vcs gc
</code></pre>

<h2>ufw を有効にする</h2>

<p>firewall 設定のために ufw を有効にします。</p>

<pre><code>sudo ufw enable
sudo etckeeper commit "Enable ufw"
</code></pre>

<h2>ssh を許可</h2>

<p>初期設定のために 22 番ポートを許可します。</p>

<pre><code>sudo ufw allow 22/tcp
</code></pre>

<p>リモートから ssh で入って <code>~/.ssh/authorized_keys</code> の設置などをします。</p>

<p>次にポート番号の変更や
<code>PasswordAuthentication no</code> への設定変更、
<code>PermitRootLogin</code> が <code>yes</code> 以外になっていることの確認、
<code>ChallengeResponseAuthentication no</code> の確認、
<code>AllowUsers</code> の追加をしました。</p>

<pre><code>sudo ufw delete allow 22/tcp
EDITOR=vi sudoedit /etc/ssh/sshd_config
sudo service ssh restart
sudo etckeeper commit "Setup sshd"
</code></pre>

<h2><code>~/.ssh/config</code> 設定</h2>

<p>クライアント側の <code>~/.ssh/config</code> に以下のような設定をして、
ポート番号などの指定を省略できるようにします。</p>

<p>ついでに後で使う dokku 用の設定も追加しました。</p>

<pre><code>Host サーバーのホスト名
    Hostname サーバーのIPアドレス
    User 初期ユーザー名
    Port 変更したポート番号
    IdentityFile ~/.ssh/id_rsa
    IdentitiesOnly yes
Host dokku-vps
    Hostname サーバーのIPアドレス
    User dokku
    Port 変更したポート番号
    IdentityFile ~/.ssh/id_rsa
    IdentitiesOnly yes
    RequestTTY yes
</code></pre>

<h2>nano を purge</h2>

<p>vi に慣れていて、
nano は使いにくいと感じているので、
purge しました。</p>

<pre><code>sudo aptitude purge nano
</code></pre>

<h2>IPv6 設定</h2>

<p>interfaces ファイルに以下の inet6 の設定を追加します。</p>

<pre><code>iface eth0 inet6 static
    address コントロールパネルで確認できるIPv6アドレス
    netmask 64
    gateway fe80::1
    accept_ra 0
    autoconf 0
    privext 0
    dns-nameservers コントロールパネルで確認できるDNS
</code></pre>

<p>編集して設定を反映して疎通確認をしました。</p>

<pre><code>sudoedit /etc/network/interfaces
sudo ifdown eth0 &amp;&amp; sudo ifup eth0
ping6 -c 3 www.kame.net
</code></pre>

<p><code>ifup</code> のときに <code>Waiting for DAD... Done</code> と出ましたが、
IPv6 の Duplicate Address Detection が動いているだけのようなので
問題はなさそうでした。</p>

<h2>dokku の Debian パッケージインストール</h2>

<p>dokku 0.3.18 からは Debian パッケージでのインストールがデフォルトになると
<a href="http://progrium.viewdocs.io/dokku/getting-started/install/debian" title="Debian Package Installation Notes">Debian Package Installation Notes</a>
に書いてあったので、この手順を参考にしてインストールしました。</p>

<pre><code>wget https://get.docker.io/gpg
sudo apt-key add gpg
rm gpg
wget https://packagecloud.io/gpg.key
sudo apt-key add gpg.key
rm gpg.key
echo "deb http://get.docker.io/ubuntu docker main" | sudo tee /etc/apt/sources.list.d/docker.list
echo "deb https://packagecloud.io/dokku/dokku/ubuntu/ trusty main" | sudo tee /etc/apt/sources.list.d/dokku.list
sudo apt-get update
sudo apt-get install dokku
</code></pre>

<p>なぜか
<code>Importing buildstep into docker (around 5 minutes)</code>
で 5 分どころではなく 1 時間ぐらいかかったので、
他のことをしながらのんびり待つ必要がありました。</p>

<h2>初期設定用ポート開放</h2>

<p>いきなり開放してしまうと Dokku Setup を勝手に実行されてしまう可能性があるので、
まず <code>SSH_CLIENT</code> 環境変数でサーバーに接続している自分のグローバル IP アドレスを確認して、
その IP アドレスのみから HTTP を許可しました。</p>

<pre><code>env | grep SSH
sudo ufw allow proto tcp from 接続元IPアドレス to any port 80
</code></pre>

<p>そして <code>http://サーバーのホスト名/</code> を開いて Dokku Setup を表示しました。</p>

<p>空欄になっていた <code>Public Key</code> には自分の <code>~/.ssh/id_rsa.pub</code> を貼付けました。
<code>Hostname</code> には IPv6 アドレスが表示されていたので、
<code>xip.io</code> (IP アドレスのサブドメインで IP アドレスを返してくれるサービス) を使って
<code>サーバーのIPv4アドレス.xip.io</code> (例えば <code>192.0.2.1.xip.io</code> のような感じ) を設定しました。
<code>Use virtualhost naming for apps</code> にチェックを入れて
<code>Finish Setup</code> を押しました。
ブラウザーは <code>http://progrium.viewdocs.io/dokku/application-deployment</code> にリダイレクトされました。</p>

<p>サーバー側では
<code>/home/dokku</code> 以下に設定が保存される他に、
<code>/etc/init/dokku-installer.conf</code> と <code>/etc/nginx/conf.d/dokku-installer.conf</code> が削除されるので、
<code>etckeeper commit</code> しました。</p>

<pre><code>sudo etckeeper commit "Finish Dokku Setup"
</code></pre>

<h2>HTTP ポート開放</h2>

<p>初期設定が終了したので、初期設定用のルールを削除して、
一般に開放するように変更しました。</p>

<pre><code>sudo ufw delete allow proto tcp from 接続元IPアドレス to any port 80
sudo ufw allow 80/tcp
</code></pre>

<h2>dokku の ssh を許可</h2>

<p><code>sshd_config</code> に <code>AllowUsers dokku</code> を追加しました。</p>

<pre><code>sudoedit /etc/ssh/sshd_config
sudo service ssh restart
sudo etckeeper commit "Allow ssh to dokku"
</code></pre>

<h2>ssh の接続確認</h2>

<pre><code>ssh dokku-vps
</code></pre>

<p>で dokku のヘルプが表示されるのを確認しておきます。</p>

<h2>サンプルアプリのデプロイ</h2>

<p>最小限のサンプルとして node-js-sample をデプロイします。</p>

<pre><code>git clone https://github.com/heroku/node-js-sample
cd node-js-sample
git remote add dokku-vps dokku-vps:node-js-app
git push dokku-vps master
</code></pre>

<p><code>http://node-js-app.サーバーのIPアドレス.xip.io/</code> を開いて
<code>Hello World!</code> と表示されたら成功です。</p>
]]></content>
  </entry>
  
</feed>
