<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: lxcjp | @znz blog]]></title>
  <link href="http://blog.n-z.jp/blog/categories/lxcjp/atom.xml" rel="self"/>
  <link href="http://blog.n-z.jp/"/>
  <updated>2017-07-10T21:53:10+09:00</updated>
  <id>http://blog.n-z.jp/</id>
  <author>
    <name><![CDATA[Kazuhiro NISHIYAMA]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[第11回 コンテナ型仮想化の情報交換会＠大阪に参加した]]></title>
    <link href="http://blog.n-z.jp/blog/2017-06-17-lxcjp.html"/>
    <updated>2017-06-17T13:30:00+09:00</updated>
    <id>http://blog.n-z.jp/blog/lxcjp</id>
    <content type="html"><![CDATA[<p><a href="https://ct-study.connpass.com/event/55305/">第11回 コンテナ型仮想化の情報交換会＠大阪</a>に参加してきました。</p>

<!--more-->


<p>以下、メモです。</p>

<h2>案内など</h2>

<ul>
<li>Wi-Fi はないはずだったが、提供できた</li>
<li>ハッシュタグは <a href="https://twitter.com/search?q=%23lxcjp">#lxcjp</a></li>
<li>(<a href="https://togetter.com/li/1121078">第11回 コンテナ型仮想化の情報交換会＠大阪 #lxcjp - Togetterまとめ</a>にまとめられています。質疑応答はメモ間違いもありそうなので、Togetter の方が正確そうです。)</li>
</ul>


<h2>Linuxコンテナ基礎(仮)</h2>

<ul>
<li>自己紹介</li>
<li><a href="http://gihyo.jp/admin/serial/01/linux_containers">LXCで学ぶコンテナ入門 －軽量仮想化環境を実現する技術</a></li>
<li>基礎知識</li>
<li>単独の機能があるわけではなく、 namespace とか cgroup とかを組みわせて実現されている</li>
<li>chroot とか pivot_root とか</li>
<li>speakerdeck で資料は公開予定</li>
<li>speakerdeck に元になった情報の多い資料も公開されている</li>
<li><a href="https://speakerdeck.com/tenforward/11th-ctstudy">Linux コンテナの基礎 / 11th CTStudy by tenforward</a></li>
</ul>


<h2>Haconiwa</h2>

<ul>
<li>イベントページでは「変拍子パワーポップ系コンテナランタイムHaconiwa - 夏を古くするな！」というタイトルになっていましたが、実際のタイトルは変わっていました。</li>
<li>自己紹介</li>
<li>Haconiwa とは?</li>
<li>mruby</li>
<li>ビュッフェ型コンテナランタイム</li>
<li>ビュッフェ型とは Web フレームワークでいうと Padrino</li>
<li>ruby で色々かける</li>
<li>コンテナの初期化処理とか</li>
<li>シグナルハンドラで CPU 割り当てを増減したりとか</li>
<li>Sqale という PaaS の運用のお手伝いの話</li>
<li>やりたいことが lxc などが古くて実現が難しかった</li>
<li>もしイチからやるなら?</li>
<li>コンテナ勉強会との出会い</li>
<li>RubyKaigi 2016 に応募して選考に通る前に完成</li>
<li>Haconiwa の実装方針</li>
<li>コア部分は Pure Ruby</li>
<li>システムコールは mruby gem でラップ</li>
<li>全てはプロセス</li>
<li>sample/process.rb を改変したものでデモ</li>
<li>関連技術</li>
<li>FastContainer</li>
<li><a href="http://hb.matsumoto-r.jp/entry/2016/11/11/234915">FastContainerアーキテクチャ構想</a></li>
<li>プロセスの3分類: immortal (いわゆるデーモン), short-lived (バッチとか ls とかの単独のコマンド), mortal</li>
<li>2つの中間的なものを定義する</li>
<li>mortal な存在としての FastCGI</li>
<li>inetd, xinetd</li>
<li>immortal なコンテナ: システムコンテナ, アプリケーションコンテナ, VPS として使う場合, Dokku</li>
<li>short-lived なコンテナ: アプリケーションコンテナで単一のジョブ: systemd-nspawn, FaaS</li>
<li>なぜ FastContainer か</li>
<li>負荷が上がった時: スケールアップ, スケールアウト</li>
<li>従来の VM では高速なスケールアップは非常に困難</li>
<li>コンテナでも煩雑さは残る</li>
<li>Haconiwa がスケールアップについての問題を解決</li>
<li>スケールアウトも従来の VM ではインスタンスの複製が難しいなど</li>
<li>コンテナもコストは下がるが自動化には課題がある</li>
<li><a href="http://mikeda.hatenablog.com/entry/2015/02/01/195102">負荷低すぎはもはや障害じゃないのか</a></li>
<li>FastContainer が解決するもの: スケールアウトについて インスタンスの入れ替え、増減が容易になる</li>
<li>+Haconiwa が解決するもの: 起動するコンテナ数をコンテナ自身で動的に操作させることが可能</li>
<li>Container as Code</li>
<li>その他のメリット</li>
<li>セキュリティ的観点: コンテナは、常に入れ替わるので、パッケージのアップグレードや、ミドルウェアの更新が非常になめらかに行える</li>
<li>運用的観点: どのホストであっても同じように動く。ホストをリソースプールとみなして透過的に扱える</li>
<li>FastContainer は実現できるか?</li>
<li>Scheduler: nomad</li>
<li>CoreAPI+CMDB</li>
<li>Web Proxy / Dispatcher : 起動のきっかけにもなるので Dispatcher</li>
<li>どうして Haconiwa を作ったのですか?</li>
<li>alternative rock</li>
<li>Docker はすごいが、それだけでいいのか</li>
<li>オルタナティブな存在が新しい価値観を届けるかもしれないのだ。</li>
<li>質疑応答</li>
<li>Q: どこで負荷を判別するか</li>
<li>A: cgroup の stat をベースに, veth (?) とかの負荷をみて</li>
<li>udzura cgroup で検索</li>
<li><a href="http://udzura.hatenablog.jp/entry/2017/05/02/175445">cgroup経由でシステムの利用状況を知る - CPU編</a> あたりが関連?</li>
<li>Q: mruby?</li>
<li>A: mruby の説明など</li>
<li>システムコール部分も Ruby っぽくやるために mruby という感じ?</li>
<li>Q: Web 以外の技術で FastCGI のような技術を応用することを考えているか?</li>
<li>A: nginx は tcp proxy 機能もあるので sshd とかも試している</li>
<li>Q: 具体的な利用予定は?</li>
<li>A: ロリポップ的に使えてオートスケールできるものができると良いかも?</li>
<li><a href="https://speakerdeck.com/udzura/the-alternative-container">変拍子パワーポップ系コンテナ、Haconiwa /the-alternative-container</a></li>
</ul>


<h2>休憩</h2>

<p>懇親会の追加申し込み受付案内</p>

<h2>chrootとnetwork namespaceでつくる簡易コンテナ</h2>

<ul>
<li>自己紹介</li>
<li>自作コンテナのモチベーション</li>
<li>Linux コンテナの勉強、既存コンテナ技術の再確認、手元でのネットワークテスト環境</li>
<li>chroot × network namespace × UTS namespace</li>
<li>UTS namespace は管理しやすいから</li>
<li>nginx + mackerel-agent + sshd</li>
<li>コマンドで作成</li>
<li>デモ</li>
<li>イメージ作成は docker export とか debootstrap とかが使える</li>
<li>namespace の永続化</li>
<li>/proc/[PID]/ns 配下にある特殊ファイル</li>
<li>bind マウントを使って永続化する</li>
<li>mount &ndash;bind /run/utsns /run/utsns</li>
<li>mount &ndash;make-shared /run/utsns</li>
<li>unshare -u mount &ndash;bind /proc/self/ns/uts /run/utsns/test01</li>
<li>最近の unshare コマンドなら unshare &ndash;uts=/run/utsns/test01</li>
<li>UTS namespace: 主に管理のため</li>
<li>Network の作成</li>
<li>veth 作って bridge に接続</li>
<li>Netowrk はポータビリティに影響が出やすい</li>
<li>一時期 docker が頑張ってた: VXLAN による overlay Network など</li>
<li>改善すべき箇所がたくさんある面白い分野</li>
<li>chroot 環境の作成</li>
<li>コンテナの中でも systemd を動かすと shared マウントだとコンテナの片付けの時に親の方まで一緒にアンマウントされてしまってはまるので、 rslave が必要</li>
<li>コンテナ内でのプロセスの実行: nsenter した上で chroot する</li>
<li>chroot 配下では systemd は動作しないので注意が必要</li>
<li>chroot の代わりに systemd-nspawn を使う</li>
<li>PID namespace</li>
<li>docker 1.13 で run に init オプションがついた</li>
<li>ss はネームスペースを指定できる</li>
<li>いけてない箇所</li>
<li>質疑応答</li>
<li>Q: udzuraさん: VXLAN を検証している?</li>
<li>A: 業務では使っていなくて趣味でやっている。 Open vSwitch で軽く試したことはある。</li>
</ul>


<p>veth のデモは <a href="https://asciinema.org/a/122327">Network Namespace &amp; Veth demo</a> を参照</p>

<h2>LXD 採用から運用までの顛末記</h2>

<ul>
<li>自己紹介</li>
<li>LXD 採用で、XREA、ハイパフォーマンスで安定稼働しております</li>
<li>XERA の歴史</li>
<li>古い物理サーバーから KVM</li>
<li>完全仮想化の利点と問題点</li>
<li>時代はコンテナだということで準仮想化</li>
<li>なぜ LXD か?</li>
<li>Docker: ユーザーの権限独立とネットワーク周りの問題が解決できず</li>
<li>KVM: オーバーヘッドが多くてリソースが無駄</li>
<li>OpenVZ: コンテナより遅かった</li>
<li>VMware: 考えたこともない</li>
<li>LXD: コンテナだし、リソースが有効に使えて、ヒャッハーだ！</li>
<li>LXD 採用からサービス開始まで</li>
<li>マイグレーションに伴う障害はあったが、コンテナが原因の問題はおきなかった</li>
<li>LXD の運用環境</li>
<li>ホスト Ubuntu 16.04 LTS</li>
<li>ゲスト CentOS 7</li>
<li>ZFS + ブロックデバイス</li>
<li>ホストシステム構築時のトラブル</li>
<li>オープンファイル数の上限編</li>
<li>試行錯誤した結果 <code>fs.inotify.max_user_instances</code> だった</li>
<li>その他色々上限解除</li>
<li>LXD 運用編</li>
<li>1: ユーザークォータがきかない→運用でカバー</li>
<li>2: マイグレーション時に Apache のアラートがあがる</li>
<li>原因は Apache RLimitNPROC + Potential DoS attacks</li>
<li>同じユーザーだったのが原因</li>
<li><a href="https://linuxcontainers.org/lxc/security/">https://linuxcontainers.org/lxc/security/</a></li>
<li>3: ホストのロードアベレージが急激に上昇→ZFS がボトルネック、チューニングを実施</li>
<li>4: コンテナ自体のリソース制御</li>
<li>5: (よそ見をしていたら見逃した)</li>
<li>LXD に変えてどうだったか</li>
<li>よかったという話</li>
<li>質疑応答</li>
<li>Q: ホスト間のマイグレーションは使っているか?</li>
<li>A: KVM からのマイグレーションだったので今回は使っていない。次回は使うかもしれない。</li>
<li>Q: ZFS で苦労されたという話だったが、他に選択肢はあったのか?</li>
<li>A: ZFS がデフォルトっぽい感じだったので、選んだ。ブロックデバイスかどうかというのはあったが、ブロックデバイスを選んだ。</li>
<li>Q: Docker のネットワーク周りの問題とは?</li>
<li>担当者 A: ポートとか IP とかの問題</li>
</ul>


<h2>休憩</h2>

<p>懇親会の案内</p>

<h2>Joe&rsquo;s と LXC とその運用実例と</h2>

<ul>
<li>Joe&rsquo;s Cloud Computing</li>
<li>会社紹介</li>
<li>Speaker 紹介</li>
<li>Joe&rsquo;s と LXC</li>
<li>2001年: Scientific Linux 6 with kernel 2.6.42 (後で訂正あり) + patch, zfs on fuse: 当初よりテンプレートを意識した設計</li>
<li>2010年〜: ubuntu に乗り換え, LXD への移行模索中</li>
<li>現在: 共用サーバーの半分が LXC 駆動</li>
<li>LXC と Docker</li>
<li>kvm との比較</li>
<li>LXC 運用のメリット: リソース管理がしやすい</li>
<li>運用例: zabbix 運用, 障害対応, IPブロック, プロセス管理</li>
<li>運用テストで LXC で zabbix を作成</li>
<li>nagios から移行</li>
<li>本番環境に移動</li>
<li>lxc だと rsync でコピーして起動できる</li>
<li>同一ネットワークだと監視の意味が、ということでさくらクラウドに移動</li>
<li>障害対応</li>
<li>ハードウェア障害</li>
<li>起動しなくても HDD から読み出せるならレスキュー環境で起動して吸い出してなんとかできる</li>
<li>IP ブロック</li>
<li>ホスト側の FORWARD チェインでブロック</li>
<li>FORWARD なので失敗しても取り消しやすい</li>
<li>ゲスト側が古くて ipset が使えなくてもホスト側で使えるので便利</li>
<li>プロセス管理: ホスト側から監視できる (htop とか)</li>
<li>これからの LXC ホスティング</li>
<li>デプロイ速度の向上</li>
<li>仮想コンソールの実装</li>
<li>Migration / HA の実装</li>
<li>まだまだこれから楽しめる分野</li>
<li>質疑応答</li>
<li>Q: Zabbix のバックアップ運用は?</li>
<li>A: ローカルは HDD が多いマシンがあるのでそこにとっている。リモートはホスト側で rsync と database のバックアップ</li>
<li>Q: ゲスト数はどのくらい?</li>
<li>A: 4コアで1台ぐらいのイメージ。テストでは40台ぐらいで</li>
<li>ディスクの I/O がボトルネックになる。</li>
<li>Q: 特権コンテナ?</li>
<li>A: マネージドは特権コンテナで問題ない。 VPS は非特権コンテナの予定あり。</li>
<li>Q: LXC のバージョンアップやマイグレーションでの気をつけたポイントは?</li>
<li>A: 古いサーバーのバージョン確認 kernel 2.6.42 ではなかった 2.6.32.41 LXC 0.7.4.1</li>
<li><a href="https://speakerdeck.com/samaiyou/joes-and-working-with-lxc">Joe&rsquo;s and working with LXC by samaiyou</a></li>
</ul>


<h2>Dockerコンテナ監視要素の検討</h2>

<ul>
<li>古い情報で誤解されていることがある</li>
<li><a href="http://docs.docker.jp/">http://docs.docker.jp/</a></li>
<li>動機: どのように監視をしたら良いのか?, runC と containerD, 私は私が欲しい監視システムを作りたい</li>
<li>監視と運用: システム稼働状況の把握と対策, サービスレベル</li>
<li><a href="http://www.brendangregg.com/linuxperf.html">http://www.brendangregg.com/linuxperf.html</a></li>
<li>ストレージドライバーによってパフォーマンスが大きく異なる</li>
<li>dockerd (Docker Engine), containerD</li>
<li>スケジューリング + クラスタ管理 = オーケストレーション</li>
<li>良い感じの自動化ツールはまだなさそう</li>
<li>Prometheus</li>
<li>Docker Engine とデーモンの変遷</li>
<li>v1.11〜 は dockerd - containerd - runC になっている</li>
<li><a href="https://www.opencontainers.org/">https://www.opencontainers.org/</a> - runC</li>
<li><a href="https://www.cncf.io/">https://www.cncf.io/</a> - containerd</li>
<li>2013年→2016年夏現在: dockerd デーモンの解体, 従来のコンテナ監視はメトリクス取得に集中</li>
<li>runC</li>
<li>バイナリ配布はされていないので自分で make する必要あり</li>
<li>runc のデモ</li>
<li>Docker Compose</li>
<li>fig が買収されて docker-compose になった</li>
<li>docker swarm mode, overlay network で Routing mesh, docker service create でサービス作成</li>
<li>サービス名で名前解決できる</li>
<li>監視はどうする?</li>
<li>Docker Swarm という swarm mode とは名前は似ているが別物がまだ残っているがそのうち消えるはず</li>
<li>API と SDK</li>
<li><code>curl --unix-socket /var/run/docker.sock -X GET http://v1.29/containers/json?size=true | jq "." | less</code> とかでも情報がとれる</li>
<li><a href="https://github.com/yadutaf/ctop">https://github.com/yadutaf/ctop</a></li>
<li>systemd-cgtop より便利</li>
<li>Q: containerd と runc を意識する必要はあるか?</li>
<li>A: 普段はあまり意識する必要はない</li>
<li>Q: ホスティングサービスでは docker を選ばなかったが、お客様から見えない部分では使いたい</li>
<li>A: さくらの VPS のコントロールパネルなどで docker を使っている</li>
<li>Q: kubernetes とかは?</li>
<li>A: 用途が違うので使い分ければ良いのでは。使いたいものを使えば良いのでは。</li>
<li>ユーザー目線で使いやすいのは swarm mode とか</li>
<li>リソースを有効活用したいのなら mesos とか</li>
<li>kubernetes はあまり詳しくない</li>
<li>mesos は API があって使いやすいらしい</li>
<li>ctop は同じ名前で別のものがある</li>
</ul>


<h2>感想</h2>

<p>lxc/lxd の話がきけてよかったです。Web 上ではあまり見かけないと思っていましたが、使っているところではちゃんと使っていて、安定して運用できていると聞いて、用途によっては使ってみたいと思いました。</p>

<p>Docker の話も普段 Dokku などで使っていて、なんか色々変わっていっているとは感じていましたが、まとまった話として聞けてよかったです。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第7回 コンテナ型仮想化の情報交換会＠大阪に参加しました]]></title>
    <link href="http://blog.n-z.jp/blog/2015-06-20-ct-study-7-osaka.html"/>
    <updated>2015-06-20T14:30:00+09:00</updated>
    <id>http://blog.n-z.jp/blog/ct-study-7-osaka</id>
    <content type="html"><![CDATA[<p><a href="http://ct-study.connpass.com/event/15121/" title="第7回 コンテナ型仮想化の情報交換会＠大阪">第7回 コンテナ型仮想化の情報交換会＠大阪</a>
に参加しました。</p>

<!--more-->


<p>入り口に pepper くんがいました。
懇親会でも人気でした。</p>

<p>以下メモです。</p>

<h2>いまさら聞けない Linux コンテナの基礎</h2>

<ul>
<li><a href="https://speakerdeck.com/tenforward/jin-sarawen-kenai-linux-kontenafalseji-chu-2015-06-20">https://speakerdeck.com/tenforward/jin-sarawen-kenai-linux-kontenafalseji-chu-2015-06-20</a></li>
<li>cgroup などの Linux コンテナの基礎についての話でした。</li>
<li><a href="http://blog.kazuhooku.com/2015/05/jailing-chroot-jail.html" title="jailing - chroot jailを構築・運用するためのスクリプトを書いた">jailing - chroot jailを構築・運用するためのスクリプトを書いた</a></li>
<li><a href="http://criu.org/">http://criu.org/</a></li>
<li>overlayfs</li>
</ul>


<h2>いまさら聞けない Linux コンテナの基礎 (後半)</h2>

<ul>
<li>いろいろと namespace のデモ</li>
<li>kernel のバージョンの他にも unshare コマンドが入っている util-linux のバージョンも重要</li>
<li>最近の systemd だと <code>mount --make-shared /</code> 相当になっている</li>
<li>いろいろなコンテナ関係の紹介</li>
<li><a href="https://github.com/mhiramat/mincs">https://github.com/mhiramat/mincs</a></li>
<li>LXC のデモ (lxc-なんとか コマンド)</li>
<li>LXD のデモ (lxc コマンド)</li>
</ul>


<h2>dokku を本番環境で使ってみた話</h2>

<ul>
<li>自分の発表でした。</li>
<li><a href="http://slide.rabbit-shocker.org/authors/znz/dokku-201506/">http://slide.rabbit-shocker.org/authors/znz/dokku-201506/</a></li>
<li>Heroku を使っていない理由は VPS の方が安い</li>
<li>apache+passenger だと ruby や passenger のバージョンアップが辛かった</li>
</ul>


<h2>VIMAGE を使ってみた話</h2>

<ul>
<li>whois owatan.jp</li>
<li>ConoHa は 17 個の IPv6 アドレスが付いてくる</li>
<li>epair</li>
</ul>


<h2>アンケート</h2>

<ul>
<li><a href="https://goo.gl/g75FNJ">https://goo.gl/g75FNJ</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第5回 コンテナ型仮想化の情報交換会＠大阪に参加しました]]></title>
    <link href="http://blog.n-z.jp/blog/2014-11-14-ct-study-osaka-5.html"/>
    <updated>2014-11-14T19:00:32+09:00</updated>
    <id>http://blog.n-z.jp/blog/ct-study-osaka-5</id>
    <content type="html"><![CDATA[<p><a href="http://ct-study.connpass.com/event/9068/" title="第5回 コンテナ型仮想化の情報交換会＠大阪">第5回 コンテナ型仮想化の情報交換会＠大阪</a>
に参加しました。</p>

<!--more-->


<p>以下メモです。</p>

<h2>いまさら聞けない Docker</h2>

<ul>
<li>前半はさくらインターネットの話でした。</li>
<li>仮想環境を動かす基盤として専用サーバがまた増えているらしいというのが興味深いと思いました。</li>
<li>後半は docker の基本についての話でした。</li>
<li><a href="http://www.slideshare.net/kunihirotanaka1/immutable-infrastructuredockercontainerstudyosaka20141114">http://www.slideshare.net/kunihirotanaka1/immutable-infrastructuredockercontainerstudyosaka20141114</a></li>
</ul>


<h2>Docker Registry入門</h2>

<ul>
<li><a href="https://github.com/docker/docker-registry">https://github.com/docker/docker-registry</a> の話</li>
<li>起動は簡単</li>
<li>pip でインストールも可能 (公式の <a href="https://github.com/docker/docker-registry/blob/master/Dockerfile">Dockerfile</a> 参照)</li>
<li>設定は <a href="https://github.com/docker/docker-registry/blob/master/config/config_sample.yml">config_sample.yml</a> などを参照</li>
<li>docker-registry-ui, docker-registry-web で検索すると非公式の Web UI が出てくる</li>
<li>ミラーリングに使える

<ul>
<li>docker コマンドで <code>--registry-mirror</code> オプション</li>
<li>private registry では <code>MIRROR_SOURCE</code> を指定</li>
</ul>
</li>
</ul>


<h2>Linuxコンテナの基本と最新情報</h2>

<ul>
<li>namespace と cgroup</li>
<li>sane_behavior オプション</li>
<li>CRIU のデモ</li>
</ul>


<h2>LT</h2>

<p>LT では boot2docker について話しました。
他の発表者も含めて、特に 5 分という制限はなく、緩い感じで発表していました。</p>

<iframe src="http://slide.rabbit-shocker.org/authors/znz/boot2docker-upgrade/viewer.html"
        width="640" height="524"
        frameborder="0"
        marginwidth="0"
        marginheight="0"
        scrolling="no"
        style="border: 1px solid #ccc; border-width: 1px 1px 0; margin-bottom: 5px"
        allowfullscreen> </iframe>


<div style="margin-bottom: 5px">
  <a href="http://slide.rabbit-shocker.org/authors/znz/boot2docker-upgrade/" title="boot2docker upgrade">boot2docker upgrade</a>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第3回 コンテナ型仮想化の情報交換会＠大阪 (コンテナ型VMや関連するカーネル等の技術が話題の勉強会)に参加した]]></title>
    <link href="http://blog.n-z.jp/blog/2014-04-12-lxcjp.html"/>
    <updated>2014-04-12T22:23:56+09:00</updated>
    <id>http://blog.n-z.jp/blog/lxcjp</id>
    <content type="html"><![CDATA[<p><a href="http://atnd.org/events/46446">第3回 コンテナ型仮想化の情報交換会＠大阪 (コンテナ型VMや関連するカーネル等の技術が話題の勉強会)</a>
に参加してきました。</p>

<!--more-->


<h2>全体の感想</h2>

<p>全体的には LXC や Docker に限らず、
Hyper-V 上での FreeBSD jail の話や Vagrant や CircleCI (LXC を使っている) などの話もあって、面白かったです。</p>

<h2>会場</h2>

<p>ちょっと早めに出発して、梅田から難波橋を通って堺筋を通って会場まで歩いていきました。
場所もわかりやすくて交差点の名前と目的地のビルの名前をちゃんとチェックしていれば迷わずにたどり着けました。</p>

<p>会場無線 LAN があったのですが、
最初に接続した MacBook Air は問題なく繋がっていたのですが、
後から追加でつなごうとした iPod touch は無線 LAN 自体は繋がっているのに APIPA の IP アドレスになっていて、
DHCP の割り当て IP アドレスが足りなかったのではないかと思いました。</p>

<h2>LXC</h2>

<p>いろいろと知らないことも多くて勉強になったのですが、特に <code>veth</code> と <code>macvlan</code> の違いがよくわかっていなかったので、
<code>veth</code> は作成しただけだと通信に使えなくてペアの片方をネットワークネームスペースに入れないと使えないというコンテナ用の機能で、
<code>macvlan</code> は物理 NIC に別 MAC アドレスを付けて使うもの、
というのがわかって良かったです。</p>

<p>LXC という言葉がさすものが「カーネルのコンテナ機能」のときと「<code>lxc-start</code> などの LXC のユーザーランド」のことがある、というのは気をつける必要があると思いました。
たとえば Docker 0.9 で LXC への依存がなくなったというのは <code>lxc-start</code> などを使わなくなって、システムコールを <code>libcontainer</code> という別ライブラリで直接呼んでカーネルのコンテナ機能を使うようになったなど。</p>

<h2>FreeBSD jail</h2>

<p>jail については存在は知っていたのですが、使ったことはなかったので、そういうものなのかと思ってみていました。</p>

<h2>VagrantユーザのためのDocker入門</h2>

<p>途中の質問にあった container と image の違いで
<a href="http://docs.docker.io/en/latest/terms/image/">http://docs.docker.io/en/latest/terms/image/</a>
に書いてある
<code>In Docker terminology, a read-only Layer is called an image. An image never changes.</code>
が根拠だと思うのですが、
イメージはコンテナに名前をつけてリードオンリーにしたもの、という説明で
今まで曖昧にしていた違いがちゃんとわかったように思いました。</p>

<p>このブログの Docker 関連記事の中で一番人気の
<a href="http://blog.n-z.jp/blog/2013-12-24-docker-rm.html">Dockerで不要になったコンテナやイメージを削除する</a>
で割とコンテナとイメージを曖昧な感じで書いているのは、はっきりとは区別できていなかったからでした。</p>

<p>Vagrant との使い分けも実際に両方使っている人の話だったので、非常に参考になりました。
基本的には Vagrant も Docker も開発環境として使うという話でした。</p>

<h2>Docker運用の観点からみたLXC</h2>

<p>いろいろな話がありました。
基本的には production 環境として使う話でした。</p>

<h2>Docker の layer 数制限の話</h2>

<p>休憩時間に話をしていたのですが layer の制限が 42 から 127 に増えたのは
<a href="https://github.com/dotcloud/docker/pull/2897">Increase max image depth to 127</a>
からで、
理由は aufs の方で <code>CONFIG_AUFS_BRANCH_MAX_127</code> という設定を <code>y</code> にすると
制限が 127 になるから、ということのようでした。</p>

<p>懇親会の時にも話が出たのですが、
<code>RUN</code> ごとにキャッシュがきくので、
基本的には <code>Dockerfile</code> の変更を試している間は <code>RUN</code> ごとに細かくコマンドを並べて試行錯誤して、
出来上がったら <code>&amp;&amp;</code> でつなげて一行の <code>RUN</code> にまとめるのが良さそう、
という話でした。</p>

<p>関連する話としては aufs の layer が重なっているのを git で merge するときのようにまとめたい、
という意見に対して、
<code>Dockerfile</code> をマスター (主) として扱って、
イメージは捨てていつでも作り直せるもの (従) として扱う方が良い、
だから、無理に aufs の差分イメージの中を直接いじってマージしようとせずに
<code>Dockerfile</code> から再生成した方が良い、
という話がありました。</p>

<h2>CircleCI, Cucumber-Chef</h2>

<p><code>CircleCI</code> と <code>ngrok</code> を組み合わせて、
rebuild.fm で話があったブランチごとよりもさらに富豪的に、
コミットごとに時間制限付きのサーバーを動かす話などがありました。</p>

<p><code>CircleCI</code> の1時間という時間制限 (SSH で入れるようにして動かすと30分) と
ローカルサーバーを外に公開できる <code>ngrok</code> というものを組み合わせて
コミットごとに一定時間サーバーを動かしているという話でした。</p>

<h2>終わり</h2>

<p>他の発表の時間に余裕を持たせていて、パネルディスカッションはありませんでした。</p>
]]></content>
  </entry>
  
</feed>
