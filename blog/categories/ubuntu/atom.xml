<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ubuntu | @znz blog]]></title>
  <link href="http://blog.n-z.jp/blog/categories/ubuntu/atom.xml" rel="self"/>
  <link href="http://blog.n-z.jp/"/>
  <updated>2016-10-07T22:26:33+09:00</updated>
  <id>http://blog.n-z.jp/</id>
  <author>
    <name><![CDATA[Kazuhiro NISHIYAMA]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[lsで丸数字で始まるファイル名の順番が変だった]]></title>
    <link href="http://blog.n-z.jp/blog/2016-08-30-lc-collate-again.html"/>
    <updated>2016-08-30T22:58:34+09:00</updated>
    <id>http://blog.n-z.jp/blog/lc-collate-again</id>
    <content type="html"><![CDATA[<p>OS X で丸数字から始まるファイル名のファイルが入ったフォルダーを Finder で開くと丸数字の数字順に並んでいたのに、 <code>ls</code> で表示すると別の順番になっていたので原因を調べてみました。</p>

<!--more-->


<h2>動作確認環境</h2>

<ul>
<li>OS X Yosemite (10.10.5)</li>
<li>ls, uniq バージョン不明</li>
<li>sort (GNU coreutils) 5.93</li>
</ul>


<h2>動作確認</h2>

<p>Unicode 的に連続している 丸1 から 丸20 までのファイル名のファイルと、それに適当な ASCII の数字をつけたファイル名のファイルを作成して <code>ls</code> で表示してみました。</p>

<pre><code>%  touch $(ruby -e 'puts ("\u{2460}".."\u{2473}").to_a')
%  touch $(ruby -e 'puts ("\u{2460}".."\u{2473}").to_a.shuffle.map.with_index{|e,i|"#{e}#{i}"}')
%  ls
①      ⑤      ⑨      ⑬      ⑰      ⑧0     ⑲12    ⑮16    ⑥2     ⑬6
②      ⑥      ⑩      ⑭      ⑱      ⑤1     ⑱13    ⑳17    ④3     ⑫7
③      ⑦      ⑪      ⑮      ⑲      ⑨10    ②14    ⑪18    ⑭4     ⑦8
④      ⑧      ⑫      ⑯      ⑳      ⑯11    ⑩15    ③19    ⑰5     ①9
</code></pre>

<p>丸数字のみだと数字順に並んでいるのに、後ろに ASCII の数字をつけた部分は ASCII の数字順に並んでいます。
(numeric sort じゃないので 1,10,2 という順番になっているのがちょっとわかりにくいかもしれませんが。)</p>

<h2>Jessie での動作確認</h2>

<p>比較のために Debian GNU/Linux 8.5 (jessie) でも同様のファイルを作成して <code>ls</code> してみると丸数字のみのところもバラバラの順番でした。
何度か実行しても同じ結果なので、ランダムというわけではなくなんらかの基準がありそうですが、どういう順番なのかはわかりませんでした。</p>

<pre><code>% ls
⑧  ⑯  ⑥  ⑬  ⑫  ⑦  ①  ③  ⑮  ⑰  ④0  ⑨10  ⑳12  ⑫14  ⑭16  ①18  ⑩2  ⑥4  ⑯6  ⑱8
⑱  ⑩  ⑨  ⑪  ⑲  ⑤  ②  ④  ⑭  ⑳  ⑪1  ⑦11  ⑲13  ⑬15  ⑮17  ⑧19  ⑤3  ②5  ⑰7  ③9
</code></pre>

<h2>LC_COLLATE</h2>

<p><a href="http://blog.n-z.jp/blog/2013-10-31-lc-collate-uniq.html" title="LC_COLLATEの問題でuniqで丸数字が同一視されてしまう">LC_COLLATEの問題でuniqで丸数字が同一視されてしまう</a>のと同じ話かと思って、 <code>sort</code> や <code>uniq</code> も試してみたところ、同じ話のように見えました。
OS X では locale data が GNU/Linux とは違うようで <code>uniq</code> で同一視されるということは起きませんでした。</p>

<pre><code>% rbenv exec irb -r irb/completion --simple-prompt
&gt;&gt; IO.popen("uniq", "r+"){|io| io.puts ("\u{2460}".."\u{2473}").to_a; io.close_write; puts io.read }
①
②
③
④
⑤
⑥
⑦
⑧
⑨
⑩
⑪
⑫
⑬
⑭
⑮
⑯
⑰
⑱
⑲
⑳
=&gt; nil
&gt;&gt; IO.popen("sort", "r+"){|io| io.puts ("\u{2460}".."\u{2473}").to_a.shuffle; io.close_write; puts io.read }
①
②
③
④
⑤
⑥
⑦
⑧
⑨
⑩
⑪
⑫
⑬
⑭
⑮
⑯
⑰
⑱
⑲
⑳
=&gt; nil
&gt;&gt; IO.popen("sort", "r+"){|io| io.puts ("\u{2460}".."\u{2473}").to_a.shuffle.map.with_index{|e,i|"#{e}#{i}"}; io.close_write; puts io.read }
⑬0
⑥1
⑰10
⑱11
⑤12
⑮13
⑦14
④15
③16
⑪17
⑩18
①19
⑧2
⑲3
⑫4
⑳5
⑭6
②7
⑯8
⑨9
=&gt; nil
&gt;&gt; IO.popen({"LC_COLLATE"=&gt;"C"}, "sort", "r+"){|io| io.puts ("\u{2460}".."\u{2473}").to_a.shuffle.map.with_index{|e,i|"#{e}#{i}"}; io.close_write; puts io.read }
①6
②5
③0
④16
⑤19
⑥18
⑦7
⑧2
⑨8
⑩3
⑪12
⑫15
⑬4
⑭9
⑮14
⑯10
⑰1
⑱17
⑲13
⑳11
=&gt; nil
</code></pre>

<h2>一番自然に感じる並び順</h2>

<p>ruby の sort での結果は <code>LC_COLLATE=C</code> と同じように文字コード順になり、意味自然な並び順に感じました。
<code>LC_COLLATE=C ls</code> も同じ並び順でした。</p>

<pre><code>&gt;&gt; puts Dir['*'].sort
①
①9
②
②14
③
③19
④
④3
⑤
⑤1
⑥
⑥2
⑦
⑦8
⑧
⑧0
⑨
⑨10
⑩
⑩15
⑪
⑪18
⑫
⑫7
⑬
⑬6
⑭
⑭4
⑮
⑮16
⑯
⑯11
⑰
⑰5
⑱
⑱13
⑲
⑲12
⑳
⑳17
=&gt; nil
</code></pre>

<pre><code>% LC_COLLATE=C ls
①      ③      ⑤      ⑦      ⑨      ⑪      ⑬      ⑮      ⑰      ⑲
①9     ③19    ⑤1     ⑦8     ⑨10    ⑪18    ⑬6     ⑮16    ⑰5     ⑲12
②      ④      ⑥      ⑧      ⑩      ⑫      ⑭      ⑯      ⑱      ⑳
②14    ④3     ⑥2     ⑧0     ⑩15    ⑫7     ⑭4     ⑯11    ⑱13    ⑳17
</code></pre>

<h2>Finder での並び順</h2>

<p>Finder での並び順は <code>LC_COLLATE=C</code> での結果と同じかと思いきや、丸1 の後に 丸10 がきて、丸19, 丸2, 丸20, 丸3 のように並んでいたので、独特な感じでした。</p>

<pre><code>①
①9
⑩
⑩15
⑪
⑪18
⑫
⑫7
⑬
⑬6
⑭
⑭4
⑮
⑮16
⑯
⑯11
⑰
⑰5
⑱
⑱13
⑲
⑲12
②
②14
⑳
⑳17
③
③19
④
④3
⑤
⑤1
⑥
⑥2
⑦
⑦8
⑧
⑧0
⑨
⑨10
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ubuntuで「ハッシュサムが適合しません」で backports のパッケージが入ってしまって大変だった]]></title>
    <link href="http://blog.n-z.jp/blog/2016-05-26-ubuntu-hash-mismatch.html"/>
    <updated>2016-05-26T22:23:35+09:00</updated>
    <id>http://blog.n-z.jp/blog/ubuntu-hash-mismatch</id>
    <content type="html"><![CDATA[<p><code>jp.archive.ubuntu.com</code> のミラーが不完全だったのか、「ハッシュサムが適合しません」という警告が出て、そのまま <code>sudo aptitude full-upgrade -DV</code> をしたら backports のパッケージが入ってしまって大変な思いをしたという話です。</p>

<!--more-->


<h2>環境</h2>

<ul>
<li>Ubuntu 14.04.4 LTS</li>
</ul>


<h2>警告</h2>

<p><code>sudo aptitude update</code> で以下のような警告とエラーが出ていました。</p>

<pre><code>W: http://jp.archive.ubuntu.com/ubuntu/dists/trusty-updates/main/source/Sources を取得できませんでした: ハッシュサムが適合しません
W: http://jp.archive.ubuntu.com/ubuntu/dists/trusty-updates/universe/source/Sources を取得できませんでした: ハッシュサムが適合しません
W: http://jp.archive.ubuntu.com/ubuntu/dists/trusty-updates/main/binary-amd64/Packages を取得できませんでした: ハッシュ サムが適合しません
W: http://jp.archive.ubuntu.com/ubuntu/dists/trusty-updates/universe/binary-amd64/Packages を取得できませんでした: ハッ シュサムが適合しません
W: http://jp.archive.ubuntu.com/ubuntu/dists/trusty-updates/main/binary-i386/Packages を取得できませんでした: ハッシュサムが適合しません
W: http://jp.archive.ubuntu.com/ubuntu/dists/trusty-updates/universe/binary-i386/Packages を取得できませんでした: ハッシュサムが適合しません
E: 一部のインデックスファイルのダウンロードに失敗しました。無視されたか古いものを代わりに利用しています。
E: パッケージキャッシュを再構築できませんでした
</code></pre>

<h2>不用意なアップグレード</h2>

<p>あまり気にせず、セキュリティアップデートがあれば更新しておこうと思って、 <code>sudo aptitude full-upgrade -DV</code> を実行してみたところ、以下のパッケージが更新対象に上がりました。</p>

<p>証明書の設定で <code>SSLCertificateChainFile</code> が必要なくなる 2.4.8 をまたぐので、ちょっと危険な気はしましたが、個人のサーバーなので多少の停止時間は構わないだろうと思ってアップグレードしてしまいました。</p>

<pre><code>以下のパッケージが更新されます:
  apache2 [2.4.7-1ubuntu4.9 -&gt; 2.4.10-1ubuntu1.1~ubuntu14.04.1]
  apache2-bin [2.4.7-1ubuntu4.9 -&gt; 2.4.10-1ubuntu1.1~ubuntu14.04.1]
  apache2-data [2.4.7-1ubuntu4.9 -&gt; 2.4.10-1ubuntu1.1~ubuntu14.04.1]
  apache2-dev [2.4.7-1ubuntu4.9 -&gt; 2.4.10-1ubuntu1.1~ubuntu14.04.1]
  apache2-mpm-prefork [2.4.7-1ubuntu4.9 -&gt; 2.4.10-1ubuntu1.1~ubuntu14.04.1]
  apache2-utils [2.4.7-1ubuntu4.9 -&gt; 2.4.10-1ubuntu1.1~ubuntu14.04.1]
  libcgmanager0 [0.24-0ubuntu7.5 -&gt; 0.39-2ubuntu2~ubuntu14.04.1]
</code></pre>

<h2>backports のパッケージだった</h2>

<p>ダウンロード中の URL を見て backports のパッケージが入ってしまっている、と気づいたのですが、手遅れで止める間もなく上がってしまいました。</p>

<pre><code>% apt-cache policy apache2
apache2:
  インストールされているバージョン: 2.4.7-1ubuntu4.9
  候補:               2.4.10-1ubuntu1.1~ubuntu14.04.1
  バージョンテーブル:
     2.4.10-1ubuntu1.1~ubuntu14.04.1 0
        100 http://jp.archive.ubuntu.com/ubuntu/ trusty-backports/main amd64 Packages
 *** 2.4.7-1ubuntu4.9 0
        100 /var/lib/dpkg/status
     2.4.7-1ubuntu4.5 0
        500 http://security.ubuntu.com/ubuntu/ trusty-security/main amd64 Packages
     2.4.7-1ubuntu4 0
        500 http://jp.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
</code></pre>

<h2>ダウングレード失敗</h2>

<p><code>/etc/apt/preferences</code> を設定してダウングレードすることにしました。</p>

<p>まず以下を試してみたところ、 <code>base-files</code> などを含む大量のパッケージがダウングレード対象になってしまったので中断しました。</p>

<pre><code>Package: *
Pin: release a=trusty
Pin-Priority: 1001
</code></pre>

<p><code>apt-cache policy</code> で確認してみると、現在のバージョンのインストール候補がなくなっているのが原因の一つでした。</p>

<pre><code>% apt-cache policy base-files
base-files:
  インストールされているバージョン: 7.2ubuntu5.4
  候補:               7.2ubuntu5
  バージョンテーブル:
 *** 7.2ubuntu5.4 0
        100 /var/lib/dpkg/status
     7.2ubuntu5 0
       1001 http://ubuntutym.u-toyama.ac.jp/ubuntu/ trusty/main amd64 Packages
</code></pre>

<p>そこで、 <code>/etc/apt/sources.list</code> の末尾に <code>archive.ubuntu.com</code> を一時的に追加することにしました。</p>

<pre><code>deb http://archive.ubuntu.com/ubuntu/ trusty main restricted universe multiverse
#deb-src http://archive.ubuntu.com/ubuntu/ trusty main restricted universe multiverse
deb http://archive.ubuntu.com/ubuntu/ trusty-updates main restricted universe multiverse
deb-src http://archive.ubuntu.com/ubuntu/ trusty-updates main restricted universe multiverse
</code></pre>

<p>すると <code>trusty-updates</code> も出てきたのですが、 priority が 500 になって期待した値になっていませんでした。</p>

<pre><code>% apt-cache policy base-files
base-files:
  インストールされているバージョン: 7.2ubuntu5.4
  候補:               7.2ubuntu5
  バージョンテーブル:
 *** 7.2ubuntu5.4 0
        500 http://archive.ubuntu.com/ubuntu/ trusty-updates/main amd64 Packages
        100 /var/lib/dpkg/status
     7.2ubuntu5 0
       1001 http://jp.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
       1001 http://archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
</code></pre>

<p>次に <code>n=trusty</code> を試してみたところ、 <code>backports</code> も priority が 1001 になってしまってダウングレードできませんでした。</p>

<pre><code>Package: *
Pin: release n=trusty
Pin-Priority: 1001
</code></pre>

<pre><code>% apt-cache policy base-files
base-files:
  インストールされているバージョン: 7.2ubuntu5.4
  候補:               7.2ubuntu5.4
  バージョンテーブル:
 *** 7.2ubuntu5.4 0
       1001 http://archive.ubuntu.com/ubuntu/ trusty-updates/main amd64 Packages
        100 /var/lib/dpkg/status
     7.2ubuntu5 0
       1001 http://jp.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
       1001 http://archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
% apt-cache policy apache2
apache2:
  インストールされているバージョン: 2.4.10-1ubuntu1.1~ubuntu14.04.1
  候補:               2.4.10-1ubuntu1.1~ubuntu14.04.1
  バージョンテーブル:
 *** 2.4.10-1ubuntu1.1~ubuntu14.04.1 0
       1001 http://jp.archive.ubuntu.com/ubuntu/ trusty-backports/main amd64 Packages
        100 /var/lib/dpkg/status
     2.4.7-1ubuntu4.9 0
       1001 http://archive.ubuntu.com/ubuntu/ trusty-updates/main amd64 Packages
     2.4.7-1ubuntu4.5 0
       1001 http://security.ubuntu.com/ubuntu/ trusty-security/main amd64 Packages
     2.4.7-1ubuntu4 0
       1001 http://jp.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
       1001 http://archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
</code></pre>

<h2>ダウングレード成功</h2>

<p>最終的に <code>a=trusty-updates</code> と <code>a=trusty-security</code> も追加することでダウングレードできました。</p>

<pre><code>Package: *
Pin: release a=trusty
Pin-Priority: 1001

Package: *
Pin: release a=trusty-updates
Pin-Priority: 1001

Package: *
Pin: release a=trusty-security
Pin-Priority: 1001
</code></pre>

<pre><code>% apt-cache policy apache2
apache2:
  インストールされているバージョン: 2.4.10-1ubuntu1.1~ubuntu14.04.1
  候補:               2.4.7-1ubuntu4.9
  バージョンテーブル:
 *** 2.4.10-1ubuntu1.1~ubuntu14.04.1 0
        100 http://jp.archive.ubuntu.com/ubuntu/ trusty-backports/main amd64 Packages
        100 /var/lib/dpkg/status
     2.4.7-1ubuntu4.9 0
       1001 http://archive.ubuntu.com/ubuntu/ trusty-updates/main amd64 Packages
     2.4.7-1ubuntu4.5 0
       1001 http://security.ubuntu.com/ubuntu/ trusty-security/main amd64 Packages
     2.4.7-1ubuntu4 0
       1001 http://jp.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
       1001 http://archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
% apt-cache policy base-files
base-files:
  インストールされているバージョン: 7.2ubuntu5.4
  候補:               7.2ubuntu5.4
  バージョンテーブル:
 *** 7.2ubuntu5.4 0
       1001 http://archive.ubuntu.com/ubuntu/ trusty-updates/main amd64 Packages
        100 /var/lib/dpkg/status
     7.2ubuntu5 0
       1001 http://jp.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
       1001 http://archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
</code></pre>

<h2>backports のコメントアウト</h2>

<p>backports のパッケージは使っていなかったので、この後 backports の apt-line はコメントアウトしました。</p>

<h2>まとめ</h2>

<p><code>apt</code> の <code>update</code> に失敗した時はアップグレード対象のパッケージに注意しましょう。</p>

<p>ダウングレードする時は <code>apt_preferences(5)</code> の <code>Pin</code> 設定をうまく工夫しましょう。</p>

<p>backports のパッケージが不要なら backports の apt-line を追加するのは避けましょう。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[letsencrypt-auto の自動アップグレードを止めて手動でアップグレード]]></title>
    <link href="http://blog.n-z.jp/blog/2016-04-07-letsencrypt.html"/>
    <updated>2016-04-07T23:00:00+09:00</updated>
    <id>http://blog.n-z.jp/blog/letsencrypt</id>
    <content type="html"><![CDATA[<p><code>/etc/cron.daily/letsencrypt</code> は <code>root</code> 権限で実行されるため、そこで自動アップグレードがかかるとファイルのオーナーが <code>root</code> になってしまうかもしれないと思ったので、自動更新を止めて手動でアップグレードするようにしました。</p>

<!--more-->


<h2>自動アップグレードを止めた <code>/etc/cron.daily/local-letsencrypt</code></h2>

<p><a href="http://blog.n-z.jp/blog/2016-03-06-letsencrypt.html">前回の記事</a> からの差分としては <a href="http://packages.debian.org/debianutils">debianutils</a> の <code>savelog</code> でログをローテートして、証明書の有効期限の 90 日分残すようにしたのと、 <code>--no-self-upgrade</code> をつけて自動アップグレードを止めたことです。
それから、パッケージで入れたものではないということを明示するために <code>local</code> という文字列を入れたファイル名に変更しました。</p>

<pre><code class="bash /etc/cron.daily/local-letsencrypt">#!/bin/sh
LOGFILE=/var/log/letsencrypt/renew.log
if [ -f "$LOGFILE" ]; then
    /usr/bin/savelog -c 90 -q "$LOGFILE"
fi
if ! /home/hoge/letsencrypt/letsencrypt-auto renew --no-self-upgrade &gt; "$LOGFILE" 2&gt;&amp;1 ; then
    echo Automated renewal failed:
    cat "$LOGFILE"
    exit 1
fi
apachectl graceful
service postfix reload &gt;/dev/null
service dovecot reload
</code></pre>

<h2>手動アップグレードしたログ</h2>

<p>手動実行したところ、ちょうど 0.4.2 から 0.5.0 へのアップグレードが実行されました。</p>

<pre><code>% ~/letsencrypt/letsencrypt-auto --help
Checking for new version...
Upgrading letsencrypt-auto 0.4.2 to 0.5.0...
Replacing letsencrypt-auto...
   sudo cp -p /home/hoge/letsencrypt/letsencrypt-auto /tmp/user/1000/tmp.MclJH3TO68/letsencrypt-auto.permission-clone
   sudo cp /tmp/user/1000/tmp.MclJH3TO68/letsencrypt-auto /tmp/user/1000/tmp.MclJH3TO68/letsencrypt-auto.permission-clone
   sudo mv -f /tmp/user/1000/tmp.MclJH3TO68/letsencrypt-auto.permission-clone /home/hoge/letsencrypt/letsencrypt-auto
Creating virtual environment...
Installing Python packages...
Installation succeeded.
Requesting root privileges to run letsencrypt...
   sudo /home/hoge/.local/share/letsencrypt/bin/letsencrypt --help

  letsencrypt-auto [SUBCOMMAND] [options] [-d domain] [-d domain] ...

The Let's Encrypt agent can obtain and install HTTPS/TLS/SSL certificates.  By
default, it will attempt to use a webserver both for obtaining and installing
the cert. Major SUBCOMMANDS are:

  (default) run        Obtain &amp; install a cert in your current webserver
  certonly             Obtain cert, but do not install it (aka "auth")
  install              Install a previously obtained cert in a server
  renew                Renew previously obtained certs that are near expiry
  revoke               Revoke a previously obtained certificate
  rollback             Rollback server configuration changes made during install
  config_changes       Show changes made to server config during installation
  plugins              Display information about installed plugins

Choice of server plugins for obtaining and installing cert:

  --apache          Use the Apache plugin for authentication &amp; installation
  --standalone      Run a standalone webserver for authentication
  (nginx support is experimental, buggy, and not installed by default)
  --webroot         Place files in a server's webroot folder for authentication

OR use different plugins to obtain (authenticate) the cert and then install it:

  --authenticator standalone --installer apache

More detailed help:

  -h, --help [topic]    print this message, or detailed help on a topic;
                        the available topics are:

   all, automation, paths, security, testing, or any of the subcommands or
   plugins (certonly, install, nginx, apache, standalone, webroot, etc)
</code></pre>

<h2>アップグレードがないときのログ</h2>

<pre><code>% ~/letsencrypt/letsencrypt-auto --help
Checking for new version...
Requesting root privileges to run letsencrypt...
   sudo /home/hoge/.local/share/letsencrypt/bin/letsencrypt --help

  letsencrypt-auto [SUBCOMMAND] [options] [-d domain] [-d domain] ...

The Let's Encrypt agent can obtain and install HTTPS/TLS/SSL certificates.  By
default, it will attempt to use a webserver both for obtaining and installing
the cert. Major SUBCOMMANDS are:

  (default) run        Obtain &amp; install a cert in your current webserver
  certonly             Obtain cert, but do not install it (aka "auth")
  install              Install a previously obtained cert in a server
  renew                Renew previously obtained certs that are near expiry
  revoke               Revoke a previously obtained certificate
  rollback             Rollback server configuration changes made during install
  config_changes       Show changes made to server config during installation
  plugins              Display information about installed plugins

Choice of server plugins for obtaining and installing cert:

  --apache          Use the Apache plugin for authentication &amp; installation
  --standalone      Run a standalone webserver for authentication
  (nginx support is experimental, buggy, and not installed by default)
  --webroot         Place files in a server's webroot folder for authentication

OR use different plugins to obtain (authenticate) the cert and then install it:

  --authenticator standalone --installer apache

More detailed help:

  -h, --help [topic]    print this message, or detailed help on a topic;
                        the available topics are:

   all, automation, paths, security, testing, or any of the subcommands or
   plugins (certonly, install, nginx, apache, standalone, webroot, etc)
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[dokku-letsencrypt を使ってみた]]></title>
    <link href="http://blog.n-z.jp/blog/2016-04-06-dokku-letsencrypt.html"/>
    <updated>2016-04-06T23:00:00+09:00</updated>
    <id>http://blog.n-z.jp/blog/dokku-letsencrypt</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/dokku/dokku-letsencrypt">dokku-letsencrypt</a> を試してみたのでそのメモです。</p>

<!--more-->


<h2>対象バージョン</h2>

<ul>
<li>Ubuntu 14.04.4 LTS</li>
<li>Docker 1.10.3</li>
<li>Dokku 0.5.3</li>
<li>dokku-letsencrypt v0.7.0-7-gb4950b8</li>
</ul>


<h2>インストール</h2>

<p>README.md に書いてある手順の通りインストールして、 <code>git describe --tags</code> でバージョンを確認しておきました。</p>

<pre><code>$ sudo dokku plugin:install https://github.com/dokku/dokku-letsencrypt.git
-----&gt; Cloning plugin repo https://github.com/dokku/dokku-letsencrypt.git to /var/lib/dokku/plugins/available/letsencrypt
Cloning into 'letsencrypt'...
remote: Counting objects: 233, done.
remote: Compressing objects: 100% (4/4), done.
remote: Total 233 (delta 0), reused 0 (delta 0), pack-reused 229
Receiving objects: 100% (233/233), 48.62 KiB | 0 bytes/s, done.
Resolving deltas: 100% (136/136), done.
Checking connectivity... done.
-----&gt; Plugin letsencrypt enabled
-----&gt; Migrating zero downtime env variables. The following variables have been deprecated
=====&gt; DOKKU_SKIP_ALL_CHECKS DOKKU_SKIP_DEFAULT_CHECKS
=====&gt; Please use dokku checks:[disable|enable] &lt;app&gt; to control zero downtime functionality
=====&gt; Migration complete
=====&gt;
=====&gt; Migration complete
=====&gt;
=====&gt; Migration complete
=====&gt;
=====&gt; Migration complete
=====&gt;
=====&gt; Migration complete
=====&gt;
Adding user dokku to group adm
$ cd /var/lib/dokku/plugins/available/letsencrypt/
$ git describe --tags
v0.7.0-7-gb4950b8
$ cd
</code></pre>

<h2>アップグレード</h2>

<p>README.md にアップグレードの手順も書いてあったので、試しておきました。</p>

<pre><code>$ sudo dokku plugin:update letsencrypt
Plugin (letsencrypt) updated
</code></pre>

<h2>対象アプリの確認</h2>

<p><code>dokku apps</code> でアプリケーション一覧を表示して、対象とするアプリケーションの名前を確認しておきました。</p>

<ul>
<li><code>dokku help</code></li>
<li><code>dokku apps:help</code></li>
<li><code>dokku apps</code></li>
</ul>


<h2>メールアドレス設定</h2>

<p>Let&rsquo;s Encrypt に登録するメールアドレスを設定しておきます。
<a href="https://letsencrypt.jp/usage/" title="Let's Encrypt の使い方">Let&rsquo;s Encrypt の使い方</a>の説明によると「ここで入力したメールアドレスは、緊急の通知や鍵を紛失したときの復旧に使われます。」</p>

<p>dokku-letsencrypt プラグインでは「利用規約への同意」に相当する手順がありませんが、念のため利用規約 (現在のバージョンは <a href="https://letsencrypt.org/documents/LE-SA-v1.0.1-July-27-2015.pdf">https://letsencrypt.org/documents/LE-SA-v1.0.1-July-27-2015.pdf</a> ) に目を通しておくと良いと思います。</p>

<p>ちなみに今のところ letsencrypt に登録したメールアドレスに letsencrypt からメールが来たことはありません。</p>

<pre><code>$ dokku config:set --no-restart staging.example.co.jp DOKKU_LETSENCRYPT_EMAIL=root@example.co.jp
-----&gt; Setting config vars
       DOKKU_LETSENCRYPT_EMAIL: root@example.co.jp
</code></pre>

<h2>メールアドレスをグローバルに設定するかアプリケーションごとに設定するか</h2>

<p>グローバルに設定することも可能だと思いますが、メールアドレスを設定していなければ <code>dokku letsencrypt APP</code> の最初のチェックで止まって、既存の TLS 設定を上書きされる心配がないので、すべてのアプリケーションで letsencrypt を使うのでなければ、アプリケーションごとに設定することをおすすめします。</p>

<p>メールアドレスを設定していなければ、以下のように失敗して止まってくれます。</p>

<pre><code>$ dokku letsencrypt node-js-app
=====&gt; Let's Encrypt node-js-app...
 !     ERROR: Cannot request a certificate without an e-mail address!
 !       please provide your e-mail address using
 !       dokku config:set --no-restart node-js-app DOKKU_LETSENCRYPT_EMAIL=&lt;e-mail&gt;
</code></pre>

<h2>証明書発行と設定</h2>

<p><code>dokku letsencrypt APP</code> で証明書発行から設定まで自動で実行されます。</p>

<p>すでに <code>tls/server.{crt,key}</code> が存在していても強制的にシンボリックリンクで上書きされるので、他で発行された証明書を使っている場合は注意が必要です。</p>

<pre><code>$ dokku letsencrypt staging.example.co.jp
=====&gt; Let's Encrypt staging.example.co.jp...
-----&gt; Updating letsencrypt docker image...
latest: Pulling from m3adow/letsencrypt-simp_le
420890c9e918: Pull complete
acbaf1e6012f: Pull complete
5f71a1a2d3dc: Pull complete
Digest: sha256:be1d7aca214d5277af18d7bf75a2bc78afa5a1eabf98aaa8a606c4ca2a7fdeb5
Status: Downloaded newer image for m3adow/letsencrypt-simp_le:latest
       done
-----&gt; Enabling ACME proxy for staging.example.co.jp...
-----&gt; Getting letsencrypt certificate for staging.example.co.jp...
        - Domain 'staging.example.co.jp'
darkhttpd/1.11, copyright (c) 2003-2015 Emil Mikulic.
listening on: http://0.0.0.0:80/
2016-04-04 03:26:42,946:INFO:__main__:1202: Generating new account key
2016-04-04 03:26:43,831:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:44,110:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:44,302:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:44,841:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): letsencrypt.org
2016-04-04 03:26:45,410:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:45,664:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:45,940:INFO:requests.packages.urllib3.connectionpool:207: Starting new HTTP connection (1): staging.example.co.jp
2016-04-04 03:26:45,946:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): staging.example.co.jp
2016-04-04 03:26:45,995:INFO:__main__:1294: staging.example.co.jp was successfully self-verified
2016-04-04 03:26:46,022:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:46,272:INFO:__main__:1302: Generating new certificate private key
2016-04-04 03:26:47,528:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:47,723:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:47,987:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:48,215:INFO:__main__:385: Saving account_key.json
2016-04-04 03:26:48,216:INFO:__main__:385: Saving fullchain.pem
2016-04-04 03:26:48,216:INFO:__main__:385: Saving chain.pem
2016-04-04 03:26:48,216:INFO:__main__:385: Saving cert.pem
2016-04-04 03:26:48,216:INFO:__main__:385: Saving key.pem
-----&gt; Certificate retrieved successfully.
-----&gt; Symlinking let's encrypt certificates
-----&gt; Configuring staging.example.co.jp...(using built-in template)
-----&gt; Creating https nginx.conf
-----&gt; Running nginx-pre-reload
       Reloading nginx
-----&gt; Disabling ACME proxy for staging.example.co.jp...
       done
</code></pre>

<h2>有効になっているアプリケーション一覧確認</h2>

<p><code>dokku letsencrypt:ls</code> で有効になっているアプリケーションとその有効期限を確認します。</p>

<pre><code>$ dokku letsencrypt:ls
-----&gt; App name           Certificate Expiry        Time before expiry        Time before renewal
staging.example.co.jp 2016-07-03 11:27:00       89d, 22h, 56m, 55s        59d, 22h, 56m, 55s
</code></pre>

<h2>自動更新</h2>

<p>有効期限が 30 日 (<code>DOKKU_LETSENCRYPT_GRACEPERIOD</code> で変更可能) を切ると自動更新してくれる <code>dokku letsencrypt:auto-renew</code> も試しておきます。</p>

<pre><code>$ dokku letsencrypt:auto-renew
=====&gt; Auto-renewing all apps...
       staging.example.co.jp still has 59d, 22h, 48m, 36s days left before renewal
=====&gt; Finished auto-renewal
</code></pre>

<p>問題なさそうなので、<code>dokku</code> ユーザーの <code>crontab</code> で設定して自動実行するようにしておきます。
リモートからのトリガーで実行されるように ssh で入れるユーザーの <code>crontab</code> で <code>ssh dokku letsencrypt:auto-renew</code> を設定しておくのでも良いと思います。</p>

<h2>セキュリティ上の問題点</h2>

<p><code>dokku-letsencrypt</code> が使用している <a href="https://github.com/kuba/simp_le" title="Simple Let's Encrypt Client">Simple Let&rsquo;s Encrypt Client</a> の issue の <a href="https://github.com/kuba/simp_le/issues/29" title="private key permissions">private key permissions</a> で指摘されているように、 <code>ls -al /home/dokku/staging.example.co.jp/letsencrypt/certs/current/</code> で確認してみると、他のユーザーからは読めなくするべき <code>account_key.json</code> や <code>key.pem</code> も誰でも読めるパーミッションになってしまっているので、 <code>sudo chmod 700 /home/dokku/staging.example.co.jp/letsencrypt</code> などでパーミッションを落としておく方が良さそうです。</p>

<p>ファイル自体のパーミッションを落としても良さそうですが、更新された後のことも考えると <code>/home/dokku/APP/letsencrypt</code> ディレクトリ自体のパーミッションを落としておくのが良さそうです。</p>

<h2>Rate Limit</h2>

<p><a href="https://letsencrypt.jp/faq/#RateLimiting" title="Let's Encrypt の証明書に取得数制限はありますか？">Let&rsquo;s Encrypt の証明書に取得数制限はありますか？</a> のリンク先に書いてあるように、この記事執筆時点では「アカウント登録/IP アドレスごと」(3 時間で 10 個) と「証明書発行/ドメインごと」(1 週間で 5 個) の制限があるので、注意が必要です。</p>

<p>特に dokku-letsencrypt では<a href="https://github.com/letsencrypt/letsencrypt">公式のクライアント</a>が <code>/etc/letsencrypt/accounts</code> でアカウントを共有するのと違って、 <code>account_key.json</code> をアプリケーションごとに作成しているので、注意が必要そうです。</p>

<p>ただし、現状の制限だと証明書発行数の制限の方が引っかかりやすいので、アカウント登録の制限は問題にならないようにも思います。</p>

<p>証明書発行数の制限については <code>dokku domains:add</code> や <code>dokku domains:remove</code> で適切にドメインの追加や削除をしてから <code>dokku letsencrypt</code> を実行するように README.md の <a href="https://github.com/dokku/dokku-letsencrypt/tree/b4950b8254f683e4af775bad44e390763a699de1#dealing-with-rate-limit" title="Dealing with rate limit">Dealing with rate limit</a> に書いてあります。</p>

<h2>証明書の情報表示</h2>

<p><code>dokku certs:info</code> で letsencrypt のものに限らず、証明書の情報を表示できます。</p>

<pre><code>adminuser@tk2-213-16013:~$ dokku certs:info staging.example.co.jp
-----&gt; Fetching SSL Endpoint info for staging.example.co.jp...
-----&gt; Certificate details:
=====&gt; Common Name(s):
=====&gt;    staging.example.co.jp
=====&gt;    staging.example.co.jp
=====&gt; Expires At: Jul  3 02:27:00 2016 GMT
=====&gt; Issuer: C=US, O=Lets Encrypt, CN=Lets Encrypt Authority X3
=====&gt; Starts At: Apr  4 02:27:00 2016 GMT
=====&gt; Subject: CN=staging.example.co.jp
=====&gt; SSL certificate is self signed.
adminuser@tk2-213-16013:~$ dokku certs:info production.example.co.jp
-----&gt; Fetching SSL Endpoint info for production.example.co.jp...
-----&gt; Certificate details:
=====&gt; Common Name(s):
=====&gt;    production.example.co.jp
=====&gt;    production.example.co.jp
=====&gt;    example.co.jp
=====&gt; Expires At: Aug  4 00:05:31 2016 GMT
=====&gt; Issuer: C=IL, O=StartCom Ltd., OU=Secure Digital Certificate Signing, CN=StartCom Class 1 Primary Intermediate Server CA
=====&gt; Starts At: Aug  3 18:20:22 2015 GMT
=====&gt; Subject: C=JP; CN=production.example.co.jp; emailAddress=hostmaster@example.co.jp
=====&gt; SSL certificate is self signed.
adminuser@tk2-213-16013:~$ dokku certs:info another.example.co.jp
-----&gt; Fetching SSL Endpoint info for another.example.co.jp...
-----&gt; Certificate details:
=====&gt; Common Name(s):
=====&gt;    another.example.co.jp
=====&gt;    another.example.co.jp
=====&gt;    example.co.jp
=====&gt; Expires At: Apr 23 04:56:14 2016 GMT
=====&gt; Issuer: C=IL, O=StartCom Ltd., OU=Secure Digital Certificate Signing, CN=StartCom Class 1 Primary Intermediate Server CA
=====&gt; Starts At: Apr 22 23:55:13 2015 GMT
=====&gt; Subject: C=JP; CN=another.example.co.jp; emailAddress=hostmaster@example.co.jp
=====&gt; SSL certificate is self signed.
adminuser@tk2-213-16013:~$
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ccollect によるバックアップの設定]]></title>
    <link href="http://blog.n-z.jp/blog/2016-04-04-ccollect.html"/>
    <updated>2016-04-04T22:51:06+09:00</updated>
    <id>http://blog.n-z.jp/blog/ccollect</id>
    <content type="html"><![CDATA[<p><code>ccollect</code> という <code>rsync</code> の <code>--link-dest</code> オプションによるハードリンクをうまく使って差分バックアップをしてくれるツールでバックアップ設定をしました。</p>

<!--more-->


<h2>インストール</h2>

<p>deb パッケージは存在しないので、まず <code>git clone https://github.com/ungleich/ccollect ~/src/github.com/ungleich/ccollect</code> などで最新 (現時点で 1.0) の ccollect を github のミラーから取得します。</p>

<p><a href="http://www.nico.schottelius.org/software/ccollect/">本家</a> の download ページにある tarball は 0.8 まででちょっと古いです。</p>

<h2>共通設定</h2>

<p>設定は <code>CCOLLECT_CONF</code> (デフォルトは <code>/etc/ccollect</code>) の中に置いていきます。</p>

<p>共通設定は <code>defaults</code> の中に、バックアップごとの設定は <code>sources</code> の中に置いていきます。</p>

<h3>バックアップ保存回数の設定</h3>

<p><code>defaults/intervals</code> の中に適当なファイル名でバックアップの保存回数を設定していきます。</p>

<p><code>daily</code> などの名前をつけることが多いようですが、 <code>ccollect</code> 自体に毎日自動実行する機能があるわけではないので、自前で <code>cron</code> などを使って実行する必要が有ります。</p>

<ul>
<li><code>sudo mkdir -p /etc/ccollect/defaults/intervals</code></li>
<li><code>echo 10 | sudo tee /etc/ccollect/defaults/intervals/daily</code></li>
<li><code>echo 24 | sudo tee /etc/ccollect/defaults/intervals/monthly</code></li>
<li><code>echo 10 | sudo tee /etc/ccollect/defaults/intervals/weekly</code></li>
</ul>


<p>ここでは日時バックアップと週次バックアップは 10 回分、月次バックアップは 2 年分保存するようにしてみました。</p>

<h3>不完全なバックアップの削除</h3>

<p><code>ccollect</code> では構造化された設定ファイルをパースするのではなく、簡単な内容のファイルの中身が設定値になっていたり、ファイルの存在がフラグとなっていたりするようになっています。</p>

<p>ここでは <code>rsync</code> の途中で <code>ssh</code> が切れたなどの理由で不完全なバックアップができてしまった時に削除するフラグを設定します。</p>

<ul>
<li><code>sudo touch /etc/ccollect/defaults/delete_incomplete</code></li>
</ul>


<h2>ローカルのバックアップ設定の追加</h2>

<p>まず動作確認も兼ねて、ローカルのバックアップを取る設定を追加してみます。</p>

<ul>
<li><code>sudo mkdir -p /etc/ccollect/sources/$(hostname)-home</code></li>
<li><code>echo '/home' | sudo tee /etc/ccollect/sources/$(hostname)-home/source</code></li>
<li><code>echo "/srv/backup/$(hostname)-home" | sudo tee /etc/ccollect/sources/$(hostname)-home/destination</code></li>
</ul>


<p>バックアップから除外するファイルも設定してみます。
除外指定ということを明示するために <code>-</code> をつけていますが、つけずにパターンだけでもこの場合は同じです。
<code>exclude</code> ファイルの書式の詳細は <code>rsync "--exclude-from"</code> で検索して調べてください。</p>

<ul>
<li><code>echo '- *.swp' | sudo tee /etc/ccollect/sources/$(hostname)-home/exclude</code></li>
<li><code>echo '- *~' | sudo tee -a /etc/ccollect/sources/$(hostname)-home/exclude</code></li>
</ul>


<p>今回は関係ないかもしれませんが、 <code>/</code> パーティションなどをバックアップする時にはつけた方が良い <code>--one-file-system</code> オプションも追加しておきます。</p>

<ul>
<li><code>echo '--one-file-system' | sudo tee /etc/ccollect/sources/$(hostname)-home/rsync_options</code></li>
</ul>


<p>サマリー表示を有効にしておきます。
初回実行なので詳細表示も有効にしてみます。</p>

<ul>
<li><code>sudo touch /etc/ccollect/sources/$(hostname)-home/summary</code></li>
<li><code>sudo touch /etc/ccollect/sources/$(hostname)-home/verbose</code></li>
</ul>


<h3>初回バックアップ実行</h3>

<p><code>destination</code> ファイルで指定したバックアップ先ディレクトリは自動作成されないので、手動で作成してバックアップを実行します。
2 回実行してちゃんと差分バックアップになっているのを確認します。</p>

<ul>
<li><code>sudo mkdir -pv $(cat /etc/ccollect/sources/*/destination)</code></li>
<li><code>sudo ~/src/github.com/ungleich/ccollect/ccollect daily $(hostname)-home</code></li>
<li><code>sudo ~/src/github.com/ungleich/ccollect/ccollect daily $(hostname)-home</code></li>
</ul>


<p>容量も 2 倍になっていないのを確認します。</p>

<ul>
<li><code>sudo du -s /srv/backup/$(hostname)-home /home</code></li>
</ul>


<p>動作確認ができたので、詳細表示オプションを削除しておきます。</p>

<ul>
<li><code>sudo rm /etc/ccollect/sources/$(hostname)-home/verbose</code></li>
</ul>


<h2>リモートからのバックアップ設定の追加</h2>

<p><code>source</code> にリモートホストを設定する以外はローカルの設定と同様に設定していきます。</p>

<ul>
<li><code>sudo mkdir /etc/ccollect/sources/vps-etc</code></li>
<li><code>echo /srv/backup/vps-etc | sudo tee /etc/ccollect/sources/vps-etc/destination</code></li>
<li><code>echo root@vps.example.jp:/etc | sudo tee /etc/ccollect/sources/vps-etc/source</code></li>
<li><code>echo '- *.swp' | sudo tee -a /etc/ccollect/sources/vps-etc/exclude</code></li>
<li><code>echo '- *~' | sudo tee -a /etc/ccollect/sources/vps-etc/exclude</code></li>
<li><code>sudo touch /etc/ccollect/sources/vps-etc/summary</code></li>
</ul>


<p>ネットワーク的につながらない時はバックアップが失敗するので、事前チェックするようにします。</p>

<ul>
<li><code>sudoedit /etc/ccollect/sources/vps-etc/pre_exec</code></li>
<li><code>sudo chmod +x /etc/ccollect/sources/vps-etc/pre_exec</code></li>
</ul>


<p><code>pre_exec</code> の内容は以下の通りです。
<a href="https://github.com/ungleich/ccollect/blob/5356370233e0883b5c6cc62b12c84ef058f8c239/doc/ccollect.text#L872-L884">ccollect のドキュメントの Testing for host reachabilty</a> を参考にしています。</p>

<pre><code class="bash">#!/bin/sh
set -e
cur_conf_dir="${CCOLLECT_CONF:-/etc/ccollect}/sources/$name"
SRC_HOST=`cat "$cur_conf_dir/source" | cut -d"@" -f2 | cut -d":" -f1`
ping -c1 -q "$SRC_HOST" || exit $?
</code></pre>

<h3>ssh 設定</h3>

<p>セキュリティ的にはあまり好ましくないのですが、バックアップ用に root から root に ssh で接続できるようにします。</p>

<p>まず、バックアップ先のローカルのマシンで root の ssh 用の鍵を作成します。</p>

<ul>
<li><code>sudo ls -al /root/.ssh</code> で root に ssh の鍵がないのを確認したら <code>sudo ssh-keygen</code> で生成します。存在する場合は別のファイル名で生成して <code>sudoedit /root/.ssh/config</code> で <code>IdentityFile</code> を設定しておきます。自動実行で使用するので、パスフレーズは空にしておきます。</li>
<li>ssh のポート番号を変更しているなど、別途設定が必要な場合は <code>sudoedit /root/.ssh/config</code> で設定しておくのを忘れないように注意が必要です。</li>
<li><code>sudo cat /root/.ssh/id_rsa.pub</code> で公開鍵を表示してコピーしておきます。</li>
</ul>


<p>続いて、バックアップ対象の VPS (バックアップ元) の方で ssh を許可する設定をします。</p>

<ul>
<li><code>sudo install -m700 -d /root/.ssh</code> で <code>/root/.ssh</code> がなければ作成します。</li>
<li><code>sudoedit /root/.ssh/authorized_keys</code> で接続を許可する鍵として、先ほどコピーした公開鍵を貼り付けます。</li>
<li>必要に応じて <code>from="pattern-list"</code> や <code>no-agent-forwarding,no-user-rc,no-X11-forwarding,no-port-forwarding</code> などの制限も追加しておきます。</li>
<li><code>sudoedit /etc/ssh/sshd_config</code> で <code>PermitRootLogin</code> を <code>no</code> 以外にします。例えば <code>without-password</code> にしておきます。</li>
<li><code>sudoedit /etc/ssh/sshd_config</code> で <code>AllowUsers</code> による制限をしている時は <code>AllowUsers root@接続元IPアドレス</code> を追加しておきます。接続元 IP アドレスが固定ではない場合は、セキュリティ的に弱くなりますが <code>AllowUsers root</code> で許可します。</li>
<li><code>/etc/ssh/sshd_config</code> の設定を変更した場合は <code>sudo service ssh restart</code> で反映させておきます。</li>
</ul>


<p>設定ができたら、接続元 (バックアップ先のローカルのマシン) から ssh の接続確認をします。</p>

<ul>
<li><code>sudo ssh root@vps.example.jp hostname</code> などで ssh 接続ができることの確認とホスト鍵の確認を済ませておきます。</li>
</ul>


<h3>初回バックアップ実行</h3>

<p>ローカルでのバックアップと同様にバックアップ先ディレクトリを作成してからバックアップを実行します。</p>

<ul>
<li><code>sudo mkdir -pv $(cat /etc/ccollect/sources/*/destination)</code></li>
<li><code>sudo ~/src/github.com/ungleich/ccollect/ccollect daily vps-etc</code></li>
<li><code>sudo ~/src/github.com/ungleich/ccollect/ccollect daily vps-etc</code></li>
</ul>


<h2>リモートからの一般ユーザー権限でのバックアップ設定の追加</h2>

<p>dokku で persistent storage としてボリュームマウントを使っているとファイルの所有者とグループがアプリケーションのデプロイのたびに変わってしまって、差分バックアップに支障が出そうだったので、一般ユーザーでのバックアップも設定しました。</p>

<p><a href="https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html" title="XDG Base Directory Specification">XDG Base Directory Specification</a> の <code>XDG_CONFIG_HOME</code> を参考にして <code>~/.config</code> 以下に <code>/etc</code> 以下と同じ構造で設定を作成することにしました。</p>

<ul>
<li><code>mkdir -p ~/.config/ccollect/defaults/intervals</code></li>
<li><code>echo 10 &gt; ~/.config/ccollect/defaults/intervals/daily</code></li>
<li><code>echo 24 &gt; ~/.config/ccollect/defaults/intervals/monthly</code></li>
<li><code>echo 10 &gt; ~/.config/ccollect/defaults/intervals/weekly</code></li>
<li><code>mkdir -p ~/.config/ccollect/sources/vps-srv</code></li>
<li><code>echo /srv/backup/vps-srv &gt; ~/.config/ccollect/sources/vps-srv/destination</code></li>
<li><code>echo vpsuser@vps.example.jp:/srv &gt; ~/.config/ccollect/sources/vps-srv/source</code></li>
<li><code>echo '- *.swp' &gt; ~/.config/ccollect/sources/vps-srv/exclude</code></li>
<li><code>echo '- *~' &gt;&gt; ~/.config/ccollect/sources/vps-srv/exclude</code></li>
<li><code>touch ~/.config/ccollect/sources/vps-srv/summary</code></li>
</ul>


<p>ネットワーク的につながらない時はバックアップが失敗するので、事前チェックするようにします。</p>

<ul>
<li><code>editor ~/.config/ccollect/sources/vps-srv/pre_exec</code></li>
<li><code>chmod +x ~/.config/ccollect/sources/vps-srv/pre_exec</code></li>
</ul>


<p><code>pre_exec</code> の内容は以下の通りです。
「リモートからのバックアップ設定の追加」で作成したものと全く同じ内容です。</p>

<pre><code class="bash">#!/bin/sh
set -e
cur_conf_dir="${CCOLLECT_CONF:-/etc/ccollect}/sources/$name"
SRC_HOST=`cat "$cur_conf_dir/source" | cut -d"@" -f2 | cut -d":" -f1`
ping -c1 -q "$SRC_HOST" || exit $?
</code></pre>

<h3>初回バックアップ実行</h3>

<p>一般ユーザー権限でバックアップするので、バックアップ先ディレクトリを <code>chown</code> しておきます。</p>

<p><code>ssh vpsuser@vps.example.jp</code> で一度接続してホスト鍵の確認なども終わらせておきます。</p>

<p>設定ファイルの場所が違うので、環境変数 <code>CCOLLECT_CONF</code> を設定しつつ実行します。</p>

<ul>
<li><code>sudo mkdir -pv $(cat ~/.config/ccollect/sources/*/destination)</code></li>
<li><code>sudo chown $(id -u) /srv/backup/vps-srv</code></li>
<li><code>env CCOLLECT_CONF=$HOME/.config/ccollect ~/src/github.com/ungleich/ccollect/ccollect daily vps-srv</code></li>
<li><code>env CCOLLECT_CONF=$HOME/.config/ccollect ~/src/github.com/ungleich/ccollect/ccollect daily vps-srv</code></li>
</ul>


<h2>バックアップ自動実行設定</h2>

<p>cron で毎日自動バックアップが動くように設定します。
時間がかかるので、 <code>cron.daily</code> のファイルの中でも最後に実行されるように <code>zz-</code> で始まる名前にしています。
そして、パッケージで入れたファイルと区別できるように <code>local</code> という文字列を名前に入れています。</p>

<p>その際、保存回数が一番多くて保存期間が長い <code>monthly</code> を優先するようにしてみました。</p>

<p>ログ保存用のディレクトリは一般的な debian の流儀に合わせて adm グループのみ読めるようにしています。
<code>install</code> コマンドについては <a href="http://blog.n-z.jp/blog/2014-02-14-install.html" title="installコマンドでコマンド数を減らす">installコマンドでコマンド数を減らす</a> を参考にしてください。</p>

<p>ログは rotate などはせずに全部残して、 <code>tools/ccollect_analyse_logs</code> でエラーや警告があれば cron からのメールとして飛ぶようにしました。
その際、 <code>tools/ccollect_analyse_logs</code> の exit status が <code>grep</code> の exit status そのままなので、エラーの有無と逆の意味に感じられてしまうので、反転するようにしました。</p>

<ul>
<li><code>sudoedit /etc/cron.daily/zz-local-ccollect</code></li>
<li><code>sudo chmod +x /etc/cron.daily/zz-local-ccollect</code></li>
</ul>


<pre><code class="bash /etc/cron.daily/zz-local-ccollect">#!/bin/sh
INTERVAL=daily
if [ 7 = "$(date +%u)" ]; then
  INTERVAL=weekly
fi
if [ 01 = "$(date +%d)" ]; then
  INTERVAL=monthly
fi
mkdir -p /var/log/ccollect
LOGDIR="/var/log/ccollect"
LOGFILE="$LOGDIR/$(date +%Y%m%d-%H%M).log"
LOCALUSER="localuser"
CCOLLECT_DIR="/home/$LOCALUSER/src/github.com/ungleich/ccollect"
install -m750 -oroot -gadm -d "$LOGDIR"
{
  su - "$LOCALUSER" -c 'env CCOLLECT_CONF=$HOME/.config/ccollect '"$CCOLLECT_DIR"'/ccollect -a '"$INTERVAL"
  "$CCOLLECT_DIR/ccollect" -a "$INTERVAL"
} &gt;"$LOGFILE" 2&gt;&amp;1
if /bin/sh "$CCOLLECT_DIR/tools/ccollect_analyse_logs" "we" &lt; "$LOGFILE"; then
  # found
  exit 1
else
  # not found
  exit 0
fi
</code></pre>

<h2>リモートの dokku の home のバックアップ設定</h2>

<p>他の設定例として、リモートの dokku の home のバックアップ設定もしてみました。
設定が似ている <code>vps-etc</code> を雛形としてコピーして <code>destination</code> と <code>source</code> などを書き換える形で設定しました。</p>

<ul>
<li><code>cd /etc/ccollect/sources</code></li>
<li><code>sudo cp -a vps-etc vps-home</code></li>
<li><code>sudoedit vps-home/destination</code> で <code>/srv/backup/vps-home</code> に変更</li>
<li><code>sudoedit vps-home/source</code> で <code>root@vps.example.jp:/home</code> に変更</li>
<li><code>sudoedit vps-home/exclude</code> で <code>- cache</code> を追加 (<code>/home/dokku/$APP/cache/</code> は buildpack での build 時などのキャッシュに使われるのと、ファイルの所有者とグループがどんどん変わるので、バックアップからは除外)</li>
</ul>


<h3>初回バックアップ実行</h3>

<p><code>vps-etc</code> のバックアップと同様にバックアップ先ディレクトリを作成してからバックアップを実行します。</p>

<ul>
<li><code>sudo mkdir -pv $(cat /etc/ccollect/sources/*/destination)</code></li>
<li><code>sudo ~/src/github.com/ungleich/ccollect/ccollect daily vps-home</code></li>
<li><code>sudo ~/src/github.com/ungleich/ccollect/ccollect daily vps-home</code></li>
</ul>


<h2>uid, gid 問題</h2>

<p>LDAP などでアカウントを共通化していれば問題ないのですが、 <code>rsync</code> では uid や gid を数値のまま保存してコピーするので、バックアップ元とバックアップ先で同じ uid に対して別のユーザーが存在すると、意図しないユーザーが読めるバックアップができてしまうので、注意が必要です。</p>

<p>この記事の例だと <code>/srv/backup/vps-home</code> のパーミッションを変更する (<code>sudo chmod 700 /srv/backup/vps-home</code>) などの対処をしておくと良いと思います。</p>

<h2>バックアップの差分の確認</h2>

<p><a href="https://github.com/ungleich/ccollect/blob/5356370233e0883b5c6cc62b12c84ef058f8c239/doc/ccollect.text#L858-L869" title="ccollect.text の Comparing backups">ccollect.text の Comparing backups</a> によると <code>rsync -n -a --delete --stats --progress daily.20080324-0313.17841/ daily.20080325-0313.31148/</code> のように <code>-n</code> オプション付きで <code>rsync</code> を実行することによってバックアップの差分を確認できるようです。</p>

<h2>まとめ</h2>

<p><code>ccollect</code> で差分バックアップを作成するようにしました。</p>

<p><code>rsync</code> によるバックアップなので、圧縮などもするバックアップツールと違い、バックアップの内容も元のディレクトリ構造そのままでわかりやすいので、一部だけ復元するなどの操作も素直に実行しやすくなっています。</p>

<p>ハードリンクなので i-node は消費しますが、変化がないファイルについては容量を消費しないので、バックアップサイズも抑えられます。</p>
]]></content>
  </entry>
  
</feed>
