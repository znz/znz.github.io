<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ubuntu | @znz blog]]></title>
  <link href="http://blog.n-z.jp/blog/categories/ubuntu/atom.xml" rel="self"/>
  <link href="http://blog.n-z.jp/"/>
  <updated>2016-07-26T23:41:03+09:00</updated>
  <id>http://blog.n-z.jp/</id>
  <author>
    <name><![CDATA[Kazuhiro NISHIYAMA]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ubuntuで「ハッシュサムが適合しません」で backports のパッケージが入ってしまって大変だった]]></title>
    <link href="http://blog.n-z.jp/blog/2016-05-26-ubuntu-hash-mismatch.html"/>
    <updated>2016-05-26T22:23:35+09:00</updated>
    <id>http://blog.n-z.jp/blog/ubuntu-hash-mismatch</id>
    <content type="html"><![CDATA[<p><code>jp.archive.ubuntu.com</code> のミラーが不完全だったのか、「ハッシュサムが適合しません」という警告が出て、そのまま <code>sudo aptitude full-upgrade -DV</code> をしたら backports のパッケージが入ってしまって大変な思いをしたという話です。</p>

<!--more-->


<h2>環境</h2>

<ul>
<li>Ubuntu 14.04.4 LTS</li>
</ul>


<h2>警告</h2>

<p><code>sudo aptitude update</code> で以下のような警告とエラーが出ていました。</p>

<pre><code>W: http://jp.archive.ubuntu.com/ubuntu/dists/trusty-updates/main/source/Sources を取得できませんでした: ハッシュサムが適合しません
W: http://jp.archive.ubuntu.com/ubuntu/dists/trusty-updates/universe/source/Sources を取得できませんでした: ハッシュサムが適合しません
W: http://jp.archive.ubuntu.com/ubuntu/dists/trusty-updates/main/binary-amd64/Packages を取得できませんでした: ハッシュ サムが適合しません
W: http://jp.archive.ubuntu.com/ubuntu/dists/trusty-updates/universe/binary-amd64/Packages を取得できませんでした: ハッ シュサムが適合しません
W: http://jp.archive.ubuntu.com/ubuntu/dists/trusty-updates/main/binary-i386/Packages を取得できませんでした: ハッシュサムが適合しません
W: http://jp.archive.ubuntu.com/ubuntu/dists/trusty-updates/universe/binary-i386/Packages を取得できませんでした: ハッシュサムが適合しません
E: 一部のインデックスファイルのダウンロードに失敗しました。無視されたか古いものを代わりに利用しています。
E: パッケージキャッシュを再構築できませんでした
</code></pre>

<h2>不用意なアップグレード</h2>

<p>あまり気にせず、セキュリティアップデートがあれば更新しておこうと思って、 <code>sudo aptitude full-upgrade -DV</code> を実行してみたところ、以下のパッケージが更新対象に上がりました。</p>

<p>証明書の設定で <code>SSLCertificateChainFile</code> が必要なくなる 2.4.8 をまたぐので、ちょっと危険な気はしましたが、個人のサーバーなので多少の停止時間は構わないだろうと思ってアップグレードしてしまいました。</p>

<pre><code>以下のパッケージが更新されます:
  apache2 [2.4.7-1ubuntu4.9 -&gt; 2.4.10-1ubuntu1.1~ubuntu14.04.1]
  apache2-bin [2.4.7-1ubuntu4.9 -&gt; 2.4.10-1ubuntu1.1~ubuntu14.04.1]
  apache2-data [2.4.7-1ubuntu4.9 -&gt; 2.4.10-1ubuntu1.1~ubuntu14.04.1]
  apache2-dev [2.4.7-1ubuntu4.9 -&gt; 2.4.10-1ubuntu1.1~ubuntu14.04.1]
  apache2-mpm-prefork [2.4.7-1ubuntu4.9 -&gt; 2.4.10-1ubuntu1.1~ubuntu14.04.1]
  apache2-utils [2.4.7-1ubuntu4.9 -&gt; 2.4.10-1ubuntu1.1~ubuntu14.04.1]
  libcgmanager0 [0.24-0ubuntu7.5 -&gt; 0.39-2ubuntu2~ubuntu14.04.1]
</code></pre>

<h2>backports のパッケージだった</h2>

<p>ダウンロード中の URL を見て backports のパッケージが入ってしまっている、と気づいたのですが、手遅れで止める間もなく上がってしまいました。</p>

<pre><code>% apt-cache policy apache2
apache2:
  インストールされているバージョン: 2.4.7-1ubuntu4.9
  候補:               2.4.10-1ubuntu1.1~ubuntu14.04.1
  バージョンテーブル:
     2.4.10-1ubuntu1.1~ubuntu14.04.1 0
        100 http://jp.archive.ubuntu.com/ubuntu/ trusty-backports/main amd64 Packages
 *** 2.4.7-1ubuntu4.9 0
        100 /var/lib/dpkg/status
     2.4.7-1ubuntu4.5 0
        500 http://security.ubuntu.com/ubuntu/ trusty-security/main amd64 Packages
     2.4.7-1ubuntu4 0
        500 http://jp.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
</code></pre>

<h2>ダウングレード失敗</h2>

<p><code>/etc/apt/preferences</code> を設定してダウングレードすることにしました。</p>

<p>まず以下を試してみたところ、 <code>base-files</code> などを含む大量のパッケージがダウングレード対象になってしまったので中断しました。</p>

<pre><code>Package: *
Pin: release a=trusty
Pin-Priority: 1001
</code></pre>

<p><code>apt-cache policy</code> で確認してみると、現在のバージョンのインストール候補がなくなっているのが原因の一つでした。</p>

<pre><code>% apt-cache policy base-files
base-files:
  インストールされているバージョン: 7.2ubuntu5.4
  候補:               7.2ubuntu5
  バージョンテーブル:
 *** 7.2ubuntu5.4 0
        100 /var/lib/dpkg/status
     7.2ubuntu5 0
       1001 http://ubuntutym.u-toyama.ac.jp/ubuntu/ trusty/main amd64 Packages
</code></pre>

<p>そこで、 <code>/etc/apt/sources.list</code> の末尾に <code>archive.ubuntu.com</code> を一時的に追加することにしました。</p>

<pre><code>deb http://archive.ubuntu.com/ubuntu/ trusty main restricted universe multiverse
#deb-src http://archive.ubuntu.com/ubuntu/ trusty main restricted universe multiverse
deb http://archive.ubuntu.com/ubuntu/ trusty-updates main restricted universe multiverse
deb-src http://archive.ubuntu.com/ubuntu/ trusty-updates main restricted universe multiverse
</code></pre>

<p>すると <code>trusty-updates</code> も出てきたのですが、 priority が 500 になって期待した値になっていませんでした。</p>

<pre><code>% apt-cache policy base-files
base-files:
  インストールされているバージョン: 7.2ubuntu5.4
  候補:               7.2ubuntu5
  バージョンテーブル:
 *** 7.2ubuntu5.4 0
        500 http://archive.ubuntu.com/ubuntu/ trusty-updates/main amd64 Packages
        100 /var/lib/dpkg/status
     7.2ubuntu5 0
       1001 http://jp.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
       1001 http://archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
</code></pre>

<p>次に <code>n=trusty</code> を試してみたところ、 <code>backports</code> も priority が 1001 になってしまってダウングレードできませんでした。</p>

<pre><code>Package: *
Pin: release n=trusty
Pin-Priority: 1001
</code></pre>

<pre><code>% apt-cache policy base-files
base-files:
  インストールされているバージョン: 7.2ubuntu5.4
  候補:               7.2ubuntu5.4
  バージョンテーブル:
 *** 7.2ubuntu5.4 0
       1001 http://archive.ubuntu.com/ubuntu/ trusty-updates/main amd64 Packages
        100 /var/lib/dpkg/status
     7.2ubuntu5 0
       1001 http://jp.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
       1001 http://archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
% apt-cache policy apache2
apache2:
  インストールされているバージョン: 2.4.10-1ubuntu1.1~ubuntu14.04.1
  候補:               2.4.10-1ubuntu1.1~ubuntu14.04.1
  バージョンテーブル:
 *** 2.4.10-1ubuntu1.1~ubuntu14.04.1 0
       1001 http://jp.archive.ubuntu.com/ubuntu/ trusty-backports/main amd64 Packages
        100 /var/lib/dpkg/status
     2.4.7-1ubuntu4.9 0
       1001 http://archive.ubuntu.com/ubuntu/ trusty-updates/main amd64 Packages
     2.4.7-1ubuntu4.5 0
       1001 http://security.ubuntu.com/ubuntu/ trusty-security/main amd64 Packages
     2.4.7-1ubuntu4 0
       1001 http://jp.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
       1001 http://archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
</code></pre>

<h2>ダウングレード成功</h2>

<p>最終的に <code>a=trusty-updates</code> と <code>a=trusty-security</code> も追加することでダウングレードできました。</p>

<pre><code>Package: *
Pin: release a=trusty
Pin-Priority: 1001

Package: *
Pin: release a=trusty-updates
Pin-Priority: 1001

Package: *
Pin: release a=trusty-security
Pin-Priority: 1001
</code></pre>

<pre><code>% apt-cache policy apache2
apache2:
  インストールされているバージョン: 2.4.10-1ubuntu1.1~ubuntu14.04.1
  候補:               2.4.7-1ubuntu4.9
  バージョンテーブル:
 *** 2.4.10-1ubuntu1.1~ubuntu14.04.1 0
        100 http://jp.archive.ubuntu.com/ubuntu/ trusty-backports/main amd64 Packages
        100 /var/lib/dpkg/status
     2.4.7-1ubuntu4.9 0
       1001 http://archive.ubuntu.com/ubuntu/ trusty-updates/main amd64 Packages
     2.4.7-1ubuntu4.5 0
       1001 http://security.ubuntu.com/ubuntu/ trusty-security/main amd64 Packages
     2.4.7-1ubuntu4 0
       1001 http://jp.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
       1001 http://archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
% apt-cache policy base-files
base-files:
  インストールされているバージョン: 7.2ubuntu5.4
  候補:               7.2ubuntu5.4
  バージョンテーブル:
 *** 7.2ubuntu5.4 0
       1001 http://archive.ubuntu.com/ubuntu/ trusty-updates/main amd64 Packages
        100 /var/lib/dpkg/status
     7.2ubuntu5 0
       1001 http://jp.archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
       1001 http://archive.ubuntu.com/ubuntu/ trusty/main amd64 Packages
</code></pre>

<h2>backports のコメントアウト</h2>

<p>backports のパッケージは使っていなかったので、この後 backports の apt-line はコメントアウトしました。</p>

<h2>まとめ</h2>

<p><code>apt</code> の <code>update</code> に失敗した時はアップグレード対象のパッケージに注意しましょう。</p>

<p>ダウングレードする時は <code>apt_preferences(5)</code> の <code>Pin</code> 設定をうまく工夫しましょう。</p>

<p>backports のパッケージが不要なら backports の apt-line を追加するのは避けましょう。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[letsencrypt-auto の自動アップグレードを止めて手動でアップグレード]]></title>
    <link href="http://blog.n-z.jp/blog/2016-04-07-letsencrypt.html"/>
    <updated>2016-04-07T23:00:00+09:00</updated>
    <id>http://blog.n-z.jp/blog/letsencrypt</id>
    <content type="html"><![CDATA[<p><code>/etc/cron.daily/letsencrypt</code> は <code>root</code> 権限で実行されるため、そこで自動アップグレードがかかるとファイルのオーナーが <code>root</code> になってしまうかもしれないと思ったので、自動更新を止めて手動でアップグレードするようにしました。</p>

<!--more-->


<h2>自動アップグレードを止めた <code>/etc/cron.daily/local-letsencrypt</code></h2>

<p><a href="http://blog.n-z.jp/blog/2016-03-06-letsencrypt.html">前回の記事</a> からの差分としては <a href="http://packages.debian.org/debianutils">debianutils</a> の <code>savelog</code> でログをローテートして、証明書の有効期限の 90 日分残すようにしたのと、 <code>--no-self-upgrade</code> をつけて自動アップグレードを止めたことです。
それから、パッケージで入れたものではないということを明示するために <code>local</code> という文字列を入れたファイル名に変更しました。</p>

<pre><code class="bash /etc/cron.daily/local-letsencrypt">#!/bin/sh
LOGFILE=/var/log/letsencrypt/renew.log
if [ -f "$LOGFILE" ]; then
    /usr/bin/savelog -c 90 -q "$LOGFILE"
fi
if ! /home/hoge/letsencrypt/letsencrypt-auto renew --no-self-upgrade &gt; "$LOGFILE" 2&gt;&amp;1 ; then
    echo Automated renewal failed:
    cat "$LOGFILE"
    exit 1
fi
apachectl graceful
service postfix reload &gt;/dev/null
service dovecot reload
</code></pre>

<h2>手動アップグレードしたログ</h2>

<p>手動実行したところ、ちょうど 0.4.2 から 0.5.0 へのアップグレードが実行されました。</p>

<pre><code>% ~/letsencrypt/letsencrypt-auto --help
Checking for new version...
Upgrading letsencrypt-auto 0.4.2 to 0.5.0...
Replacing letsencrypt-auto...
   sudo cp -p /home/hoge/letsencrypt/letsencrypt-auto /tmp/user/1000/tmp.MclJH3TO68/letsencrypt-auto.permission-clone
   sudo cp /tmp/user/1000/tmp.MclJH3TO68/letsencrypt-auto /tmp/user/1000/tmp.MclJH3TO68/letsencrypt-auto.permission-clone
   sudo mv -f /tmp/user/1000/tmp.MclJH3TO68/letsencrypt-auto.permission-clone /home/hoge/letsencrypt/letsencrypt-auto
Creating virtual environment...
Installing Python packages...
Installation succeeded.
Requesting root privileges to run letsencrypt...
   sudo /home/hoge/.local/share/letsencrypt/bin/letsencrypt --help

  letsencrypt-auto [SUBCOMMAND] [options] [-d domain] [-d domain] ...

The Let's Encrypt agent can obtain and install HTTPS/TLS/SSL certificates.  By
default, it will attempt to use a webserver both for obtaining and installing
the cert. Major SUBCOMMANDS are:

  (default) run        Obtain &amp; install a cert in your current webserver
  certonly             Obtain cert, but do not install it (aka "auth")
  install              Install a previously obtained cert in a server
  renew                Renew previously obtained certs that are near expiry
  revoke               Revoke a previously obtained certificate
  rollback             Rollback server configuration changes made during install
  config_changes       Show changes made to server config during installation
  plugins              Display information about installed plugins

Choice of server plugins for obtaining and installing cert:

  --apache          Use the Apache plugin for authentication &amp; installation
  --standalone      Run a standalone webserver for authentication
  (nginx support is experimental, buggy, and not installed by default)
  --webroot         Place files in a server's webroot folder for authentication

OR use different plugins to obtain (authenticate) the cert and then install it:

  --authenticator standalone --installer apache

More detailed help:

  -h, --help [topic]    print this message, or detailed help on a topic;
                        the available topics are:

   all, automation, paths, security, testing, or any of the subcommands or
   plugins (certonly, install, nginx, apache, standalone, webroot, etc)
</code></pre>

<h2>アップグレードがないときのログ</h2>

<pre><code>% ~/letsencrypt/letsencrypt-auto --help
Checking for new version...
Requesting root privileges to run letsencrypt...
   sudo /home/hoge/.local/share/letsencrypt/bin/letsencrypt --help

  letsencrypt-auto [SUBCOMMAND] [options] [-d domain] [-d domain] ...

The Let's Encrypt agent can obtain and install HTTPS/TLS/SSL certificates.  By
default, it will attempt to use a webserver both for obtaining and installing
the cert. Major SUBCOMMANDS are:

  (default) run        Obtain &amp; install a cert in your current webserver
  certonly             Obtain cert, but do not install it (aka "auth")
  install              Install a previously obtained cert in a server
  renew                Renew previously obtained certs that are near expiry
  revoke               Revoke a previously obtained certificate
  rollback             Rollback server configuration changes made during install
  config_changes       Show changes made to server config during installation
  plugins              Display information about installed plugins

Choice of server plugins for obtaining and installing cert:

  --apache          Use the Apache plugin for authentication &amp; installation
  --standalone      Run a standalone webserver for authentication
  (nginx support is experimental, buggy, and not installed by default)
  --webroot         Place files in a server's webroot folder for authentication

OR use different plugins to obtain (authenticate) the cert and then install it:

  --authenticator standalone --installer apache

More detailed help:

  -h, --help [topic]    print this message, or detailed help on a topic;
                        the available topics are:

   all, automation, paths, security, testing, or any of the subcommands or
   plugins (certonly, install, nginx, apache, standalone, webroot, etc)
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[dokku-letsencrypt を使ってみた]]></title>
    <link href="http://blog.n-z.jp/blog/2016-04-06-dokku-letsencrypt.html"/>
    <updated>2016-04-06T23:00:00+09:00</updated>
    <id>http://blog.n-z.jp/blog/dokku-letsencrypt</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/dokku/dokku-letsencrypt">dokku-letsencrypt</a> を試してみたのでそのメモです。</p>

<!--more-->


<h2>対象バージョン</h2>

<ul>
<li>Ubuntu 14.04.4 LTS</li>
<li>Docker 1.10.3</li>
<li>Dokku 0.5.3</li>
<li>dokku-letsencrypt v0.7.0-7-gb4950b8</li>
</ul>


<h2>インストール</h2>

<p>README.md に書いてある手順の通りインストールして、 <code>git describe --tags</code> でバージョンを確認しておきました。</p>

<pre><code>$ sudo dokku plugin:install https://github.com/dokku/dokku-letsencrypt.git
-----&gt; Cloning plugin repo https://github.com/dokku/dokku-letsencrypt.git to /var/lib/dokku/plugins/available/letsencrypt
Cloning into 'letsencrypt'...
remote: Counting objects: 233, done.
remote: Compressing objects: 100% (4/4), done.
remote: Total 233 (delta 0), reused 0 (delta 0), pack-reused 229
Receiving objects: 100% (233/233), 48.62 KiB | 0 bytes/s, done.
Resolving deltas: 100% (136/136), done.
Checking connectivity... done.
-----&gt; Plugin letsencrypt enabled
-----&gt; Migrating zero downtime env variables. The following variables have been deprecated
=====&gt; DOKKU_SKIP_ALL_CHECKS DOKKU_SKIP_DEFAULT_CHECKS
=====&gt; Please use dokku checks:[disable|enable] &lt;app&gt; to control zero downtime functionality
=====&gt; Migration complete
=====&gt;
=====&gt; Migration complete
=====&gt;
=====&gt; Migration complete
=====&gt;
=====&gt; Migration complete
=====&gt;
=====&gt; Migration complete
=====&gt;
Adding user dokku to group adm
$ cd /var/lib/dokku/plugins/available/letsencrypt/
$ git describe --tags
v0.7.0-7-gb4950b8
$ cd
</code></pre>

<h2>アップグレード</h2>

<p>README.md にアップグレードの手順も書いてあったので、試しておきました。</p>

<pre><code>$ sudo dokku plugin:update letsencrypt
Plugin (letsencrypt) updated
</code></pre>

<h2>対象アプリの確認</h2>

<p><code>dokku apps</code> でアプリケーション一覧を表示して、対象とするアプリケーションの名前を確認しておきました。</p>

<ul>
<li><code>dokku help</code></li>
<li><code>dokku apps:help</code></li>
<li><code>dokku apps</code></li>
</ul>


<h2>メールアドレス設定</h2>

<p>Let&rsquo;s Encrypt に登録するメールアドレスを設定しておきます。
<a href="https://letsencrypt.jp/usage/" title="Let's Encrypt の使い方">Let&rsquo;s Encrypt の使い方</a>の説明によると「ここで入力したメールアドレスは、緊急の通知や鍵を紛失したときの復旧に使われます。」</p>

<p>dokku-letsencrypt プラグインでは「利用規約への同意」に相当する手順がありませんが、念のため利用規約 (現在のバージョンは <a href="https://letsencrypt.org/documents/LE-SA-v1.0.1-July-27-2015.pdf">https://letsencrypt.org/documents/LE-SA-v1.0.1-July-27-2015.pdf</a> ) に目を通しておくと良いと思います。</p>

<p>ちなみに今のところ letsencrypt に登録したメールアドレスに letsencrypt からメールが来たことはありません。</p>

<pre><code>$ dokku config:set --no-restart staging.example.co.jp DOKKU_LETSENCRYPT_EMAIL=root@example.co.jp
-----&gt; Setting config vars
       DOKKU_LETSENCRYPT_EMAIL: root@example.co.jp
</code></pre>

<h2>メールアドレスをグローバルに設定するかアプリケーションごとに設定するか</h2>

<p>グローバルに設定することも可能だと思いますが、メールアドレスを設定していなければ <code>dokku letsencrypt APP</code> の最初のチェックで止まって、既存の TLS 設定を上書きされる心配がないので、すべてのアプリケーションで letsencrypt を使うのでなければ、アプリケーションごとに設定することをおすすめします。</p>

<p>メールアドレスを設定していなければ、以下のように失敗して止まってくれます。</p>

<pre><code>$ dokku letsencrypt node-js-app
=====&gt; Let's Encrypt node-js-app...
 !     ERROR: Cannot request a certificate without an e-mail address!
 !       please provide your e-mail address using
 !       dokku config:set --no-restart node-js-app DOKKU_LETSENCRYPT_EMAIL=&lt;e-mail&gt;
</code></pre>

<h2>証明書発行と設定</h2>

<p><code>dokku letsencrypt APP</code> で証明書発行から設定まで自動で実行されます。</p>

<p>すでに <code>tls/server.{crt,key}</code> が存在していても強制的にシンボリックリンクで上書きされるので、他で発行された証明書を使っている場合は注意が必要です。</p>

<pre><code>$ dokku letsencrypt staging.example.co.jp
=====&gt; Let's Encrypt staging.example.co.jp...
-----&gt; Updating letsencrypt docker image...
latest: Pulling from m3adow/letsencrypt-simp_le
420890c9e918: Pull complete
acbaf1e6012f: Pull complete
5f71a1a2d3dc: Pull complete
Digest: sha256:be1d7aca214d5277af18d7bf75a2bc78afa5a1eabf98aaa8a606c4ca2a7fdeb5
Status: Downloaded newer image for m3adow/letsencrypt-simp_le:latest
       done
-----&gt; Enabling ACME proxy for staging.example.co.jp...
-----&gt; Getting letsencrypt certificate for staging.example.co.jp...
        - Domain 'staging.example.co.jp'
darkhttpd/1.11, copyright (c) 2003-2015 Emil Mikulic.
listening on: http://0.0.0.0:80/
2016-04-04 03:26:42,946:INFO:__main__:1202: Generating new account key
2016-04-04 03:26:43,831:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:44,110:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:44,302:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:44,841:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): letsencrypt.org
2016-04-04 03:26:45,410:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:45,664:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:45,940:INFO:requests.packages.urllib3.connectionpool:207: Starting new HTTP connection (1): staging.example.co.jp
2016-04-04 03:26:45,946:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): staging.example.co.jp
2016-04-04 03:26:45,995:INFO:__main__:1294: staging.example.co.jp was successfully self-verified
2016-04-04 03:26:46,022:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:46,272:INFO:__main__:1302: Generating new certificate private key
2016-04-04 03:26:47,528:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:47,723:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:47,987:INFO:requests.packages.urllib3.connectionpool:758: Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org
2016-04-04 03:26:48,215:INFO:__main__:385: Saving account_key.json
2016-04-04 03:26:48,216:INFO:__main__:385: Saving fullchain.pem
2016-04-04 03:26:48,216:INFO:__main__:385: Saving chain.pem
2016-04-04 03:26:48,216:INFO:__main__:385: Saving cert.pem
2016-04-04 03:26:48,216:INFO:__main__:385: Saving key.pem
-----&gt; Certificate retrieved successfully.
-----&gt; Symlinking let's encrypt certificates
-----&gt; Configuring staging.example.co.jp...(using built-in template)
-----&gt; Creating https nginx.conf
-----&gt; Running nginx-pre-reload
       Reloading nginx
-----&gt; Disabling ACME proxy for staging.example.co.jp...
       done
</code></pre>

<h2>有効になっているアプリケーション一覧確認</h2>

<p><code>dokku letsencrypt:ls</code> で有効になっているアプリケーションとその有効期限を確認します。</p>

<pre><code>$ dokku letsencrypt:ls
-----&gt; App name           Certificate Expiry        Time before expiry        Time before renewal
staging.example.co.jp 2016-07-03 11:27:00       89d, 22h, 56m, 55s        59d, 22h, 56m, 55s
</code></pre>

<h2>自動更新</h2>

<p>有効期限が 30 日 (<code>DOKKU_LETSENCRYPT_GRACEPERIOD</code> で変更可能) を切ると自動更新してくれる <code>dokku letsencrypt:auto-renew</code> も試しておきます。</p>

<pre><code>$ dokku letsencrypt:auto-renew
=====&gt; Auto-renewing all apps...
       staging.example.co.jp still has 59d, 22h, 48m, 36s days left before renewal
=====&gt; Finished auto-renewal
</code></pre>

<p>問題なさそうなので、<code>dokku</code> ユーザーの <code>crontab</code> で設定して自動実行するようにしておきます。
リモートからのトリガーで実行されるように ssh で入れるユーザーの <code>crontab</code> で <code>ssh dokku letsencrypt:auto-renew</code> を設定しておくのでも良いと思います。</p>

<h2>セキュリティ上の問題点</h2>

<p><code>dokku-letsencrypt</code> が使用している <a href="https://github.com/kuba/simp_le" title="Simple Let's Encrypt Client">Simple Let&rsquo;s Encrypt Client</a> の issue の <a href="https://github.com/kuba/simp_le/issues/29" title="private key permissions">private key permissions</a> で指摘されているように、 <code>ls -al /home/dokku/staging.example.co.jp/letsencrypt/certs/current/</code> で確認してみると、他のユーザーからは読めなくするべき <code>account_key.json</code> や <code>key.pem</code> も誰でも読めるパーミッションになってしまっているので、 <code>sudo chmod 700 /home/dokku/staging.example.co.jp/letsencrypt</code> などでパーミッションを落としておく方が良さそうです。</p>

<p>ファイル自体のパーミッションを落としても良さそうですが、更新された後のことも考えると <code>/home/dokku/APP/letsencrypt</code> ディレクトリ自体のパーミッションを落としておくのが良さそうです。</p>

<h2>Rate Limit</h2>

<p><a href="https://letsencrypt.jp/faq/#RateLimiting" title="Let's Encrypt の証明書に取得数制限はありますか？">Let&rsquo;s Encrypt の証明書に取得数制限はありますか？</a> のリンク先に書いてあるように、この記事執筆時点では「アカウント登録/IP アドレスごと」(3 時間で 10 個) と「証明書発行/ドメインごと」(1 週間で 5 個) の制限があるので、注意が必要です。</p>

<p>特に dokku-letsencrypt では<a href="https://github.com/letsencrypt/letsencrypt">公式のクライアント</a>が <code>/etc/letsencrypt/accounts</code> でアカウントを共有するのと違って、 <code>account_key.json</code> をアプリケーションごとに作成しているので、注意が必要そうです。</p>

<p>ただし、現状の制限だと証明書発行数の制限の方が引っかかりやすいので、アカウント登録の制限は問題にならないようにも思います。</p>

<p>証明書発行数の制限については <code>dokku domains:add</code> や <code>dokku domains:remove</code> で適切にドメインの追加や削除をしてから <code>dokku letsencrypt</code> を実行するように README.md の <a href="https://github.com/dokku/dokku-letsencrypt/tree/b4950b8254f683e4af775bad44e390763a699de1#dealing-with-rate-limit" title="Dealing with rate limit">Dealing with rate limit</a> に書いてあります。</p>

<h2>証明書の情報表示</h2>

<p><code>dokku certs:info</code> で letsencrypt のものに限らず、証明書の情報を表示できます。</p>

<pre><code>adminuser@tk2-213-16013:~$ dokku certs:info staging.example.co.jp
-----&gt; Fetching SSL Endpoint info for staging.example.co.jp...
-----&gt; Certificate details:
=====&gt; Common Name(s):
=====&gt;    staging.example.co.jp
=====&gt;    staging.example.co.jp
=====&gt; Expires At: Jul  3 02:27:00 2016 GMT
=====&gt; Issuer: C=US, O=Lets Encrypt, CN=Lets Encrypt Authority X3
=====&gt; Starts At: Apr  4 02:27:00 2016 GMT
=====&gt; Subject: CN=staging.example.co.jp
=====&gt; SSL certificate is self signed.
adminuser@tk2-213-16013:~$ dokku certs:info production.example.co.jp
-----&gt; Fetching SSL Endpoint info for production.example.co.jp...
-----&gt; Certificate details:
=====&gt; Common Name(s):
=====&gt;    production.example.co.jp
=====&gt;    production.example.co.jp
=====&gt;    example.co.jp
=====&gt; Expires At: Aug  4 00:05:31 2016 GMT
=====&gt; Issuer: C=IL, O=StartCom Ltd., OU=Secure Digital Certificate Signing, CN=StartCom Class 1 Primary Intermediate Server CA
=====&gt; Starts At: Aug  3 18:20:22 2015 GMT
=====&gt; Subject: C=JP; CN=production.example.co.jp; emailAddress=hostmaster@example.co.jp
=====&gt; SSL certificate is self signed.
adminuser@tk2-213-16013:~$ dokku certs:info another.example.co.jp
-----&gt; Fetching SSL Endpoint info for another.example.co.jp...
-----&gt; Certificate details:
=====&gt; Common Name(s):
=====&gt;    another.example.co.jp
=====&gt;    another.example.co.jp
=====&gt;    example.co.jp
=====&gt; Expires At: Apr 23 04:56:14 2016 GMT
=====&gt; Issuer: C=IL, O=StartCom Ltd., OU=Secure Digital Certificate Signing, CN=StartCom Class 1 Primary Intermediate Server CA
=====&gt; Starts At: Apr 22 23:55:13 2015 GMT
=====&gt; Subject: C=JP; CN=another.example.co.jp; emailAddress=hostmaster@example.co.jp
=====&gt; SSL certificate is self signed.
adminuser@tk2-213-16013:~$
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ccollect によるバックアップの設定]]></title>
    <link href="http://blog.n-z.jp/blog/2016-04-04-ccollect.html"/>
    <updated>2016-04-04T22:51:06+09:00</updated>
    <id>http://blog.n-z.jp/blog/ccollect</id>
    <content type="html"><![CDATA[<p><code>ccollect</code> という <code>rsync</code> の <code>--link-dest</code> オプションによるハードリンクをうまく使って差分バックアップをしてくれるツールでバックアップ設定をしました。</p>

<!--more-->


<h2>インストール</h2>

<p>deb パッケージは存在しないので、まず <code>git clone https://github.com/ungleich/ccollect ~/src/github.com/ungleich/ccollect</code> などで最新 (現時点で 1.0) の ccollect を github のミラーから取得します。</p>

<p><a href="http://www.nico.schottelius.org/software/ccollect/">本家</a> の download ページにある tarball は 0.8 まででちょっと古いです。</p>

<h2>共通設定</h2>

<p>設定は <code>CCOLLECT_CONF</code> (デフォルトは <code>/etc/ccollect</code>) の中に置いていきます。</p>

<p>共通設定は <code>defaults</code> の中に、バックアップごとの設定は <code>sources</code> の中に置いていきます。</p>

<h3>バックアップ保存回数の設定</h3>

<p><code>defaults/intervals</code> の中に適当なファイル名でバックアップの保存回数を設定していきます。</p>

<p><code>daily</code> などの名前をつけることが多いようですが、 <code>ccollect</code> 自体に毎日自動実行する機能があるわけではないので、自前で <code>cron</code> などを使って実行する必要が有ります。</p>

<ul>
<li><code>sudo mkdir -p /etc/ccollect/defaults/intervals</code></li>
<li><code>echo 10 | sudo tee /etc/ccollect/defaults/intervals/daily</code></li>
<li><code>echo 24 | sudo tee /etc/ccollect/defaults/intervals/monthly</code></li>
<li><code>echo 10 | sudo tee /etc/ccollect/defaults/intervals/weekly</code></li>
</ul>


<p>ここでは日時バックアップと週次バックアップは 10 回分、月次バックアップは 2 年分保存するようにしてみました。</p>

<h3>不完全なバックアップの削除</h3>

<p><code>ccollect</code> では構造化された設定ファイルをパースするのではなく、簡単な内容のファイルの中身が設定値になっていたり、ファイルの存在がフラグとなっていたりするようになっています。</p>

<p>ここでは <code>rsync</code> の途中で <code>ssh</code> が切れたなどの理由で不完全なバックアップができてしまった時に削除するフラグを設定します。</p>

<ul>
<li><code>sudo touch /etc/ccollect/defaults/delete_incomplete</code></li>
</ul>


<h2>ローカルのバックアップ設定の追加</h2>

<p>まず動作確認も兼ねて、ローカルのバックアップを取る設定を追加してみます。</p>

<ul>
<li><code>sudo mkdir -p /etc/ccollect/sources/$(hostname)-home</code></li>
<li><code>echo '/home' | sudo tee /etc/ccollect/sources/$(hostname)-home/source</code></li>
<li><code>echo "/srv/backup/$(hostname)-home" | sudo tee /etc/ccollect/sources/$(hostname)-home/destination</code></li>
</ul>


<p>バックアップから除外するファイルも設定してみます。
除外指定ということを明示するために <code>-</code> をつけていますが、つけずにパターンだけでもこの場合は同じです。
<code>exclude</code> ファイルの書式の詳細は <code>rsync "--exclude-from"</code> で検索して調べてください。</p>

<ul>
<li><code>echo '- *.swp' | sudo tee /etc/ccollect/sources/$(hostname)-home/exclude</code></li>
<li><code>echo '- *~' | sudo tee -a /etc/ccollect/sources/$(hostname)-home/exclude</code></li>
</ul>


<p>今回は関係ないかもしれませんが、 <code>/</code> パーティションなどをバックアップする時にはつけた方が良い <code>--one-file-system</code> オプションも追加しておきます。</p>

<ul>
<li><code>echo '--one-file-system' | sudo tee /etc/ccollect/sources/$(hostname)-home/rsync_options</code></li>
</ul>


<p>サマリー表示を有効にしておきます。
初回実行なので詳細表示も有効にしてみます。</p>

<ul>
<li><code>sudo touch /etc/ccollect/sources/$(hostname)-home/summary</code></li>
<li><code>sudo touch /etc/ccollect/sources/$(hostname)-home/verbose</code></li>
</ul>


<h3>初回バックアップ実行</h3>

<p><code>destination</code> ファイルで指定したバックアップ先ディレクトリは自動作成されないので、手動で作成してバックアップを実行します。
2 回実行してちゃんと差分バックアップになっているのを確認します。</p>

<ul>
<li><code>sudo mkdir -pv $(cat /etc/ccollect/sources/*/destination)</code></li>
<li><code>sudo ~/src/github.com/ungleich/ccollect/ccollect daily $(hostname)-home</code></li>
<li><code>sudo ~/src/github.com/ungleich/ccollect/ccollect daily $(hostname)-home</code></li>
</ul>


<p>容量も 2 倍になっていないのを確認します。</p>

<ul>
<li><code>sudo du -s /srv/backup/$(hostname)-home /home</code></li>
</ul>


<p>動作確認ができたので、詳細表示オプションを削除しておきます。</p>

<ul>
<li><code>sudo rm /etc/ccollect/sources/$(hostname)-home/verbose</code></li>
</ul>


<h2>リモートからのバックアップ設定の追加</h2>

<p><code>source</code> にリモートホストを設定する以外はローカルの設定と同様に設定していきます。</p>

<ul>
<li><code>sudo mkdir /etc/ccollect/sources/vps-etc</code></li>
<li><code>echo /srv/backup/vps-etc | sudo tee /etc/ccollect/sources/vps-etc/destination</code></li>
<li><code>echo root@vps.example.jp:/etc | sudo tee /etc/ccollect/sources/vps-etc/source</code></li>
<li><code>echo '- *.swp' | sudo tee -a /etc/ccollect/sources/vps-etc/exclude</code></li>
<li><code>echo '- *~' | sudo tee -a /etc/ccollect/sources/vps-etc/exclude</code></li>
<li><code>sudo touch /etc/ccollect/sources/vps-etc/summary</code></li>
</ul>


<p>ネットワーク的につながらない時はバックアップが失敗するので、事前チェックするようにします。</p>

<ul>
<li><code>sudoedit /etc/ccollect/sources/vps-etc/pre_exec</code></li>
<li><code>sudo chmod +x /etc/ccollect/sources/vps-etc/pre_exec</code></li>
</ul>


<p><code>pre_exec</code> の内容は以下の通りです。
<a href="https://github.com/ungleich/ccollect/blob/5356370233e0883b5c6cc62b12c84ef058f8c239/doc/ccollect.text#L872-L884">ccollect のドキュメントの Testing for host reachabilty</a> を参考にしています。</p>

<pre><code class="bash">#!/bin/sh
set -e
cur_conf_dir="${CCOLLECT_CONF:-/etc/ccollect}/sources/$name"
SRC_HOST=`cat "$cur_conf_dir/source" | cut -d"@" -f2 | cut -d":" -f1`
ping -c1 -q "$SRC_HOST" || exit $?
</code></pre>

<h3>ssh 設定</h3>

<p>セキュリティ的にはあまり好ましくないのですが、バックアップ用に root から root に ssh で接続できるようにします。</p>

<p>まず、バックアップ先のローカルのマシンで root の ssh 用の鍵を作成します。</p>

<ul>
<li><code>sudo ls -al /root/.ssh</code> で root に ssh の鍵がないのを確認したら <code>sudo ssh-keygen</code> で生成します。存在する場合は別のファイル名で生成して <code>sudoedit /root/.ssh/config</code> で <code>IdentityFile</code> を設定しておきます。自動実行で使用するので、パスフレーズは空にしておきます。</li>
<li>ssh のポート番号を変更しているなど、別途設定が必要な場合は <code>sudoedit /root/.ssh/config</code> で設定しておくのを忘れないように注意が必要です。</li>
<li><code>sudo cat /root/.ssh/id_rsa.pub</code> で公開鍵を表示してコピーしておきます。</li>
</ul>


<p>続いて、バックアップ対象の VPS (バックアップ元) の方で ssh を許可する設定をします。</p>

<ul>
<li><code>sudo install -m700 -d /root/.ssh</code> で <code>/root/.ssh</code> がなければ作成します。</li>
<li><code>sudoedit /root/.ssh/authorized_keys</code> で接続を許可する鍵として、先ほどコピーした公開鍵を貼り付けます。</li>
<li>必要に応じて <code>from="pattern-list"</code> や <code>no-agent-forwarding,no-user-rc,no-X11-forwarding,no-port-forwarding</code> などの制限も追加しておきます。</li>
<li><code>sudoedit /etc/ssh/sshd_config</code> で <code>PermitRootLogin</code> を <code>no</code> 以外にします。例えば <code>without-password</code> にしておきます。</li>
<li><code>sudoedit /etc/ssh/sshd_config</code> で <code>AllowUsers</code> による制限をしている時は <code>AllowUsers root@接続元IPアドレス</code> を追加しておきます。接続元 IP アドレスが固定ではない場合は、セキュリティ的に弱くなりますが <code>AllowUsers root</code> で許可します。</li>
<li><code>/etc/ssh/sshd_config</code> の設定を変更した場合は <code>sudo service ssh restart</code> で反映させておきます。</li>
</ul>


<p>設定ができたら、接続元 (バックアップ先のローカルのマシン) から ssh の接続確認をします。</p>

<ul>
<li><code>sudo ssh root@vps.example.jp hostname</code> などで ssh 接続ができることの確認とホスト鍵の確認を済ませておきます。</li>
</ul>


<h3>初回バックアップ実行</h3>

<p>ローカルでのバックアップと同様にバックアップ先ディレクトリを作成してからバックアップを実行します。</p>

<ul>
<li><code>sudo mkdir -pv $(cat /etc/ccollect/sources/*/destination)</code></li>
<li><code>sudo ~/src/github.com/ungleich/ccollect/ccollect daily vps-etc</code></li>
<li><code>sudo ~/src/github.com/ungleich/ccollect/ccollect daily vps-etc</code></li>
</ul>


<h2>リモートからの一般ユーザー権限でのバックアップ設定の追加</h2>

<p>dokku で persistent storage としてボリュームマウントを使っているとファイルの所有者とグループがアプリケーションのデプロイのたびに変わってしまって、差分バックアップに支障が出そうだったので、一般ユーザーでのバックアップも設定しました。</p>

<p><a href="https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html" title="XDG Base Directory Specification">XDG Base Directory Specification</a> の <code>XDG_CONFIG_HOME</code> を参考にして <code>~/.config</code> 以下に <code>/etc</code> 以下と同じ構造で設定を作成することにしました。</p>

<ul>
<li><code>mkdir -p ~/.config/ccollect/defaults/intervals</code></li>
<li><code>echo 10 &gt; ~/.config/ccollect/defaults/intervals/daily</code></li>
<li><code>echo 24 &gt; ~/.config/ccollect/defaults/intervals/monthly</code></li>
<li><code>echo 10 &gt; ~/.config/ccollect/defaults/intervals/weekly</code></li>
<li><code>mkdir -p ~/.config/ccollect/sources/vps-srv</code></li>
<li><code>echo /srv/backup/vps-srv &gt; ~/.config/ccollect/sources/vps-srv/destination</code></li>
<li><code>echo vpsuser@vps.example.jp:/srv &gt; ~/.config/ccollect/sources/vps-srv/source</code></li>
<li><code>echo '- *.swp' &gt; ~/.config/ccollect/sources/vps-srv/exclude</code></li>
<li><code>echo '- *~' &gt;&gt; ~/.config/ccollect/sources/vps-srv/exclude</code></li>
<li><code>touch ~/.config/ccollect/sources/vps-srv/summary</code></li>
</ul>


<p>ネットワーク的につながらない時はバックアップが失敗するので、事前チェックするようにします。</p>

<ul>
<li><code>editor ~/.config/ccollect/sources/vps-srv/pre_exec</code></li>
<li><code>chmod +x ~/.config/ccollect/sources/vps-srv/pre_exec</code></li>
</ul>


<p><code>pre_exec</code> の内容は以下の通りです。
「リモートからのバックアップ設定の追加」で作成したものと全く同じ内容です。</p>

<pre><code class="bash">#!/bin/sh
set -e
cur_conf_dir="${CCOLLECT_CONF:-/etc/ccollect}/sources/$name"
SRC_HOST=`cat "$cur_conf_dir/source" | cut -d"@" -f2 | cut -d":" -f1`
ping -c1 -q "$SRC_HOST" || exit $?
</code></pre>

<h3>初回バックアップ実行</h3>

<p>一般ユーザー権限でバックアップするので、バックアップ先ディレクトリを <code>chown</code> しておきます。</p>

<p><code>ssh vpsuser@vps.example.jp</code> で一度接続してホスト鍵の確認なども終わらせておきます。</p>

<p>設定ファイルの場所が違うので、環境変数 <code>CCOLLECT_CONF</code> を設定しつつ実行します。</p>

<ul>
<li><code>sudo mkdir -pv $(cat ~/.config/ccollect/sources/*/destination)</code></li>
<li><code>sudo chown $(id -u) /srv/backup/vps-srv</code></li>
<li><code>env CCOLLECT_CONF=$HOME/.config/ccollect ~/src/github.com/ungleich/ccollect/ccollect daily vps-srv</code></li>
<li><code>env CCOLLECT_CONF=$HOME/.config/ccollect ~/src/github.com/ungleich/ccollect/ccollect daily vps-srv</code></li>
</ul>


<h2>バックアップ自動実行設定</h2>

<p>cron で毎日自動バックアップが動くように設定します。
時間がかかるので、 <code>cron.daily</code> のファイルの中でも最後に実行されるように <code>zz-</code> で始まる名前にしています。
そして、パッケージで入れたファイルと区別できるように <code>local</code> という文字列を名前に入れています。</p>

<p>その際、保存回数が一番多くて保存期間が長い <code>monthly</code> を優先するようにしてみました。</p>

<p>ログ保存用のディレクトリは一般的な debian の流儀に合わせて adm グループのみ読めるようにしています。
<code>install</code> コマンドについては <a href="http://blog.n-z.jp/blog/2014-02-14-install.html" title="installコマンドでコマンド数を減らす">installコマンドでコマンド数を減らす</a> を参考にしてください。</p>

<p>ログは rotate などはせずに全部残して、 <code>tools/ccollect_analyse_logs</code> でエラーや警告があれば cron からのメールとして飛ぶようにしました。
その際、 <code>tools/ccollect_analyse_logs</code> の exit status が <code>grep</code> の exit status そのままなので、エラーの有無と逆の意味に感じられてしまうので、反転するようにしました。</p>

<ul>
<li><code>sudoedit /etc/cron.daily/zz-local-ccollect</code></li>
<li><code>sudo chmod +x /etc/cron.daily/zz-local-ccollect</code></li>
</ul>


<pre><code class="bash /etc/cron.daily/zz-local-ccollect">#!/bin/sh
INTERVAL=daily
if [ 7 = "$(date +%u)" ]; then
  INTERVAL=weekly
fi
if [ 01 = "$(date +%d)" ]; then
  INTERVAL=monthly
fi
mkdir -p /var/log/ccollect
LOGDIR="/var/log/ccollect"
LOGFILE="$LOGDIR/$(date +%Y%m%d-%H%M).log"
LOCALUSER="localuser"
CCOLLECT_DIR="/home/$LOCALUSER/src/github.com/ungleich/ccollect"
install -m750 -oroot -gadm -d "$LOGDIR"
{
  su - "$LOCALUSER" -c 'env CCOLLECT_CONF=$HOME/.config/ccollect '"$CCOLLECT_DIR"'/ccollect -a '"$INTERVAL"
  "$CCOLLECT_DIR/ccollect" -a "$INTERVAL"
} &gt;"$LOGFILE" 2&gt;&amp;1
if /bin/sh "$CCOLLECT_DIR/tools/ccollect_analyse_logs" "we" &lt; "$LOGFILE"; then
  # found
  exit 1
else
  # not found
  exit 0
fi
</code></pre>

<h2>リモートの dokku の home のバックアップ設定</h2>

<p>他の設定例として、リモートの dokku の home のバックアップ設定もしてみました。
設定が似ている <code>vps-etc</code> を雛形としてコピーして <code>destination</code> と <code>source</code> などを書き換える形で設定しました。</p>

<ul>
<li><code>cd /etc/ccollect/sources</code></li>
<li><code>sudo cp -a vps-etc vps-home</code></li>
<li><code>sudoedit vps-home/destination</code> で <code>/srv/backup/vps-home</code> に変更</li>
<li><code>sudoedit vps-home/source</code> で <code>root@vps.example.jp:/home</code> に変更</li>
<li><code>sudoedit vps-home/exclude</code> で <code>- cache</code> を追加 (<code>/home/dokku/$APP/cache/</code> は buildpack での build 時などのキャッシュに使われるのと、ファイルの所有者とグループがどんどん変わるので、バックアップからは除外)</li>
</ul>


<h3>初回バックアップ実行</h3>

<p><code>vps-etc</code> のバックアップと同様にバックアップ先ディレクトリを作成してからバックアップを実行します。</p>

<ul>
<li><code>sudo mkdir -pv $(cat /etc/ccollect/sources/*/destination)</code></li>
<li><code>sudo ~/src/github.com/ungleich/ccollect/ccollect daily vps-home</code></li>
<li><code>sudo ~/src/github.com/ungleich/ccollect/ccollect daily vps-home</code></li>
</ul>


<h2>uid, gid 問題</h2>

<p>LDAP などでアカウントを共通化していれば問題ないのですが、 <code>rsync</code> では uid や gid を数値のまま保存してコピーするので、バックアップ元とバックアップ先で同じ uid に対して別のユーザーが存在すると、意図しないユーザーが読めるバックアップができてしまうので、注意が必要です。</p>

<p>この記事の例だと <code>/srv/backup/vps-home</code> のパーミッションを変更する (<code>sudo chmod 700 /srv/backup/vps-home</code>) などの対処をしておくと良いと思います。</p>

<h2>バックアップの差分の確認</h2>

<p><a href="https://github.com/ungleich/ccollect/blob/5356370233e0883b5c6cc62b12c84ef058f8c239/doc/ccollect.text#L858-L869" title="ccollect.text の Comparing backups">ccollect.text の Comparing backups</a> によると <code>rsync -n -a --delete --stats --progress daily.20080324-0313.17841/ daily.20080325-0313.31148/</code> のように <code>-n</code> オプション付きで <code>rsync</code> を実行することによってバックアップの差分を確認できるようです。</p>

<h2>まとめ</h2>

<p><code>ccollect</code> で差分バックアップを作成するようにしました。</p>

<p><code>rsync</code> によるバックアップなので、圧縮などもするバックアップツールと違い、バックアップの内容も元のディレクトリ構造そのままでわかりやすいので、一部だけ復元するなどの操作も素直に実行しやすくなっています。</p>

<p>ハードリンクなので i-node は消費しますが、変化がないファイルについては容量を消費しないので、バックアップサイズも抑えられます。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[dokku 0.5.3 を vagrant 環境で試してみた]]></title>
    <link href="http://blog.n-z.jp/blog/2016-03-30-dokku-053.html"/>
    <updated>2016-03-30T22:00:00+09:00</updated>
    <id>http://blog.n-z.jp/blog/dokku-053</id>
    <content type="html"><![CDATA[<p>社内向けアプリで本番環境でも使っている dokku のバージョン 0.5.3 をいろいろ試しやすくするために vagrant 環境で試してみました。</p>

<!--more-->


<h2>確認バージョン</h2>

<ul>
<li>VirtualBox 5.0.16</li>
<li>Vagrant 1.8.1</li>
<li>dokku 0.5.3</li>
</ul>


<h2>dokku v0.5.0 での主な変更点</h2>

<p><a href="https://github.com/dokku/dokku/releases/tag/v0.5.0">v0.5.0</a> での主な変更点は以下の通りです。</p>

<ul>
<li>docker 1.10/1.11 のサポートと、 docker 1.9.1 以上の必須化</li>
<li>ドキュメント改善</li>
<li><a href="http://dokku.viewdocs.io/dokku/deployment/deployment-tasks/" title="Deployment Tasks">Deployment Tasks</a> (<code>app.json</code> での <code>scripts.dokku.predeploy</code> と <code>scripts.dokku.postdeploy</code> のサポート)</li>
<li><a href="http://dokku.viewdocs.io/dokku/deployment/dockerfiles/" title="Dockerfile Deployment">Dockerfile Deployment</a> で <code>Procfile</code> サポート、<code>EXPOSE</code> の扱いの変更</li>
<li><a href="http://dokku.viewdocs.io/dokku/dokku-storage/">persistent storage plugin</a> のオフィシャル化</li>
</ul>


<h2>初期設定</h2>

<p><code>git clone https://github.com/dokku/dokku</code> で clone してきたディレクトリの中に入って <code>vagrant up</code> します。
最初は box のダウンロードもあるので時間がかかります。</p>

<p><a href="http://xip.io/">xip.io</a> を使ってサブドメインを使ったデプロイを試します。</p>

<p><code>http://10.0.0.2.xip.io/</code> を開き、 <code>Hostname</code> を <code>10.0.0.2.xip.io</code> にして <code>Use virtualhost naming for apps</code> にチェックを入れて、 <code>Finish Setup</code> を押します。</p>

<p><a href="http://dokku.viewdocs.io/dokku/application-deployment/">http://dokku.viewdocs.io/dokku/application-deployment/</a> にリダイレクトされるので、そのチュートリアルを試します。</p>

<h2>チュートリアル前の準備</h2>

<p><code>vagrant ssh</code> で入って操作します。</p>

<p><code>docker</code> コマンドや <code>dokku</code> コマンドで <code>sudo</code> を不要にするためにグループに追加します。</p>

<ul>
<li><code>sudo usermod -aG docker vagrant</code></li>
<li><code>sudo usermod -aG dokku vagrant</code></li>
</ul>


<p>ビルド中のダウンロードでタイムアウトしにくくするためにタイムアウト時間をのばします。</p>

<ul>
<li><code>dokku config:set --global CURL_TIMEOUT=120</code></li>
</ul>


<p><code>dokku run</code> などで実行して終了したコンテナが溜まっていかないようにするために、デフォルトで <code>--rm</code> をつけるようにします。(この設定をしなくても <code>git push</code> したときに自動で実行される <code>dokku cleanup</code> で削除されます。)</p>

<ul>
<li><code>dokku config:set --global DOKKU_RM_CONTAINER=1</code></li>
</ul>


<h2>チュートリアル</h2>

<p>チュートリアルも <code>vagrant ssh</code> で入った環境で試します。
<code>sudo dokku plugin:install</code> 以外はホスト側からでも実行できます。</p>

<ul>
<li><code>git clone git@github.com:heroku/ruby-rails-sample.git</code> で rails のサンプルを clone しておきます。</li>
<li><code>dokku apps:create ruby-rails-sample</code> でアプリケーションを作成します。データベースとのリンクに必要なので、事前に作成していますが、 <a href="https://github.com/heroku/node-js-sample">https://github.com/heroku/node-js-sample</a> のように単独で動くアプリケーションでは事前に <code>apps:create</code> しなくても構いません。</li>
<li><code>sudo dokku plugin:install https://github.com/dokku/dokku-postgres.git</code> で postgres プラグインをインストールします。インストールの後処理で <code>postgres:9.5.0</code>, <code>svendowideit/ambassador:latest</code>, <code>dokkupaas/wait:latest</code> が docker pull されるので、ダウンロードに少し時間がかかります。</li>
<li><code>docker images</code> で確認するとわかるのですが、なぜか <code>gliderlabs/herokuish</code> が 0 バイトのイメージになってしまっているので <code>docker pull gliderlabs/herokuish</code> でダウンロードしておきます。ここもダウンロードに時間がかかります。この手順は普通にインストールした場合は不要なはずです。</li>
<li><code>dokku postgres:create rails-database</code> でデータベースのコンテナを作成して <code>dokku postgres:link rails-database ruby-rails-sample</code> でリンクします。</li>
<li><code>git remote add dokku dokku@10.0.0.2:ruby-rails-sample</code> で remote に dokku を登録して <code>git push dokku master</code> でデプロイします。</li>
<li><code>curl</code> コマンドでエラーになった場合、 <code>CURL_TIMEOUT</code> をのばして、再度 <code>git push dokku master</code> します。</li>
<li><code>http://ruby-rails-sample.10.0.0.2.xip.io/</code> を開いて <code>Hello World</code> と現在時刻が UTC (+0000) で表示されていたら成功です。</li>
</ul>


<h2>チュートリアル後の変更例</h2>

<p>現在時刻が UTC で表示されていたので JST に変更してみます。</p>

<ul>
<li><code>dokku config:set ruby-rails-sample TZ=Asia/Tokyo</code></li>
</ul>


<p><code>http://ruby-rails-sample.10.0.0.2.xip.io/</code> を開いて <code>Hello World</code> と現在時刻が JST (+0900) で表示されていたら成功です。</p>

<h2><code>rake db:migrate</code> を実行する</h2>

<p><code>dokku run ruby-rails-sample bundle exec rake db:migrate</code> で実行できます。</p>

<h2><code>scripts.dokku.predeploy</code> で <code>rake db:migrate</code> を自動実行する</h2>

<p><a href="http://dokku.viewdocs.io/dokku~v0.5.3/deployment/deployment-tasks/">Deployment Tasks</a> に書いてあるように v0.5.0 から <code>app.json</code> に <code>scripts.dokku.predeploy</code> を設定できるようになっているので、そこで <code>rake db:migrate</code> を自動実行するように設定してみます。</p>

<p>heroku が対応している <code>scripts.postdeploy</code> は初回の deploy 時にしか実行されないのに対して、 <code>scripts.dokku.predeploy</code> と <code>scripts.dokku.postdeploy</code> は毎回実行されるという違いがあります。</p>

<pre><code class="diff">diff --git a/app.json b/app.json
index 452cef1..4c828fa 100644
--- a/app.json
+++ b/app.json
@@ -5,6 +5,9 @@
   "repository": "https://github.com/heroku/ruby-rails-sample",
   "logo": "https://upload.wikimedia.org/wikipedia/commons/c/c3/Ruby_on_Rails_logo.svg",
   "scripts": {
+    "dokku": {
+      "predeploy": "bundle exec rake db:migrate"
+    },
     "postdeploy": "bundle exec rake db:migrate"
   },
   "env": {
</code></pre>

<p>という変更を commit して push して動作確認します。</p>

<p>さらに <code>rails g model</code> などで migration ファイルを作成してさらに動作確認できます。</p>

<h2>pre-flight checks</h2>

<p><a href="http://dokku.viewdocs.io/dokku~v0.5.3/checks-examples/">Zero Downtime Deploys</a> に書いてあるようにゼロダウンタイムデプロイを実現するために <code>CHECKS</code> ファイルを作成します。
(デプロイ後のメッセージに <code>Shutting down old containers in 60 seconds</code> とあるように、デプロイして新しいコンテナに切り替わった直後の 1 分間は古いコンテナも動いています。)</p>

<p>以下の内容の <code>CHECKS</code> ファイルを作成して、デプロイ時の起動確認をデフォルトの 10 秒待つだけの動作から、 http で特定の URL にアクセスして指定した内容が含まれるかどうかのチェックに変更します。</p>

<pre><code>/ Hello World
</code></pre>

<p>デフォルトでは 5 秒ごとに 5 回までのチェックですが、以下の内容にすると 10 秒ごとに 20 回までのチェックになります。
起動に時間がかかるアプリケーションの場合に、回数を増やしたり時間をのばしたりすると良いと思います。</p>

<pre><code>WAIT=10
ATTEMPTS=20
/ Hello World
</code></pre>

<h2>アプリケーションを削除する</h2>

<p><code>dokku apps:destroy ruby-rails-sample</code> で削除できます。
heroku での削除と同じように、確認のため、アプリケーション名を再度入力しないと消えないようになっています。</p>

<p>データベースも作成していたので、同様に <code>dokku postgres:destroy rails-database</code> で削除します。</p>

<h2>node-js-sample を試す</h2>

<p>Dokku の昔のバージョンのチュートリアルは node-js-sample を使っていたので、 node-js-sample も試してみます。</p>

<ul>
<li><code>git clone git@github.com:heroku/node-js-sample.git</code></li>
<li><code>cd node-js-sample</code></li>
<li><code>git remote add dokku dokku@10.0.0.2:node-js-sample</code></li>
<li><code>git push dokku master</code></li>
</ul>


<p><code>http://node-js-sample.10.0.0.2.xip.io/</code> を開いて <code>Hello World!</code> が表示されたら成功です。</p>

<h2>動作確認用シェルスクリプト</h2>

<p><code>rails g model</code> 用に <a href="https://github.com/riywo/anyenv">anyenv</a> と <a href="https://github.com/rbenv/rbenv">rbenv</a> を使って ruby と rails のインストールまでしています。</p>

<p>実行前に <code>http://10.0.0.2.xip.io/</code> を開いて設定をしないと途中で失敗して止まります。</p>

<pre><code class="bash">#!/bin/bash
set -euo pipefail
set -x
cd /home/vagrant
sudo usermod -aG docker vagrant
sudo usermod -aG dokku vagrant
dokku config:set --global CURL_TIMEOUT=120
dokku config:set --global DOKKU_RM_CONTAINER=1
if [[ ! -d ruby-rails-sample ]]; then
  git clone https://github.com/heroku/ruby-rails-sample.git
fi
if [[ ! -d /home/dokku/ruby-rails-sample ]]; then
  dokku apps:create ruby-rails-sample
fi
if [[ ! -d /var/lib/dokku/plugins/available/postgres ]]; then
  sudo dokku plugin:install https://github.com/dokku/dokku-postgres.git || :
  sudo docker pull gliderlabs/herokuish
fi
if [[ ! -f /home/dokku/ruby-rails-sample/DOCKER_OPTIONS_RUN ]]; then
  dokku postgres:create rails-database || :
  dokku postgres:link rails-database ruby-rails-sample
fi
pushd ~/ruby-rails-sample
if ! git remote | grep -q dokku; then
  git remote add dokku dokku@10.0.0.2:ruby-rails-sample
fi
git push dokku master
if ! dokku config ruby-rails-sample | grep -q '^TZ'; then
  dokku config:set ruby-rails-sample TZ=Asia/Tokyo
fi
popd
if [[ ! -d node-js-sample ]]; then
  git clone https://github.com/heroku/node-js-sample.git
fi
pushd ~/node-js-sample
if ! git remote | grep -q dokku; then
  git remote add dokku dokku@10.0.0.2:node-js-sample
fi
git push dokku master
popd
if [[ -z "$(dpkg -l | grep nodejs)" ]]; then
  sudo sed -i~ -e 's/us\.archive/jp.archive/' /etc/apt/sources.list
  sudo apt-get update
  sudo apt-get -y install autoconf bison build-essential libssl-dev libyaml-dev libreadline6-dev zlib1g-dev libncurses5-dev libffi-dev libgdbm3 libgdbm-dev
  sudo apt-get -y install libpq-dev
  sudo apt-get -y install nodejs
fi
if [[ ! -d ~/.anyenv ]]; then
  git clone https://github.com/riywo/anyenv.git ~/.anyenv
  echo 'export PATH="$HOME/.anyenv/bin:$PATH"' &gt;&gt; ~/.bashrc
  echo 'eval "$(anyenv init -)"' &gt;&gt; ~/.bashrc
fi
if [[ -z "$(command -v anyenv)" ]]; then
  export PATH="$HOME/.anyenv/bin:$PATH"
  set +x
  eval "$(anyenv init - --no-rehash)"
  set -x
fi
if [[ ! -d ~/.anyenv/envs/rbenv ]]; then
  anyenv install rbenv
fi
if [[ -z "$(command -v rbenv)" ]]; then
  set +x
  eval "$(anyenv init - --no-rehash)"
  set -x
fi
ruby_version=$(awk '/^ruby/{print $2}' ~/ruby-rails-sample/Gemfile | tr -d "'")
if ! rbenv versions | grep -q "$ruby_version"; then
  rbenv install "$ruby_version"
fi
if [[ ! -f ~/.gemrc ]]; then
  cat &lt;&lt;EOF &gt;~/.gemrc
install: --no-rdoc --no-ri --format-executable
update: --no-rdoc --no-ri --format-executable
EOF
fi
export RBENV_VERSION="$ruby_version"
if ! gem list | grep -q bundler; then
  gem install bundler
fi
pushd ~/ruby-rails-sample
bundle
cat &lt;&lt;EOF &gt;CHECKS
WAIT=10
ATTEMPTS=20
/ Hello World
EOF
git add CHECKS
git commit -m "Add pre-flight checks file" || :
git push dokku master
cat &lt;&lt;EOF &gt;app.json
{
  "scripts": {
    "dokku": {
      "predeploy": "bundle exec rake db:migrate"
    }
  }
}
EOF
git add app.json
git commit -m "Set script.dokku.predeploy to app.json" || :
git push dokku master
popd
pushd ~/node-js-sample
cat &lt;&lt;EOF &gt;CHECKS
/ Hello World!
EOF
git add CHECKS
git commit -m "Add pre-flight checks file" || :
git push dokku master
popd
</code></pre>

<h2>まとめ</h2>

<p>vagrant を使って dokku をいろいろ試す環境を簡単に作ることができました。
この環境を使ってテストやデバッグなどいろいろ試しやすくなると思います。</p>
]]></content>
  </entry>
  
</feed>
